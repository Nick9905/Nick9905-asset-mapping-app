import warningsÂ Â 
warnings.filterwarnings("ignore", message=".*missing ScriptRunContext.*")
import streamlit as st
import pandas as pd
import json
import os
from datetime import datetime
import io
import numpy as np
import re
import plotly
# æ·»åŠ GitHubå­˜å‚¨æ”¯æŒ - ä¿®å¤GITHUB_AVAILABLEå˜é‡å®šä¹‰
GITHUB_AVAILABLE = False
try:
    from github import Github
    import base64
    import requests
    GITHUB_AVAILABLE = True
    print("âœ… GitHubåº“å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âš ï¸ GitHubåº“å¯¼å…¥å¤±è´¥: {e}")
    GITHUB_AVAILABLE = False
except Exception as e:
    print(f"âš ï¸ GitHubåº“å¯¼å…¥å¼‚å¸¸: {e}")
    GITHUB_AVAILABLE = False

# æ˜¾ç¤ºGitHubå¯ç”¨çŠ¶æ€ï¼ˆè°ƒè¯•ç”¨ï¼‰
if not GITHUB_AVAILABLE:
    st.sidebar.warning("âš ï¸ GitHubåŠŸèƒ½ä¸å¯ç”¨ï¼Œä½¿ç”¨æœ¬åœ°å­˜å‚¨")

# GitHubæ•°æ®å­˜å‚¨å‡½æ•°
def get_github_config():
    """è·å–GitHubé…ç½®"""
    try:
        # æ£€æŸ¥Streamlit secrets
        if hasattr(st, 'secrets') and "github" in st.secrets:
            config = {
                "token": st.secrets["github"]["token"],
                "repo": st.secrets["github"]["repo"]
            }
            # éªŒè¯é…ç½®å®Œæ•´æ€§
            if config["token"] and config["repo"]:
                return config
        return None
    except Exception as e:
        print(f"GitHubé…ç½®è¯»å–å¤±è´¥: {str(e)}")
        return None

def save_data_to_github(data, filename):
    """ä¿å­˜æ•°æ®åˆ°GitHub"""
    if not GITHUB_AVAILABLE:
        return False
        
    try:
        config = get_github_config()
        if not config:
            st.warning("âš ï¸ GitHubé…ç½®æœªæ‰¾åˆ°")
            return False
            
        g = Github(config["token"])
        repo = g.get_repo(config["repo"])
        
        # æ¸…ç†æ•°æ®
        cleaned_data = clean_data_for_json(data)
        content = json.dumps(cleaned_data, ensure_ascii=False, indent=2)
        
        # æ–‡ä»¶è·¯å¾„
        file_path = f"data/{filename}"
        
        try:
            # å°è¯•è·å–ç°æœ‰æ–‡ä»¶
            file = repo.get_contents(file_path)
            # æ›´æ–°æ–‡ä»¶
            repo.update_file(
                file_path,
                f"Update {filename} - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
                content,
                file.sha
            )
            st.success(f"âœ… æ•°æ®å·²ä¿å­˜åˆ°GitHub: {filename}")
        except:
            # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°æ–‡ä»¶
            repo.create_file(
                file_path,
                f"Create {filename} - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
                content
            )
            st.success(f"âœ… æ•°æ®å·²åˆ›å»ºåˆ°GitHub: {filename}")
        
        return True
        
    except Exception as e:
        st.error(f"âŒ GitHubä¿å­˜å¤±è´¥: {str(e)}")
        return False

def load_data_from_github(filename):
    """å¢å¼ºç‰ˆGitHubæ•°æ®åŠ è½½"""
    if not GITHUB_AVAILABLE:
        return []
        
    try:
        config = get_github_config()
        if not config:
            return []
            
        g = Github(config["token"])
        repo = g.get_repo(config["repo"])
        
        file_path = f"data/{filename}"
        
        try:
            file = repo.get_contents(file_path)
            raw_content = base64.b64decode(file.content)
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºç©º
            if len(raw_content) == 0:
                st.sidebar.warning(f"âš ï¸ {filename} æ–‡ä»¶ä¸ºç©º")
                return []
            
            # å°è¯•ä¸åŒç¼–ç è§£ç 
            content = None
            for encoding in ['utf-8', 'utf-8-sig', 'gbk', 'gb2312']:
                try:
                    content = raw_content.decode(encoding)
                    break
                except UnicodeDecodeError:
                    continue
            
            if content is None:
                st.sidebar.error(f"âŒ {filename} ç¼–ç è§£æå¤±è´¥")
                return []
            
            # æ¸…ç†å†…å®¹ï¼ˆç§»é™¤BOMå’Œç©ºç™½å­—ç¬¦ï¼‰
            content = content.strip()
            if content.startswith('\ufeff'):  # ç§»é™¤BOM
                content = content[1:]
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºå†…å®¹
            if not content:
                st.sidebar.warning(f"âš ï¸ {filename} å†…å®¹ä¸ºç©º")
                return []
            
            # å°è¯•è§£æJSON
            try:
                data = json.loads(content)
                if isinstance(data, list):
                    st.sidebar.success(f"âœ… {filename} åŠ è½½æˆåŠŸ: {len(data)} æ¡è®°å½•")
                    return data
                else:
                    st.sidebar.error(f"âŒ {filename} ä¸æ˜¯æ•°ç»„æ ¼å¼")
                    return []
            except json.JSONDecodeError as json_error:
                st.sidebar.error(f"âŒ {filename} JSONè§£æå¤±è´¥: {str(json_error)}")
                st.sidebar.write(f"å†…å®¹é¢„è§ˆ: {repr(content[:200])}")
                return []
                
        except Exception as file_error:
            st.sidebar.error(f"âŒ {filename} æ–‡ä»¶è®¿é—®å¤±è´¥: {str(file_error)}")
            return []
            
    except Exception as e:
        st.sidebar.error(f"âŒ GitHubè¿æ¥å¤±è´¥: {str(e)}")
        return []
def debug_github_file_content(filename):
    """è°ƒè¯•GitHubæ–‡ä»¶å†…å®¹"""
    try:
        config = get_github_config()
        if not config:
            return None
            
        g = Github(config["token"])
        repo = g.get_repo(config["repo"])
        
        file_path = f"data/{filename}"
        file = repo.get_contents(file_path)
        
        # è·å–åŸå§‹å†…å®¹
        raw_content = base64.b64decode(file.content)
        
        st.sidebar.write(f"ğŸ“„ {filename} æ–‡ä»¶ä¿¡æ¯:")
        st.sidebar.write(f"- æ–‡ä»¶å¤§å°: {len(raw_content)} å­—èŠ‚")
        st.sidebar.write(f"- ç¼–ç æ£€æµ‹: {raw_content[:100]}")
        
        # å°è¯•ä¸åŒç¼–ç 
        try:
            content_utf8 = raw_content.decode('utf-8')
            st.sidebar.write(f"- UTF-8è§£ç é•¿åº¦: {len(content_utf8)}")
            st.sidebar.write(f"- å‰100å­—ç¬¦: {repr(content_utf8[:100])}")
            return content_utf8
        except UnicodeDecodeError:
            st.sidebar.error("âŒ UTF-8è§£ç å¤±è´¥")
            try:
                content_gbk = raw_content.decode('gbk')
                st.sidebar.write(f"- GBKè§£ç æˆåŠŸï¼Œé•¿åº¦: {len(content_gbk)}")
                return content_gbk
            except:
                st.sidebar.error("âŒ å¤šç§ç¼–ç å°è¯•å¤±è´¥")
                return None
                
    except Exception as e:
        st.sidebar.error(f"âŒ æ–‡ä»¶å†…å®¹æ£€æŸ¥å¤±è´¥: {str(e)}")
        return None

def create_sample_data_files():
    """åˆ›å»ºç¤ºä¾‹æ•°æ®æ–‡ä»¶"""
    st.sidebar.markdown("### ğŸ”§ æ•°æ®æ–‡ä»¶ä¿®å¤")
    
    if st.sidebar.button("ğŸ” æ£€æŸ¥æ–‡ä»¶å†…å®¹", key="debug_files"):
        st.sidebar.write("**è´¢åŠ¡æ•°æ®æ–‡ä»¶æ£€æŸ¥:**")
        debug_github_file_content("financial_data.json")
        
        st.sidebar.write("**å®ç‰©æ•°æ®æ–‡ä»¶æ£€æŸ¥:**")
        debug_github_file_content("physical_data.json")
    
    if st.sidebar.button("ğŸ“ åˆ›å»ºç¤ºä¾‹æ•°æ®", key="create_sample"):
        # ç¤ºä¾‹è´¢åŠ¡æ•°æ®
        sample_financial = [
            {
                "èµ„äº§ç¼–å·": "FA001",
                "èµ„äº§åç§°": "åŠå…¬æ¡Œ",
                "èµ„äº§ç±»åˆ«": "åŠå…¬è®¾å¤‡",
                "è´­ç½®æ—¥æœŸ": "2023-01-15",
                "åŸå€¼": 1200.00,
                "ç´¯è®¡æŠ˜æ—§": 100.00,
                "å‡€å€¼": 1100.00,
                "ä½¿ç”¨éƒ¨é—¨": "è¡Œæ”¿éƒ¨",
                "èµ„äº§çŠ¶æ€": "åœ¨ç”¨"
            },
            {
                "èµ„äº§ç¼–å·": "FA002", 
                "èµ„äº§åç§°": "ç¬”è®°æœ¬ç”µè„‘",
                "èµ„äº§ç±»åˆ«": "ç”µå­è®¾å¤‡",
                "è´­ç½®æ—¥æœŸ": "2023-02-20",
                "åŸå€¼": 5500.00,
                "ç´¯è®¡æŠ˜æ—§": 458.33,
                "å‡€å€¼": 5041.67,
                "ä½¿ç”¨éƒ¨é—¨": "æŠ€æœ¯éƒ¨",
                "èµ„äº§çŠ¶æ€": "åœ¨ç”¨"
            }
        ]
        
        # ç¤ºä¾‹å®ç‰©æ•°æ®
        sample_physical = [
            {
                "å®ç‰©ç¼–å·": "PA001",
                "å®ç‰©åç§°": "åŠå…¬æ¡Œ",
                "è§„æ ¼å‹å·": "1.2m*0.6m",
                "å­˜æ”¾ä½ç½®": "åŠå…¬å®¤101",
                "è´£ä»»äºº": "å¼ ä¸‰",
                "ç›˜ç‚¹æ—¥æœŸ": "2023-12-01",
                "å®ç‰©çŠ¶æ€": "æ­£å¸¸",
                "å¤‡æ³¨": "çŠ¶æ€è‰¯å¥½"
            },
            {
                "å®ç‰©ç¼–å·": "PA002",
                "å®ç‰©åç§°": "ç¬”è®°æœ¬ç”µè„‘", 
                "è§„æ ¼å‹å·": "ThinkPad E14",
                "å­˜æ”¾ä½ç½®": "æŠ€æœ¯éƒ¨",
                "è´£ä»»äºº": "æå››",
                "ç›˜ç‚¹æ—¥æœŸ": "2023-12-01", 
                "å®ç‰©çŠ¶æ€": "æ­£å¸¸",
                "å¤‡æ³¨": "è¿è¡Œæ­£å¸¸"
            }
        ]
        
        # æä¾›ä¸‹è½½é“¾æ¥
        financial_json = json.dumps(sample_financial, ensure_ascii=False, indent=2)
        physical_json = json.dumps(sample_physical, ensure_ascii=False, indent=2)
        
        st.sidebar.download_button(
            "ğŸ“¥ ä¸‹è½½è´¢åŠ¡æ•°æ®æ¨¡æ¿",
            financial_json,
            "financial_data.json",
            "application/json",
            key="download_financial"
        )
        
        st.sidebar.download_button(
            "ğŸ“¥ ä¸‹è½½å®ç‰©æ•°æ®æ¨¡æ¿", 
            physical_json,
            "physical_data.json",
            "application/json",
            key="download_physical"
        )
        
        st.sidebar.success("âœ… ç¤ºä¾‹æ•°æ®å·²ç”Ÿæˆï¼Œè¯·ä¸‹è½½å¹¶ä¸Šä¼ åˆ°GitHub")
# ========== é…ç½®å’Œå¸¸é‡ ==========

# æ•°æ®æ–‡ä»¶è·¯å¾„
FINANCIAL_DATA_FILE = "financial_data.json"
PHYSICAL_DATA_FILE = "physical_data.json"
MAPPING_DATA_FILE = "mapping_data.json"

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="èµ„äº§æ˜ å°„å…³ç³»æŸ¥è¯¢",
    page_icon="ğŸ”—",
    layout="wide",
    initial_sidebar_state="expanded"
)


# ========== æ•°æ®å¤„ç†å‡½æ•° ==========
def clean_data_for_json(data):
    """æ¸…ç†æ•°æ®ä»¥ä¾¿JSONåºåˆ—åŒ–"""
    import numpy as np

    def clean_value(value):
        """æ¸…ç†å•ä¸ªå€¼"""
        # å¤„ç†NaNå€¼
        if pd.isna(value):
            return None
        # å¤„ç†numpyç±»å‹
        if isinstance(value, (np.integer, np.int64, np.int32)):
            return int(value)
        elif isinstance(value, (np.floating, np.float64, np.float32)):
            if np.isnan(value):
                return None
            return float(value)
        elif isinstance(value, np.bool_):
            return bool(value)
        elif isinstance(value, np.ndarray):
            return value.tolist()
        # å¤„ç†å­—ç¬¦ä¸²
        elif isinstance(value, str):
            return value.strip() if value.strip() else ""
        # å…¶ä»–ç±»å‹è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        elif value is None:
            return None
        else:
            try:
                return str(value)
            except:
                return ""

    def clean_record(record):
        """æ¸…ç†å•æ¡è®°å½•"""
        if isinstance(record, dict):
            cleaned = {}
            for key, value in record.items():
                cleaned_key = str(key) if key is not None else ""
                cleaned_value = clean_value(value)
                if cleaned_key:  # åªä¿ç•™éç©ºé”®
                    cleaned[cleaned_key] = cleaned_value
            return cleaned
        else:
            return clean_value(record)

    # æ¸…ç†æ•´ä¸ªæ•°æ®åˆ—è¡¨
    if isinstance(data, list):
        return [clean_record(record) for record in data]
    else:
        return clean_record(data)

    """ä¿å­˜æ•°æ®åˆ°JSONæ–‡ä»¶"""
    try:
        # âœ… æ·»åŠ ï¼šæ•°æ®éªŒè¯
        if not isinstance(data, list):
            st.error(f"âŒ æ•°æ®æ ¼å¼é”™è¯¯ï¼šæœŸæœ›åˆ—è¡¨æ ¼å¼ï¼Œå®é™…ä¸º {type(data)}")
            return False

        # âœ… æ·»åŠ ï¼šæ¸…ç†æ•°æ®ä¸­çš„NaNå€¼
        cleaned_data = clean_data_for_json(data)

        # âœ… æ·»åŠ ï¼šåˆ›å»ºå¤‡ä»½
        if os.path.exists(filename):
            backup_name = f"{filename}.backup"
            try:
                with open(filename, 'r', encoding='utf-8') as f:
                    backup_data = f.read()
                with open(backup_name, 'w', encoding='utf-8') as f:
                    f.write(backup_data)
            except:
                pass  # å¤‡ä»½å¤±è´¥ä¸å½±å“ä¸»æµç¨‹

        # ä¿å­˜æ¸…ç†åçš„æ•°æ®
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(cleaned_data, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        st.error(f"âŒ ä¿å­˜æ•°æ®å¤±è´¥ ({filename}): {str(e)}")
        return False
def save_data(data, filename):
    """ä¿å­˜æ•°æ® - ä¼˜å…ˆGitHubå­˜å‚¨"""
    # å…ˆå°è¯•GitHubå­˜å‚¨
    if save_data_to_github(data, filename):
        # GitHubä¿å­˜æˆåŠŸï¼ŒåŒæ—¶ä¿å­˜æœ¬åœ°å¤‡ä»½
        try:
            cleaned_data = clean_data_for_json(data)
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(cleaned_data, f, ensure_ascii=False, indent=2)
        except:
            pass  # æœ¬åœ°å¤‡ä»½å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
        return True
    
    # GitHubå¤±è´¥ï¼Œå°è¯•æœ¬åœ°å­˜å‚¨
    try:
        cleaned_data = clean_data_for_json(data)
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(cleaned_data, f, ensure_ascii=False, indent=2)
        st.warning("âš ï¸ æ•°æ®å·²ä¿å­˜åˆ°æœ¬åœ°ï¼ˆGitHubä¸å¯ç”¨ï¼‰")
        return True
    except Exception as e:
        st.error(f"âŒ ä¿å­˜å¤±è´¥: {str(e)}")
        return False

def load_data(filename):
    """åŠ è½½æ•°æ® - ä¼˜å…ˆGitHubå­˜å‚¨"""
    # å…ˆå°è¯•ä»GitHubåŠ è½½
    github_data = load_data_from_github(filename)
    if github_data:
        return github_data
    
    # GitHubå¤±è´¥ï¼Œå°è¯•æœ¬åœ°åŠ è½½
    try:
        if os.path.exists(filename):
            with open(filename, 'r', encoding='utf-8') as f:
                data = json.load(f)
                st.info(f"ğŸ“ ä»æœ¬åœ°åŠ è½½æ•°æ®: {filename} ({len(data)} æ¡è®°å½•)")
                return data
        return []
    except Exception as e:
        st.error(f"âŒ åŠ è½½æ•°æ®å¤±è´¥: {str(e)}")
        return []

def parse_excel_file(uploaded_file, sheet_name=None):
    """è§£æExcelæ–‡ä»¶"""
    try:
        if sheet_name:
            df = pd.read_excel(uploaded_file, sheet_name=sheet_name)
        else:
            df = pd.read_excel(uploaded_file)

        # æ¸…ç†æ•°æ®
        df = df.dropna(how='all')  # åˆ é™¤å®Œå…¨ç©ºç™½çš„è¡Œ
        df = df.fillna('')  # å¡«å……ç©ºå€¼

        # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
        return df.to_dict('records')
    except Exception as e:
        st.error(f"è§£æExcelæ–‡ä»¶å¤±è´¥: {str(e)}")
        return None


def create_data_index(data, key_field):
    """åˆ›å»ºæ•°æ®ç´¢å¼•ä»¥æé«˜æŸ¥è¯¢æ•ˆç‡"""
    index = {}
    for record in data:
        key = record.get(key_field)
        if key:
            index[str(key)] = record
    return index


def create_mapping_index(mapping_data):
    """
    åˆ›å»ºæ˜ å°„ç´¢å¼•
    è¿”å›ä¸¤ä¸ªå­—å…¸ï¼š
    - financial_to_physical_mapping: 'èµ„äº§ç¼–å·+åºå·' -> ['å›ºå®šèµ„äº§ç¼–ç 'åˆ—è¡¨]
    - physical_to_financial_mapping: 'å›ºå®šèµ„äº§ç¼–ç ' -> ['èµ„äº§ç¼–å·+åºå·'åˆ—è¡¨]
    """
    financial_to_physical_mapping = {}  # è´¢åŠ¡ç³»ç»Ÿä¸»é”®åˆ°å®ç‰©å°è´¦ä¸»é”®çš„æ˜ å°„
    physical_to_financial_mapping = {}  # å®ç‰©å°è´¦ä¸»é”®åˆ°è´¢åŠ¡ç³»ç»Ÿä¸»é”®çš„æ˜ å°„

    for mapping in mapping_data:
        financial_key = str(mapping.get("èµ„äº§ç¼–å·+åºå·", "")).strip()  # è´¢åŠ¡ç³»ç»Ÿä¸»é”®
        physical_key = str(mapping.get("å›ºå®šèµ„äº§ç¼–ç ", "")).strip()    # å®ç‰©å°è´¦ä¸»é”®

        if (pd.notna(financial_key) and pd.notna(physical_key) and
                str(financial_key).strip() and str(physical_key).strip()):
            # è´¢åŠ¡ç³»ç»Ÿåˆ°å®ç‰©å°è´¦çš„æ˜ å°„
            if financial_key not in financial_to_physical_mapping:
                financial_to_physical_mapping[financial_key] = []
            if physical_key not in financial_to_physical_mapping[financial_key]:
                financial_to_physical_mapping[financial_key].append(physical_key)

            # å®ç‰©å°è´¦åˆ°è´¢åŠ¡ç³»ç»Ÿçš„æ˜ å°„
            if physical_key not in physical_to_financial_mapping:
                physical_to_financial_mapping[physical_key] = []
            if financial_key not in physical_to_financial_mapping[physical_key]:
                physical_to_financial_mapping[physical_key].append(financial_key)

    return financial_to_physical_mapping, physical_to_financial_mapping


def safe_get_value(record, key, default=0):
    """å®‰å…¨è·å–æ•°å€¼ï¼Œå¤„ç†å¯èƒ½çš„ç±»å‹è½¬æ¢é—®é¢˜ - é€šç”¨å¢å¼ºç‰ˆ"""
    try:
        # æ ¹æ®å®é™…Excelå­—æ®µï¼Œå°è¯•å¤šä¸ªå¯èƒ½çš„å­—æ®µå
        value = None

        # ğŸ”§ æ–°å¢ï¼šèµ„äº§åç§°å­—æ®µå¤„ç†
        if key == "èµ„äº§åç§°":
            # è´¢åŠ¡ç³»ç»Ÿèµ„äº§åç§°å­—æ®µ
            for field in ["èµ„äº§åç§°", "å›ºå®šèµ„äº§åç§°", "èµ„äº§å", "åç§°", "è®¾å¤‡åç§°"]:
                if field in record and record[field] is not None:
                    return str(record[field]).strip()
            return str(default)

        elif key == "å›ºå®šèµ„äº§åç§°":
            # å®ç‰©ç³»ç»Ÿèµ„äº§åç§°å­—æ®µ
            for field in ["å›ºå®šèµ„äº§åç§°", "èµ„äº§åç§°", "è®¾å¤‡åç§°", "åç§°", "èµ„äº§å"]:
                if field in record and record[field] is not None:
                    return str(record[field]).strip()
            return str(default)

        # ç‰¹å®šå­—æ®µçš„æ˜ å°„å¤„ç†
        elif key == "èµ„äº§ä»·å€¼":
            # è´¢åŠ¡ç³»ç»Ÿå¯èƒ½çš„å­—æ®µå
            for field in ["èµ„äº§ä»·å€¼", "è´¦é¢ä»·å€¼", "èµ„äº§å‡€é¢", "å›ºå®šèµ„äº§åŸå€¼", "åŸä»·", "åŸå€¼"]:
                if field in record and record[field] is not None:
                    value = record[field]
                    break
        elif key == "å›ºå®šèµ„äº§åŸå€¼":
            # å®ç‰©å°è´¦å¯èƒ½çš„å­—æ®µå
            for field in ["å›ºå®šèµ„äº§åŸå€¼", "èµ„äº§ä»·å€¼", "åŸå€¼", "èµ„äº§åŸå€¼", "åŸä»·", "è´­ç½®ä»·å€¼"]:
                if field in record and record[field] is not None:
                    value = record[field]
                    break
        elif key == "ç´¯è®¡æŠ˜æ—§":
            # ç´¯è®¡æŠ˜æ—§å­—æ®µçš„å¯èƒ½åç§°ï¼ˆè´¢åŠ¡å’Œå®ç‰©é€šç”¨ï¼‰
            for field in ["ç´¯è®¡æŠ˜æ—§", "ç´¯è®¡æ‘Šé”€", "æŠ˜æ—§ç´¯è®¡", "å·²è®¡ææŠ˜æ—§", "æŠ˜æ—§é‡‘é¢", "ç´¯è®¡æŠ˜æ—§é¢", "æŠ˜æ—§åˆè®¡"]:
                if field in record and record[field] is not None:
                    value = record[field]
                    break
            # å¦‚æœè¿˜æ²¡æ‰¾åˆ°ï¼Œå°è¯•æ¨¡ç³ŠåŒ¹é…
            if value is None:
                for field_name, field_value in record.items():
                    if field_value is not None and ("æŠ˜æ—§" in str(field_name) or "æ‘Šé”€" in str(field_name)):
                        # æ’é™¤æ˜æ˜¾ä¸æ˜¯ç´¯è®¡æŠ˜æ—§çš„å­—æ®µ
                        if not any(
                                exclude in str(field_name) for exclude in ["ç‡", "å¹´é™", "æ–¹æ³•", "æ”¿ç­–", "è¯´æ˜"]):
                            value = field_value
                            break
        elif key == "å‡€é¢" or key == "å‡€å€¼":
            # å‡€å€¼å­—æ®µçš„å¯èƒ½åç§°ï¼ˆä¸»è¦ç”¨äºè´¢åŠ¡ç³»ç»Ÿï¼‰
            for field in ["å‡€é¢", "å‡€å€¼", "è´¦é¢å‡€å€¼", "èµ„äº§å‡€å€¼", "å›ºå®šèµ„äº§å‡€å€¼", "è´¦é¢ä»·å€¼", "å‡€èµ„äº§"]:
                if field in record and record[field] is not None:
                    value = record[field]
                    break
        else:
            # ç›´æ¥è·å–å­—æ®µå€¼
            value = record.get(key, default)

        # è°ƒç”¨é€šç”¨æ•°å€¼è½¬æ¢å‡½æ•°
        return convert_to_number(value, default)

    except Exception:
        # å¦‚æœå‡ºç°ä»»ä½•å¼‚å¸¸ï¼Œè¿”å›é»˜è®¤å€¼
        return default


def convert_to_number(value, default=0):
    """é€šç”¨æ•°å€¼è½¬æ¢å‡½æ•°ï¼Œå¤„ç†å„ç§å¯èƒ½çš„æ•°å€¼æ ¼å¼"""
    try:
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å€¼ï¼Œè¿”å›é»˜è®¤å€¼
        if value is None or value == "":
            return default

        # å¤„ç†pandasçš„NaNå€¼
        if pd.isna(value):
            return default

        # å¦‚æœå·²ç»æ˜¯æ•°å­—ç±»å‹
        if isinstance(value, (int, float)):
            return float(value) if not pd.isna(value) else default

        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œè¿›è¡Œæ¸…ç†å’Œè½¬æ¢
        if isinstance(value, str):
            # ç§»é™¤å¸¸è§çš„éæ•°å­—å­—ç¬¦
            cleaned_value = value.strip()

            # å¤„ç†å¸¸è§çš„æ–‡æœ¬æƒ…å†µ
            if cleaned_value.lower() in ['', '-', 'nan', 'null', 'none', 'æ— ', 'ç©º', 'n/a', '#n/a', '#value!',
                                         '#div/0!']:
                return default

            # ç§»é™¤è´§å¸ç¬¦å·å’Œæ ¼å¼å­—ç¬¦
            cleaned_value = cleaned_value.replace(',', '').replace('Â¥', '').replace('ï¿¥', '').replace('$', '').replace(
                'â‚¬', '')
            cleaned_value = cleaned_value.replace('ï¼Œ', '').replace(' ', '').replace('\t', '').replace('\n', '')
            cleaned_value = cleaned_value.replace('å…ƒ', '').replace('ä¸‡å…ƒ', '0000').replace('åƒå…ƒ', '000')

            # å¤„ç†æ‹¬å·è¡¨ç¤ºè´Ÿæ•°çš„æƒ…å†µ (1,000.00) -> -1000.00
            if cleaned_value.startswith('(') and cleaned_value.endswith(')'):
                cleaned_value = '-' + cleaned_value[1:-1]

            # å¤„ç†ç™¾åˆ†å·
            if cleaned_value.endswith('%'):
                try:
                    return float(cleaned_value[:-1]) / 100
                except ValueError:
                    pass

            # å°è¯•è½¬æ¢ä¸ºæµ®ç‚¹æ•°
            try:
                return float(cleaned_value)
            except ValueError:
                # å¦‚æœåŒ…å«å…¶ä»–æ–‡å­—ï¼Œå°è¯•æå–æ•°å­—éƒ¨åˆ†
                import re
                # åŒ¹é…æ•°å­—ï¼ˆåŒ…æ‹¬å°æ•°ç‚¹å’Œè´Ÿå·ï¼‰
                number_match = re.search(r'-?\d+(?:\.\d+)?', cleaned_value)
                if number_match:
                    return float(number_match.group())
                else:
                    return default

        # å…¶ä»–ç±»å‹å°è¯•ç›´æ¥è½¬æ¢
        try:
            return float(value)
        except (ValueError, TypeError):
            return default

    except Exception:
        # å¦‚æœå‡ºç°ä»»ä½•å¼‚å¸¸ï¼Œè¿”å›é»˜è®¤å€¼
        return default


def is_numeric_field(field_name, sample_values):
    """åˆ¤æ–­å­—æ®µæ˜¯å¦ä¸ºæ•°å€¼ç±»å‹å­—æ®µ"""
    # æ˜ç¡®çš„æ•°å€¼å­—æ®µå…³é”®è¯
    numeric_keywords = [
        'ä»·å€¼', 'é‡‘é¢', 'åŸå€¼', 'å‡€å€¼', 'å‡€é¢', 'æŠ˜æ—§', 'æ‘Šé”€',
        'æˆæœ¬', 'è´¹ç”¨', 'æ”¶å…¥', 'åˆ©æ¶¦', 'èµ„äº§', 'è´Ÿå€º', 'æƒç›Š',
        'æ•°é‡', 'å•ä»·', 'æ€»ä»·', 'åˆè®¡', 'å°è®¡', 'ä½™é¢', 'ç»“ä½™',
        'é¢ç§¯', 'é•¿åº¦', 'é‡é‡', 'å®¹é‡', 'åŠŸç‡', 'ç”µå‹', 'ç”µæµ',
        'å¹´é™', 'æœˆæ•°', 'å¤©æ•°', 'æ¯”ç‡', 'ç‡', 'ç™¾åˆ†æ¯”', '%'
    ]

    # æ£€æŸ¥å­—æ®µåæ˜¯å¦åŒ…å«æ•°å€¼å…³é”®è¯
    field_name_lower = field_name.lower()
    for keyword in numeric_keywords:
        if keyword in field_name_lower:
            return True

    # æ£€æŸ¥æ ·æœ¬å€¼æ˜¯å¦ä¸»è¦ä¸ºæ•°å€¼ç±»å‹
    if not sample_values:
        return False

    numeric_count = 0
    total_count = len(sample_values)

    for value in sample_values[:min(10, total_count)]:  # æ£€æŸ¥å‰10ä¸ªæ ·æœ¬
        if value is None or value == "":
            continue

        # å°è¯•è½¬æ¢ä¸ºæ•°å€¼
        converted = convert_to_number(value, None)
        if converted is not None:
            numeric_count += 1

    # å¦‚æœè¶…è¿‡60%çš„æ ·æœ¬å¯ä»¥è½¬æ¢ä¸ºæ•°å€¼ï¼Œåˆ™è®¤ä¸ºæ˜¯æ•°å€¼å­—æ®µ
    return numeric_count / max(1, total_count) > 0.6


def auto_detect_and_convert_numeric_fields(data):
    """è‡ªåŠ¨æ£€æµ‹å¹¶è½¬æ¢æ•°å€¼å­—æ®µ"""
    if not data:
        return data

    # è·å–æ‰€æœ‰å­—æ®µå
    all_fields = set()
    for record in data[:100]:  # æ£€æŸ¥å‰100æ¡è®°å½•ä»¥ç¡®å®šå­—æ®µ
        all_fields.update(record.keys())

    # æ£€æµ‹æ•°å€¼å­—æ®µ
    numeric_fields = {}
    for field in all_fields:
        # æ”¶é›†è¯¥å­—æ®µçš„æ ·æœ¬å€¼
        sample_values = []
        for record in data[:20]:  # å–å‰20æ¡è®°å½•ä½œä¸ºæ ·æœ¬
            if field in record:
                sample_values.append(record[field])

        if is_numeric_field(field, sample_values):
            numeric_fields[field] = True

    # è½¬æ¢æ•°å€¼å­—æ®µ
    converted_data = []
    for record in data:
        new_record = {}
        for key, value in record.items():
            if key in numeric_fields:
                # è½¬æ¢ä¸ºæ•°å€¼
                new_record[key] = convert_to_number(value, 0)
            else:
                # ä¿æŒåŸå€¼
                new_record[key] = value
        converted_data.append(new_record)

    return converted_data, numeric_fields


# ========== é¡µé¢å‡½æ•° ==========

def data_import_page():
    """æ•°æ®å¯¼å…¥é¡µé¢ - å¢åŠ åˆ é™¤æ•°æ®åŠŸèƒ½"""
    st.header("ğŸ“¥ æ•°æ®å¯¼å…¥ç®¡ç†")

    st.info("ğŸ’¡ **æ˜ å°„è§„åˆ™è¯´æ˜**ï¼šè´¢åŠ¡ç³»ç»Ÿçš„'èµ„äº§ç¼–å·+åºå·' â†” å®ç‰©å°è´¦çš„'å›ºå®šèµ„äº§ç¼–ç 'ï¼ˆå¤šå¯¹å¤šå…³ç³»ï¼‰")

    # åˆ›å»ºå››ä¸ªæ ‡ç­¾é¡µ
    tab1, tab2, tab3, tab4 = st.tabs(["è´¢åŠ¡ç³»ç»Ÿæ•°æ®", "å®ç‰©å°è´¦æ•°æ®", "æ˜ å°„å…³ç³»æ•°æ®", "ğŸ—‘ï¸ æ•°æ®åˆ é™¤"])

    with tab1:
        st.subheader("ğŸ’° è´¢åŠ¡ç³»ç»Ÿæ˜ç»†è´¦æ•°æ®")
        st.markdown("**å¿…éœ€å­—æ®µ**ï¼š`èµ„äº§ç¼–å·+åºå·`ã€`èµ„äº§åç§°`ã€`èµ„äº§ä»·å€¼`ç­‰")

        # æ˜¾ç¤ºå½“å‰æ•°æ®çŠ¶æ€
        current_financial = load_data(FINANCIAL_DATA_FILE)

        # âœ… æ·»åŠ ï¼šæ•°æ®éªŒè¯å’Œä¿®å¤
        if current_financial is None:
            current_financial = []
            st.warning("âš ï¸ è´¢åŠ¡æ•°æ®æ–‡ä»¶å¯èƒ½æŸåï¼Œå·²é‡ç½®ä¸ºç©º")
        elif not isinstance(current_financial, list):
            st.error("âŒ è´¢åŠ¡æ•°æ®æ ¼å¼é”™è¯¯ï¼Œåº”ä¸ºåˆ—è¡¨æ ¼å¼")
            current_financial = []

        if current_financial:
            st.success(f"âœ… å½“å‰å·²æœ‰ {len(current_financial)} æ¡è´¢åŠ¡èµ„äº§è®°å½•")

            # æ˜¾ç¤ºå®Œæ•´å½“å‰æ•°æ®
            with st.expander("ğŸ“Š æŸ¥çœ‹å½“å‰æ‰€æœ‰è´¢åŠ¡æ•°æ®", expanded=False):
                df_current = pd.DataFrame(current_financial)

                # æ·»åŠ æœç´¢åŠŸèƒ½
                search_term = st.text_input("ğŸ” æœç´¢è´¢åŠ¡æ•°æ®ï¼ˆæŒ‰èµ„äº§ç¼–å·æˆ–åç§°ï¼‰", key="search_financial_current")
                if search_term:
                    mask = df_current.astype(str).apply(
                        lambda x: x.str.contains(search_term, case=False, na=False)).any(axis=1)
                    df_filtered = df_current[mask]
                    st.write(f"æœç´¢ç»“æœï¼š{len(df_filtered)} æ¡è®°å½•")
                    st.dataframe(df_filtered, use_container_width=True, height=400)
                else:
                    st.dataframe(df_current, use_container_width=True, height=400)

                # æ•°æ®ç»Ÿè®¡
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("æ€»è®°å½•æ•°", len(df_current))
                with col2:
                    # âœ… ä¿®å¤ï¼šåªä»"èµ„äº§ä»·å€¼"å­—æ®µè®¡ç®—æ€»ä»·å€¼
                    if "èµ„äº§ä»·å€¼" in df_current.columns:
                        try:
                            total_value = 0.0
                            valid_count = 0
                            error_count = 0

                            # é€è¡Œå¤„ç†"èµ„äº§ä»·å€¼"å­—æ®µ
                            for _, row in df_current.iterrows():
                                asset_value = row["èµ„äº§ä»·å€¼"]
                                try:
                                    # ä½¿ç”¨å®‰å…¨è½¬æ¢å‡½æ•°
                                    converted_value = safe_convert_to_float(asset_value)
                                    if converted_value >= 0:  # æ¥å—0å’Œæ­£æ•°
                                        total_value += converted_value
                                        valid_count += 1
                                    else:
                                        error_count += 1
                                except:
                                    error_count += 1

                            # æ˜¾ç¤ºè®¡ç®—ç»“æœ
                            st.metric("æ€»èµ„äº§ä»·å€¼", f"Â¥{total_value:,.2f}")

                            # æ˜¾ç¤ºå¤„ç†ç»Ÿè®¡
                            if valid_count > 0:
                                success_rate = (valid_count / len(df_current)) * 100
                                st.success(f"âœ… æˆåŠŸå¤„ç† {valid_count}/{len(df_current)} æ¡è®°å½• ({success_rate:.1f}%)")

                                if error_count > 0:
                                    st.warning(f"âš ï¸ {error_count} æ¡è®°å½•çš„èµ„äº§ä»·å€¼å­—æ®µæ— æ³•è½¬æ¢ä¸ºæ•°å­—")
                            else:
                                st.error("âŒ æ‰€æœ‰èµ„äº§ä»·å€¼å­—æ®µéƒ½æ— æ³•è½¬æ¢ä¸ºæœ‰æ•ˆæ•°å­—")

                                # æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
                                with st.expander("ğŸ”§ èµ„äº§ä»·å€¼å­—æ®µé—®é¢˜åˆ†æ"):
                                    st.write("**å‰5æ¡è®°å½•çš„èµ„äº§ä»·å€¼å­—æ®µå†…å®¹ï¼š**")
                                    sample_data = df_current["èµ„äº§ä»·å€¼"].head(5).tolist()
                                    for i, value in enumerate(sample_data, 1):
                                        converted = safe_convert_to_float(value)
                                        st.write(f"{i}. åŸå€¼: `{value}` ({type(value).__name__}) â†’ è½¬æ¢å: {converted}")

                                    st.markdown("**å¯èƒ½çš„é—®é¢˜ï¼š**")
                                    st.markdown("- å­—æ®µåŒ…å«æ–‡æœ¬è€Œéæ•°å­—")
                                    st.markdown("- æ•°å­—æ ¼å¼ä¸æ ‡å‡†ï¼ˆå¦‚åŒ…å«ç‰¹æ®Šå­—ç¬¦ï¼‰")
                                    st.markdown("- å­—æ®µä¸ºç©ºå€¼æˆ–NaN")
                                    st.markdown("- æ•°å­—ä½¿ç”¨äº†ç‰¹æ®Šçš„åƒä½åˆ†éš”ç¬¦")

                        except Exception as e:
                            st.metric("æ€»èµ„äº§ä»·å€¼", "è®¡ç®—é”™è¯¯")
                            st.error(f"âŒ è®¡ç®—èµ„äº§ä»·å€¼æ—¶å‡ºé”™: {str(e)}")

                            with st.expander("ğŸš¨ é”™è¯¯è¯¦æƒ…"):
                                st.code(f"é”™è¯¯ç±»å‹: {type(e).__name__}\né”™è¯¯ä¿¡æ¯: {str(e)}")
                                if len(df_current) > 0:
                                    st.write("æ•°æ®æ ·æœ¬ï¼š", df_current["èµ„äº§ä»·å€¼"].head(3).tolist())
                    else:
                        st.metric("æ€»èµ„äº§ä»·å€¼", "å­—æ®µç¼ºå¤±")
                        st.error("âŒ æ•°æ®ä¸­æ²¡æœ‰èµ„äº§ä»·å€¼å­—æ®µ")

                        with st.expander("ğŸ“‹ å½“å‰æ•°æ®å­—æ®µåˆ—è¡¨"):
                            st.write("**ç°æœ‰å­—æ®µï¼š**")
                            for i, col in enumerate(df_current.columns, 1):
                                st.write(f"{i}. `{col}`")

                            st.info("ğŸ’¡ è¯·ç¡®ä¿Excelæ–‡ä»¶ä¸­æœ‰åä¸ºèµ„äº§ä»·å€¼çš„åˆ—")

                with col3:
                    if "éƒ¨é—¨åç§°" in df_current.columns:
                        dept_count = df_current["éƒ¨é—¨åç§°"].nunique()
                        st.metric("æ¶‰åŠéƒ¨é—¨æ•°", dept_count)

            # ğŸ—‘ï¸ å¿«é€Ÿåˆ é™¤åŠŸèƒ½
            st.markdown("---")
            with st.expander("ğŸ—‘ï¸ è´¢åŠ¡æ•°æ®å¿«é€Ÿåˆ é™¤", expanded=False):
                st.warning("âš ï¸ **æ³¨æ„**ï¼šåˆ é™¤æ“ä½œä¸å¯æ¢å¤ï¼Œè¯·è°¨æ…æ“ä½œï¼")

                col1, col2, col3 = st.columns(3)
                with col1:
                    # æŒ‰æ¡ä»¶åˆ é™¤
                    st.markdown("**ğŸ¯ æ¡ä»¶åˆ é™¤**")
                    delete_condition = st.selectbox(
                        "é€‰æ‹©åˆ é™¤æ¡ä»¶",
                        ["é€‰æ‹©æ¡ä»¶...", "èµ„äº§ä»·å€¼ä¸º0", "èµ„äº§åç§°ä¸ºç©º", "éƒ¨é—¨åç§°ä¸ºç©º", "è‡ªå®šä¹‰æ¡ä»¶"],
                        key="financial_delete_condition"
                    )

                    if delete_condition == "è‡ªå®šä¹‰æ¡ä»¶":
                        custom_field = st.selectbox("é€‰æ‹©å­—æ®µ", df_current.columns.tolist(),
                                                    key="financial_custom_field")
                        custom_value = st.text_input("è¾“å…¥è¦åˆ é™¤çš„å€¼", key="financial_custom_value")

                        if st.button("ğŸ—‘ï¸ æ‰§è¡Œæ¡ä»¶åˆ é™¤", key="financial_condition_delete"):
                            if custom_value:
                                original_count = len(current_financial)
                                filtered_data = [
                                    record for record in current_financial
                                    if str(record.get(custom_field, "")) != custom_value
                                ]
                                save_data(filtered_data, FINANCIAL_DATA_FILE)
                                deleted_count = original_count - len(filtered_data)
                                st.success(f"âœ… å·²åˆ é™¤ {deleted_count} æ¡è®°å½•")
                                st.rerun()

                    elif delete_condition != "é€‰æ‹©æ¡ä»¶..." and st.button("ğŸ—‘ï¸ æ‰§è¡Œæ¡ä»¶åˆ é™¤",
                                                                         key="financial_preset_delete"):
                        original_count = len(current_financial)
                        if delete_condition == "èµ„äº§ä»·å€¼ä¸º0":
                            filtered_data = [
                                record for record in current_financial
                                if safe_convert_to_float(record.get("èµ„äº§ä»·å€¼", 0)) != 0
                            ]
                        elif delete_condition == "èµ„äº§åç§°ä¸ºç©º":
                            filtered_data = [
                                record for record in current_financial
                                if str(record.get("èµ„äº§åç§°", "")).strip() != ""
                            ]
                        elif delete_condition == "éƒ¨é—¨åç§°ä¸ºç©º":
                            filtered_data = [
                                record for record in current_financial
                                if str(record.get("éƒ¨é—¨åç§°", "")).strip() != ""
                            ]

                        save_data(filtered_data, FINANCIAL_DATA_FILE)
                        deleted_count = original_count - len(filtered_data)
                        st.success(f"âœ… å·²åˆ é™¤ {deleted_count} æ¡è®°å½•")
                        st.rerun()

                with col2:
                    # æŒ‰ç¼–å·åˆ é™¤
                    st.markdown("**ğŸ”¢ æŒ‰ç¼–å·åˆ é™¤**")
                    delete_codes = st.text_area(
                        "è¾“å…¥è¦åˆ é™¤çš„èµ„äº§ç¼–å·ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰",
                        height=100,
                        key="financial_delete_codes",
                        help="æ¯è¡Œè¾“å…¥ä¸€ä¸ªèµ„äº§ç¼–å·+åºå·"
                    )

                    if st.button("ğŸ—‘ï¸ åˆ é™¤æŒ‡å®šç¼–å·", key="financial_code_delete"):
                        if delete_codes.strip():
                            codes_to_delete = [code.strip() for code in delete_codes.split('\n') if code.strip()]
                            original_count = len(current_financial)
                            filtered_data = [
                                record for record in current_financial
                                if record.get("èµ„äº§ç¼–å·+åºå·", "") not in codes_to_delete
                            ]
                            save_data(filtered_data, FINANCIAL_DATA_FILE)
                            deleted_count = original_count - len(filtered_data)
                            st.success(f"âœ… å·²åˆ é™¤ {deleted_count} æ¡è®°å½•")
                            st.rerun()

                with col3:
                    # æ¸…ç©ºæ‰€æœ‰æ•°æ®
                    st.markdown("**ğŸš¨ å±é™©æ“ä½œ**")
                    st.error("âš ï¸ ä»¥ä¸‹æ“ä½œå°†æ¸…ç©ºæ‰€æœ‰è´¢åŠ¡æ•°æ®")

                    # åŒé‡ç¡®è®¤æœºåˆ¶
                    confirm_clear = st.checkbox("æˆ‘ç¡®è®¤è¦æ¸…ç©ºæ‰€æœ‰è´¢åŠ¡æ•°æ®", key="financial_confirm_clear")

                    if confirm_clear:
                        final_confirm = st.text_input(
                            "è¯·è¾“å…¥ 'DELETE ALL' ç¡®è®¤æ¸…ç©º",
                            key="financial_final_confirm"
                        )

                        if final_confirm == "DELETE ALL" and st.button("ğŸš¨ æ¸…ç©ºæ‰€æœ‰æ•°æ®", key="financial_clear_all"):
                            save_data([], FINANCIAL_DATA_FILE)
                            st.success("âœ… å·²æ¸…ç©ºæ‰€æœ‰è´¢åŠ¡æ•°æ®")
                            st.rerun()

        else:
            st.warning("âš ï¸ æš‚æ— è´¢åŠ¡ç³»ç»Ÿæ•°æ®")

        # æ–‡ä»¶ä¸Šä¼ éƒ¨åˆ†ä¿æŒä¸å˜
        financial_file = st.file_uploader(
            "ä¸Šä¼ è´¢åŠ¡ç³»ç»Ÿæ˜ç»†è´¦Excelæ–‡ä»¶",
            type=['xlsx', 'xls'],
            key="financial_upload",
            help="Excelæ–‡ä»¶åº”åŒ…å«'èµ„äº§ç¼–å·+åºå·'åˆ—ä½œä¸ºä¸»é”®"
        )

        if financial_file is not None:
            try:
                financial_df = pd.read_excel(financial_file)
                st.success(f"âœ… æˆåŠŸè¯»å–è´¢åŠ¡æ•°æ®: {len(financial_df)} è¡Œ x {len(financial_df.columns)} åˆ—")

                # æ£€æŸ¥å¿…éœ€å­—æ®µ
                required_columns = ["èµ„äº§ç¼–å·+åºå·"]
                missing_columns = []

                for col in required_columns:
                    if col not in financial_df.columns:
                        similar_cols = [c for c in financial_df.columns if "èµ„äº§ç¼–å·" in str(c) and "åºå·" in str(c)]
                        if not similar_cols:
                            similar_cols = [c for c in financial_df.columns if "ç¼–å·" in str(c)]

                        if similar_cols:
                            st.warning(f"âš ï¸ æœªæ‰¾åˆ°æ ‡å‡†åˆ—å'{col}'ï¼Œå‘ç°ç›¸ä¼¼åˆ—åï¼š{similar_cols}")
                            st.info("è¯·ç¡®ä¿Excelæ–‡ä»¶ä¸­æœ‰'èµ„äº§ç¼–å·+åºå·'åˆ—ï¼Œæˆ–æ‰‹åŠ¨é‡å‘½åç›¸åº”åˆ—")
                        else:
                            missing_columns.append(col)

                if missing_columns:
                    st.error(f"âŒ ç¼ºå°‘å¿…éœ€å­—æ®µï¼š{missing_columns}")
                    st.stop()

                # æ˜¾ç¤ºå®Œæ•´ä¸Šä¼ æ•°æ®é¢„è§ˆ
                st.subheader("ğŸ“Š ä¸Šä¼ æ•°æ®å®Œæ•´é¢„è§ˆ")

                search_upload = st.text_input("ğŸ” æœç´¢ä¸Šä¼ æ•°æ®", key="search_financial_upload")
                if search_upload:
                    mask = financial_df.astype(str).apply(
                        lambda x: x.str.contains(search_upload, case=False, na=False)).any(axis=1)
                    df_filtered = financial_df[mask]
                    st.write(f"æœç´¢ç»“æœï¼š{len(df_filtered)} æ¡è®°å½•")
                    st.dataframe(df_filtered, use_container_width=True, height=500)
                else:
                    st.dataframe(financial_df, use_container_width=True, height=500)

                # æ•°æ®è´¨é‡æ£€æŸ¥
                st.subheader("ğŸ” æ•°æ®è´¨é‡æ£€æŸ¥")

                col1, col2, col3 = st.columns(3)
                with col1:
                    asset_codes = financial_df["èµ„äº§ç¼–å·+åºå·"].dropna()
                    duplicate_codes = asset_codes[asset_codes.duplicated()].unique()

                    if len(duplicate_codes) > 0:
                        st.error(f"âŒ é‡å¤ç¼–å·: {len(duplicate_codes)} ä¸ª")
                        with st.expander("æŸ¥çœ‹é‡å¤è®°å½•"):
                            duplicate_records = financial_df[financial_df["èµ„äº§ç¼–å·+åºå·"].isin(duplicate_codes)]
                            st.dataframe(duplicate_records, use_container_width=True)
                    else:
                        st.success("âœ… ç¼–å·å”¯ä¸€æ€§é€šè¿‡")

                with col2:
                    null_counts = financial_df.isnull().sum()
                    total_nulls = null_counts.sum()
                    if total_nulls > 0:
                        st.warning(f"âš ï¸ ç©ºå€¼: {total_nulls} ä¸ª")
                        with st.expander("æŸ¥çœ‹ç©ºå€¼ç»Ÿè®¡"):
                            st.dataframe(null_counts[null_counts > 0].to_frame("ç©ºå€¼æ•°é‡"), use_container_width=True)
                    else:
                        st.success("âœ… æ— ç©ºå€¼")

                with col3:
                    if "èµ„äº§ä»·å€¼" in financial_df.columns:
                        total_value = financial_df["èµ„äº§ä»·å€¼"].sum()
                        st.metric("æ€»ä»·å€¼", f"{total_value:,.2f}")

                # å¯¼å…¥é€‰é¡¹
                st.markdown("---")
                st.subheader("ğŸ“¥ å¯¼å…¥é€‰é¡¹")

                import_mode = st.radio(
                    "é€‰æ‹©å¯¼å…¥æ¨¡å¼",
                    ["è¦†ç›–å¯¼å…¥ï¼ˆæ¸…ç©ºåŸæ•°æ®ï¼‰", "è¿½åŠ å¯¼å…¥ï¼ˆä¿ç•™åŸæ•°æ®ï¼‰", "æ›´æ–°å¯¼å…¥ï¼ˆæŒ‰ç¼–å·æ›´æ–°ï¼‰"],
                    key="financial_import_mode"
                )

                # å¯¼å…¥ç¡®è®¤
                col1, col2, col3 = st.columns(3)
                with col1:
                    if st.button("ğŸ’¾ ç¡®è®¤å¯¼å…¥è´¢åŠ¡æ•°æ®", type="primary", use_container_width=True):
                        # æ•°æ®æ ‡å‡†åŒ–å¤„ç†
                        processed_data = []
                        for _, row in financial_df.iterrows():
                            record = {}
                            # ç¡®ä¿ä¸»é”®å­—æ®µæ­£ç¡®
                            record["èµ„äº§ç¼–å·+åºå·"] = str(row.get("èµ„äº§ç¼–å·+åºå·", "")).strip()
                            record["åºå·"] = str(row.get("åºå·", "")).strip()
                            record["èµ„äº§ç¼–å·"] = str(row.get("èµ„äº§ç¼–å·", "")).strip()
                            record["èµ„äº§åç§°"] = str(row.get("èµ„äº§åç§°", "")).strip()

                            # âœ… ä¿®å¤ï¼šä½¿ç”¨å®‰å…¨çš„æ•°å€¼è½¬æ¢
                            record["èµ„äº§ä»·å€¼"] = safe_convert_to_float(row.get("èµ„äº§ä»·å€¼", 0))
                            record["è´¦é¢ä»·å€¼"] = safe_convert_to_float(row.get("è´¦é¢ä»·å€¼", 0))
                            record["èµ„äº§å‡€é¢"] = safe_convert_to_float(row.get("èµ„äº§å‡€é¢", 0))

                            record["éƒ¨é—¨åç§°"] = str(row.get("éƒ¨é—¨åç§°", "")).strip()
                            record["ä¿ç®¡äººåç§°"] = str(row.get("ä¿ç®¡äººåç§°", "")).strip()
                            record["èµ„äº§åˆ†ç±»"] = str(row.get("èµ„äº§åˆ†ç±»", "")).strip()

                            # âœ… ä¿®å¤ï¼šå®‰å…¨å¤„ç†æ‰€æœ‰å…¶ä»–å­—æ®µ
                            for col in financial_df.columns:
                                if col not in record:
                                    value = row.get(col)
                                    # æ¸…ç†NaNå€¼å’Œç‰¹æ®Šç±»å‹
                                    if pd.isna(value):
                                        record[col] = ""
                                    elif isinstance(value, (int, float)):
                                        if pd.isna(value):
                                            record[col] = 0
                                        else:
                                            record[col] = float(value) if not pd.isna(value) else 0
                                    else:
                                        record[col] = str(value).strip() if value is not None else ""

                            if record["èµ„äº§ç¼–å·+åºå·"]:
                                processed_data.append(record)

                        # æ ¹æ®å¯¼å…¥æ¨¡å¼å¤„ç†æ•°æ®
                        if import_mode == "è¦†ç›–å¯¼å…¥ï¼ˆæ¸…ç©ºåŸæ•°æ®ï¼‰":
                            save_data(processed_data, FINANCIAL_DATA_FILE)
                            st.success(f"âœ… è¦†ç›–å¯¼å…¥ {len(processed_data)} æ¡è´¢åŠ¡èµ„äº§è®°å½•")

                        elif import_mode == "è¿½åŠ å¯¼å…¥ï¼ˆä¿ç•™åŸæ•°æ®ï¼‰":
                            existing_data = load_data(FINANCIAL_DATA_FILE)
                            combined_data = existing_data + processed_data
                            save_data(combined_data, FINANCIAL_DATA_FILE)
                            st.success(f"âœ… è¿½åŠ å¯¼å…¥ {len(processed_data)} æ¡è®°å½•ï¼Œæ€»è®¡ {len(combined_data)} æ¡")

                        elif import_mode == "æ›´æ–°å¯¼å…¥ï¼ˆæŒ‰ç¼–å·æ›´æ–°ï¼‰":
                            existing_data = load_data(FINANCIAL_DATA_FILE)
                            existing_dict = {record.get("èµ„äº§ç¼–å·+åºå·"): record for record in existing_data}

                            # æ›´æ–°æˆ–æ·»åŠ æ–°è®°å½•
                            for record in processed_data:
                                existing_dict[record[("èµ„äº§ç¼–å·+åºå·")]] = record

                            updated_data = list(existing_dict.values())
                            save_data(updated_data, FINANCIAL_DATA_FILE)
                            st.success(f"âœ… æ›´æ–°å¯¼å…¥å®Œæˆï¼Œæ€»è®¡ {len(updated_data)} æ¡è®°å½•")

                        st.balloons()
                        time.sleep(2)
                        st.rerun()

                with col2:
                    if st.button("ğŸ“¥ å¯¼å‡ºå½“å‰æ•°æ®", use_container_width=True):
                        output = BytesIO()
                        with pd.ExcelWriter(output, engine='openpyxl') as writer:
                            financial_df.to_excel(writer, index=False, sheet_name='è´¢åŠ¡æ•°æ®')

                        st.download_button(
                            label="â¬‡ï¸ ä¸‹è½½Excelæ–‡ä»¶",
                            data=output.getvalue(),
                            file_name=f"è´¢åŠ¡æ•°æ®_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )

                with col3:
                    if st.button("ğŸ”„ é‡æ–°ä¸Šä¼ ", use_container_width=True):
                        st.rerun()

            except Exception as e:
                st.error(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥ï¼š{str(e)}")

    with tab2:
        st.subheader("ğŸ“¦ å®ç‰©å°è´¦æ•°æ®")
        st.markdown("**å¿…éœ€å­—æ®µ**ï¼š`å›ºå®šèµ„äº§ç¼–ç `ã€`å›ºå®šèµ„äº§åç§°`ã€`å›ºå®šèµ„äº§åŸå€¼`ç­‰")

        # æ˜¾ç¤ºå½“å‰æ•°æ®çŠ¶æ€
        current_physical = load_data(PHYSICAL_DATA_FILE)
        if current_physical:
            st.success(f"âœ… å½“å‰å·²æœ‰ {len(current_physical)} æ¡å®ç‰©èµ„äº§è®°å½•")

            # æ˜¾ç¤ºå®Œæ•´å½“å‰æ•°æ®
            with st.expander("ğŸ“Š æŸ¥çœ‹å½“å‰æ‰€æœ‰å®ç‰©æ•°æ®", expanded=False):
                df_current = pd.DataFrame(current_physical)

                search_term = st.text_input("ğŸ” æœç´¢å®ç‰©æ•°æ®ï¼ˆæŒ‰ç¼–ç æˆ–åç§°ï¼‰", key="search_physical_current")
                if search_term:
                    mask = df_current.astype(str).apply(
                        lambda x: x.str.contains(search_term, case=False, na=False)).any(axis=1)
                    df_filtered = df_current[mask]
                    st.write(f"æœç´¢ç»“æœï¼š{len(df_filtered)} æ¡è®°å½•")
                    st.dataframe(df_filtered, use_container_width=True, height=400)
                else:
                    st.dataframe(df_current, use_container_width=True, height=400)

                # æ•°æ®ç»Ÿè®¡
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("æ€»è®°å½•æ•°", len(df_current))

                with col2:
                    # âœ… ä¿®å¤ï¼šä½¿ç”¨å›ºå®šèµ„äº§åŸå€¼å­—æ®µè®¡ç®—æ€»ä»·å€¼ï¼Œæ”¯æŒæ ¸ç®—ç­›é€‰
                    if "å›ºå®šèµ„äº§åŸå€¼" in df_current.columns:
                        try:
                            # ğŸ†• æ–°å¢ï¼šæ£€æŸ¥æ˜¯å¦æœ‰æ ¸ç®—å­—æ®µ
                            has_accounting_field = "æ˜¯å¦æ ¸ç®—" in df_current.columns

                            # åŸå§‹è®¡ç®—ï¼ˆæ”¯æŒæ ¸ç®—ç­›é€‰ï¼‰
                            total_value_raw = 0.0
                            valid_count_raw = 0
                            error_count = 0
                            non_accounting_count = 0  # éæ ¸ç®—èµ„äº§æ•°é‡

                            for _, row in df_current.iterrows():
                                try:
                                    # ğŸ†• æ£€æŸ¥æ˜¯å¦æ ¸ç®—
                                    if has_accounting_field:
                                        accounting_status = str(row.get("æ˜¯å¦æ ¸ç®—", "")).strip()
                                        if accounting_status not in ["æ˜¯", "Y", "y", "Yes", "YES", "1", "True", "true"]:
                                            non_accounting_count += 1
                                            continue  # è·³è¿‡éæ ¸ç®—èµ„äº§

                                    value = safe_convert_to_float(row.get("å›ºå®šèµ„äº§åŸå€¼", 0))
                                    if value > 0:
                                        total_value_raw += value
                                        valid_count_raw += 1
                                    elif value == 0:
                                        pass  # ä»·å€¼ä¸º0çš„è®°å½•
                                    else:
                                        error_count += 1
                                except:
                                    error_count += 1

                            # å»é‡è®¡ç®—ï¼ˆæ”¯æŒæ ¸ç®—ç­›é€‰ï¼‰
                            df_deduped = df_current.drop_duplicates(subset=['å›ºå®šèµ„äº§ç¼–ç '], keep='first')
                            total_value_dedup = 0.0
                            valid_count_dedup = 0
                            non_accounting_dedup_count = 0

                            for _, row in df_deduped.iterrows():
                                try:
                                    # ğŸ†• æ£€æŸ¥æ˜¯å¦æ ¸ç®—
                                    if has_accounting_field:
                                        accounting_status = str(row.get("æ˜¯å¦æ ¸ç®—", "")).strip()
                                        if accounting_status not in ["æ˜¯", "Y", "y", "Yes", "YES", "1", "True", "true"]:
                                            non_accounting_dedup_count += 1
                                            continue  # è·³è¿‡éæ ¸ç®—èµ„äº§

                                    value = safe_convert_to_float(row.get("å›ºå®šèµ„äº§åŸå€¼", 0))
                                    if value > 0:
                                        total_value_dedup += value
                                        valid_count_dedup += 1
                                except:
                                    pass

                            # æ˜¾ç¤ºç»“æœ
                            duplicate_count = len(df_current) - len(df_deduped)

                            if duplicate_count > 0:
                                st.metric("å›ºå®šèµ„äº§åŸå€¼æ€»è®¡", f"Â¥{total_value_dedup:,.2f}")
                                caption_text = f"å»é‡åé‡‘é¢ï¼ˆåˆ é™¤{duplicate_count}æ¡é‡å¤ï¼‰"
                                if has_accounting_field and non_accounting_dedup_count > 0:
                                    caption_text += f" | å·²æ’é™¤{non_accounting_dedup_count}æ¡éæ ¸ç®—"
                                st.caption(caption_text)
                            else:
                                st.metric("å›ºå®šèµ„äº§åŸå€¼æ€»è®¡", f"Â¥{total_value_raw:,.2f}")
                                caption_text = "æ— é‡å¤è®°å½•"
                                if has_accounting_field and non_accounting_count > 0:
                                    caption_text += f" | å·²æ’é™¤{non_accounting_count}æ¡éæ ¸ç®—"
                                st.caption(caption_text)

                            # æ˜¾ç¤ºå¤„ç†ç»Ÿè®¡
                            effective_valid_count = valid_count_dedup if duplicate_count > 0 else valid_count_raw
                            effective_total_count = len(df_deduped) if duplicate_count > 0 else len(df_current)
                            effective_non_accounting = non_accounting_dedup_count if duplicate_count > 0 else non_accounting_count

                            if effective_valid_count > 0:
                                success_rate = (effective_valid_count / (
                                            effective_valid_count + effective_non_accounting + error_count)) * 100
                                st.success(
                                    f"âœ… æˆåŠŸå¤„ç† {effective_valid_count}/{effective_total_count} æ¡è®°å½• ({success_rate:.1f}%)")

                                if error_count > 0:
                                    st.warning(f"âš ï¸ {error_count} æ¡è®°å½•çš„å›ºå®šèµ„äº§åŸå€¼å­—æ®µæ— æ³•è½¬æ¢ä¸ºæ•°å­—")

                                # ğŸ†• æ˜¾ç¤ºæ ¸ç®—ç­›é€‰ç»Ÿè®¡
                                if has_accounting_field and effective_non_accounting > 0:
                                    st.info(f"ğŸ“Š å·²æ’é™¤ {effective_non_accounting} æ¡éæ ¸ç®—èµ„äº§")
                            else:
                                st.error("âŒ æ‰€æœ‰å›ºå®šèµ„äº§åŸå€¼å­—æ®µéƒ½æ— æ³•è½¬æ¢ä¸ºæœ‰æ•ˆæ•°å­—")

                            # å»é‡è®¡ç®—
                            df_deduped = df_current.drop_duplicates(subset=['å›ºå®šèµ„äº§ç¼–ç '], keep='first')
                            total_value_dedup = 0.0
                            valid_count_dedup = 0

                            for _, row in df_deduped.iterrows():
                                try:
                                    value = safe_convert_to_float(row.get("å›ºå®šèµ„äº§åŸå€¼", 0))
                                    if value > 0:
                                        total_value_dedup += value
                                        valid_count_dedup += 1
                                except:
                                    pass

                            # æ˜¾ç¤ºç»“æœ
                            duplicate_count = len(df_current) - len(df_deduped)

                            if duplicate_count > 0:
                                st.metric("å›ºå®šèµ„äº§åŸå€¼æ€»è®¡", f"Â¥{total_value_dedup:,.2f}")
                                st.caption(f"å»é‡åé‡‘é¢ï¼ˆåˆ é™¤{duplicate_count}æ¡é‡å¤ï¼‰")
                            else:
                                st.metric("å›ºå®šèµ„äº§åŸå€¼æ€»è®¡", f"Â¥{total_value_raw:,.2f}")
                                st.caption("æ— é‡å¤è®°å½•")

                            # æ˜¾ç¤ºå¤„ç†ç»Ÿè®¡
                            if valid_count_raw > 0:
                                success_rate = (valid_count_raw / len(df_current)) * 100
                                st.success(
                                    f"âœ… æˆåŠŸå¤„ç† {valid_count_raw}/{len(df_current)} æ¡è®°å½• ({success_rate:.1f}%)")

                                if error_count > 0:
                                    st.warning(f"âš ï¸ {error_count} æ¡è®°å½•çš„å›ºå®šèµ„äº§åŸå€¼å­—æ®µæ— æ³•è½¬æ¢ä¸ºæ•°å­—")
                            else:
                                st.error("âŒ æ‰€æœ‰å›ºå®šèµ„äº§åŸå€¼å­—æ®µéƒ½æ— æ³•è½¬æ¢ä¸ºæœ‰æ•ˆæ•°å­—")

                                # æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
                                with st.expander("ğŸ”§ å›ºå®šèµ„äº§åŸå€¼å­—æ®µé—®é¢˜åˆ†æ"):
                                    st.write("**å‰5æ¡è®°å½•çš„å›ºå®šèµ„äº§åŸå€¼å­—æ®µå†…å®¹ï¼š**")
                                    sample_data = df_current["å›ºå®šèµ„äº§åŸå€¼"].head(5).tolist()
                                    for i, value in enumerate(sample_data, 1):
                                        converted = safe_convert_to_float(value)
                                        st.write(f"{i}. åŸå€¼: `{value}` ({type(value).__name__}) â†’ è½¬æ¢å: {converted}")

                                    st.markdown("**å¯èƒ½çš„é—®é¢˜ï¼š**")
                                    st.markdown("- å­—æ®µåŒ…å«æ–‡æœ¬è€Œéæ•°å­—")
                                    st.markdown("- æ•°å­—æ ¼å¼ä¸æ ‡å‡†ï¼ˆå¦‚åŒ…å«ç‰¹æ®Šå­—ç¬¦ï¼‰")
                                    st.markdown("- å­—æ®µä¸ºç©ºå€¼æˆ–NaN")
                                    st.markdown("- æ•°å­—ä½¿ç”¨äº†ç‰¹æ®Šçš„åƒä½åˆ†éš”ç¬¦")

                        except Exception as e:
                            st.metric("å›ºå®šèµ„äº§åŸå€¼æ€»è®¡", "è®¡ç®—é”™è¯¯")
                            st.error(f"âŒ è®¡ç®—å›ºå®šèµ„äº§åŸå€¼æ—¶å‡ºé”™: {str(e)}")

                            with st.expander("ğŸš¨ é”™è¯¯è¯¦æƒ…"):
                                st.code(f"é”™è¯¯ç±»å‹: {type(e).__name__}\né”™è¯¯ä¿¡æ¯: {str(e)}")
                                if len(df_current) > 0:
                                    st.write("æ•°æ®æ ·æœ¬ï¼š", df_current["å›ºå®šèµ„äº§åŸå€¼"].head(3).tolist())

                    elif "èµ„äº§ä»·å€¼" in df_current.columns:
                        # å¤‡ç”¨ï¼šå¦‚æœæ²¡æœ‰å›ºå®šèµ„äº§åŸå€¼å­—æ®µï¼Œä½¿ç”¨èµ„äº§ä»·å€¼å­—æ®µ
                        st.warning("âš ï¸ æœªæ‰¾åˆ°'å›ºå®šèµ„äº§åŸå€¼'å­—æ®µï¼Œä½¿ç”¨'èµ„äº§ä»·å€¼'å­—æ®µ")
                        try:
                            total_value = sum(
                                safe_convert_to_float(row.get("èµ„äº§ä»·å€¼", 0)) for _, row in df_current.iterrows())
                            st.metric("èµ„äº§ä»·å€¼æ€»è®¡", f"Â¥{total_value:,.2f}")
                            st.caption("ä½¿ç”¨èµ„äº§ä»·å€¼å­—æ®µ")
                        except Exception as e:
                            st.metric("èµ„äº§ä»·å€¼æ€»è®¡", "è®¡ç®—é”™è¯¯")
                            st.error(f"âŒ è®¡ç®—èµ„äº§ä»·å€¼æ—¶å‡ºé”™: {str(e)}")

                    else:
                        st.metric("èµ„äº§ä»·å€¼æ€»è®¡", "å­—æ®µç¼ºå¤±")
                        st.error("âŒ æ•°æ®ä¸­æ²¡æœ‰'å›ºå®šèµ„äº§åŸå€¼'æˆ–'èµ„äº§ä»·å€¼'å­—æ®µ")

                        with st.expander("ğŸ“‹ å½“å‰æ•°æ®å­—æ®µåˆ—è¡¨"):
                            st.write("**ç°æœ‰å­—æ®µï¼š**")
                            for i, col in enumerate(df_current.columns, 1):
                                st.write(f"{i}. `{col}`")

                            st.info("ğŸ’¡ è¯·ç¡®ä¿Excelæ–‡ä»¶ä¸­æœ‰åä¸º'å›ºå®šèµ„äº§åŸå€¼'çš„åˆ—")

                with col3:
                    if "å­˜æ”¾éƒ¨é—¨" in df_current.columns:
                        dept_count = df_current["å­˜æ”¾éƒ¨é—¨"].nunique()
                        st.metric("æ¶‰åŠéƒ¨é—¨æ•°", dept_count)

            # ğŸ—‘ï¸ å®ç‰©æ•°æ®åˆ é™¤åŠŸèƒ½ï¼ˆä¿æŒä¸å˜ï¼‰
            st.markdown("---")
            with st.expander("ğŸ—‘ï¸ å®ç‰©æ•°æ®å¿«é€Ÿåˆ é™¤", expanded=False):
                st.warning("âš ï¸ **æ³¨æ„**ï¼šåˆ é™¤æ“ä½œä¸å¯æ¢å¤ï¼Œè¯·è°¨æ…æ“ä½œï¼")

                col1, col2, col3 = st.columns(3)
                with col1:
                    st.markdown("**ğŸ¯ æ¡ä»¶åˆ é™¤**")
                    delete_condition = st.selectbox(
                        "é€‰æ‹©åˆ é™¤æ¡ä»¶",
                        ["é€‰æ‹©æ¡ä»¶...", "å›ºå®šèµ„äº§åŸå€¼ä¸º0", "å›ºå®šèµ„äº§åç§°ä¸ºç©º", "å­˜æ”¾éƒ¨é—¨ä¸ºç©º", "è‡ªå®šä¹‰æ¡ä»¶"],
                        key="physical_delete_condition"
                    )

                    if delete_condition == "è‡ªå®šä¹‰æ¡ä»¶":
                        custom_field = st.selectbox("é€‰æ‹©å­—æ®µ", df_current.columns.tolist(),
                                                    key="physical_custom_field")
                        custom_value = st.text_input("è¾“å…¥è¦åˆ é™¤çš„å€¼", key="physical_custom_value")

                        if st.button("ğŸ—‘ï¸ æ‰§è¡Œæ¡ä»¶åˆ é™¤", key="physical_condition_delete"):
                            if custom_value:
                                original_count = len(current_physical)
                                filtered_data = [
                                    record for record in current_physical
                                    if str(record.get(custom_field, "")) != custom_value
                                ]
                                save_data(filtered_data, PHYSICAL_DATA_FILE)
                                deleted_count = original_count - len(filtered_data)
                                st.success(f"âœ… å·²åˆ é™¤ {deleted_count} æ¡è®°å½•")
                                st.rerun()

                    elif delete_condition != "é€‰æ‹©æ¡ä»¶..." and st.button("ğŸ—‘ï¸ æ‰§è¡Œæ¡ä»¶åˆ é™¤",
                                                                         key="physical_preset_delete"):
                        original_count = len(current_physical)
                        if delete_condition == "å›ºå®šèµ„äº§åŸå€¼ä¸º0":
                            filtered_data = [
                                record for record in current_physical
                                if safe_convert_to_float(record.get("å›ºå®šèµ„äº§åŸå€¼", 0)) != 0
                            ]
                        elif delete_condition == "å›ºå®šèµ„äº§åç§°ä¸ºç©º":
                            filtered_data = [
                                record for record in current_physical
                                if str(record.get("å›ºå®šèµ„äº§åç§°", "")).strip() != ""
                            ]
                        elif delete_condition == "å­˜æ”¾éƒ¨é—¨ä¸ºç©º":
                            filtered_data = [
                                record for record in current_physical
                                if str(record.get("å­˜æ”¾éƒ¨é—¨", "")).strip() != ""
                            ]

                        save_data(filtered_data, PHYSICAL_DATA_FILE)
                        deleted_count = original_count - len(filtered_data)
                        st.success(f"âœ… å·²åˆ é™¤ {deleted_count} æ¡è®°å½•")
                        st.rerun()

                with col2:
                    st.markdown("**ğŸ”¢ æŒ‰ç¼–ç åˆ é™¤**")
                    delete_codes = st.text_area(
                        "è¾“å…¥è¦åˆ é™¤çš„å›ºå®šèµ„äº§ç¼–ç ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰",
                        height=100,
                        key="physical_delete_codes"
                    )

                    if st.button("ğŸ—‘ï¸ åˆ é™¤æŒ‡å®šç¼–ç ", key="physical_code_delete"):
                        if delete_codes.strip():
                            codes_to_delete = [code.strip() for code in delete_codes.split('\n') if code.strip()]
                            original_count = len(current_physical)
                            filtered_data = [
                                record for record in current_physical
                                if record.get("å›ºå®šèµ„äº§ç¼–ç ", "") not in codes_to_delete
                            ]
                            save_data(filtered_data, PHYSICAL_DATA_FILE)
                            deleted_count = original_count - len(filtered_data)
                            st.success(f"âœ… å·²åˆ é™¤ {deleted_count} æ¡è®°å½•")
                            st.rerun()

                with col3:
                    st.markdown("**ğŸš¨ å±é™©æ“ä½œ**")
                    st.error("âš ï¸ ä»¥ä¸‹æ“ä½œå°†æ¸…ç©ºæ‰€æœ‰å®ç‰©æ•°æ®")

                    confirm_clear = st.checkbox("æˆ‘ç¡®è®¤è¦æ¸…ç©ºæ‰€æœ‰å®ç‰©æ•°æ®", key="physical_confirm_clear")

                    if confirm_clear:
                        final_confirm = st.text_input(
                            "è¯·è¾“å…¥ 'DELETE ALL' ç¡®è®¤æ¸…ç©º",
                            key="physical_final_confirm"
                        )

                        if final_confirm == "DELETE ALL" and st.button("ğŸš¨ æ¸…ç©ºæ‰€æœ‰æ•°æ®", key="physical_clear_all"):
                            save_data([], PHYSICAL_DATA_FILE)
                            st.success("âœ… å·²æ¸…ç©ºæ‰€æœ‰å®ç‰©æ•°æ®")
                            st.rerun()

        else:
            st.warning("âš ï¸ æš‚æ— å®ç‰©å°è´¦æ•°æ®")

        # å®ç‰©æ•°æ®ä¸Šä¼ éƒ¨åˆ†
        physical_file = st.file_uploader(
            "ä¸Šä¼ å®ç‰©å°è´¦Excelæ–‡ä»¶",
            type=['xlsx', 'xls'],
            key="physical_upload",
            help="Excelæ–‡ä»¶åº”åŒ…å«'å›ºå®šèµ„äº§ç¼–ç 'åˆ—ä½œä¸ºä¸»é”®ï¼Œ'å›ºå®šèµ„äº§åŸå€¼'åˆ—ä½œä¸ºä»·å€¼å­—æ®µ"
        )

        if physical_file is not None:
            try:
                physical_df = pd.read_excel(physical_file)
                st.success(f"âœ… æˆåŠŸè¯»å–å®ç‰©æ•°æ®: {len(physical_df)} è¡Œ x {len(physical_df.columns)} åˆ—")

                required_columns = ["å›ºå®šèµ„äº§ç¼–ç "]
                missing_columns = [col for col in required_columns if col not in physical_df.columns]

                if missing_columns:
                    st.error(f"âŒ ç¼ºå°‘å¿…éœ€å­—æ®µï¼š{missing_columns}")
                    st.stop()

                st.subheader("ğŸ“Š ä¸Šä¼ æ•°æ®å®Œæ•´é¢„è§ˆ")

                search_upload = st.text_input("ğŸ” æœç´¢ä¸Šä¼ æ•°æ®", key="search_physical_upload")
                if search_upload:
                    mask = physical_df.astype(str).apply(
                        lambda x: x.str.contains(search_upload, case=False, na=False)).any(axis=1)
                    df_filtered = physical_df[mask]
                    st.write(f"æœç´¢ç»“æœï¼š{len(df_filtered)} æ¡è®°å½•")
                    st.dataframe(df_filtered, use_container_width=True, height=500)
                else:
                    st.dataframe(physical_df, use_container_width=True, height=500)

                # æ•°æ®è´¨é‡æ£€æŸ¥
                st.subheader("ğŸ” æ•°æ®è´¨é‡æ£€æŸ¥")

                col1, col2, col3 = st.columns(3)
                with col1:
                    asset_codes = physical_df["å›ºå®šèµ„äº§ç¼–ç "].dropna()
                    duplicate_codes = asset_codes[asset_codes.duplicated()].unique()

                    if len(duplicate_codes) > 0:
                        st.error(f"âŒ é‡å¤ç¼–ç : {len(duplicate_codes)} ä¸ª")
                        with st.expander("æŸ¥çœ‹é‡å¤è®°å½•"):
                            duplicate_records = physical_df[physical_df["å›ºå®šèµ„äº§ç¼–ç "].isin(duplicate_codes)]
                            st.dataframe(duplicate_records, use_container_width=True)
                    else:
                        st.success("âœ… ç¼–ç å”¯ä¸€æ€§é€šè¿‡")

                with col2:
                    null_counts = physical_df.isnull().sum()
                    total_nulls = null_counts.sum()
                    if total_nulls > 0:
                        st.warning(f"âš ï¸ ç©ºå€¼: {total_nulls} ä¸ª")
                        with st.expander("æŸ¥çœ‹ç©ºå€¼ç»Ÿè®¡"):
                            st.dataframe(null_counts[null_counts > 0].to_frame("ç©ºå€¼æ•°é‡"), use_container_width=True)
                    else:
                        st.success("âœ… æ— ç©ºå€¼")

                with col3:
                    # âœ… ä¿®å¤ï¼šä¼˜å…ˆä½¿ç”¨å›ºå®šèµ„äº§åŸå€¼å­—æ®µ
                    if "å›ºå®šèµ„äº§åŸå€¼" in physical_df.columns:
                        total_value = sum(safe_convert_to_float(val) for val in physical_df["å›ºå®šèµ„äº§åŸå€¼"])
                        st.metric("å›ºå®šèµ„äº§åŸå€¼æ€»è®¡", f"Â¥{total_value:,.2f}")
                    elif "èµ„äº§ä»·å€¼" in physical_df.columns:
                        total_value = sum(safe_convert_to_float(val) for val in physical_df["èµ„äº§ä»·å€¼"])
                        st.metric("èµ„äº§ä»·å€¼æ€»è®¡", f"Â¥{total_value:,.2f}")
                        st.caption("ä½¿ç”¨èµ„äº§ä»·å€¼å­—æ®µ")
                    else:
                        st.warning("âš ï¸ æœªæ‰¾åˆ°ä»·å€¼å­—æ®µ")

                # å¯¼å…¥é€‰é¡¹
                st.markdown("---")
                st.subheader("ğŸ“¥ å¯¼å…¥é€‰é¡¹")

                import_mode = st.radio(
                    "é€‰æ‹©å¯¼å…¥æ¨¡å¼",
                    ["è¦†ç›–å¯¼å…¥ï¼ˆæ¸…ç©ºåŸæ•°æ®ï¼‰", "è¿½åŠ å¯¼å…¥ï¼ˆä¿ç•™åŸæ•°æ®ï¼‰", "æ›´æ–°å¯¼å…¥ï¼ˆæŒ‰ç¼–ç æ›´æ–°ï¼‰"],
                    key="physical_import_mode"
                )

                col1, col2, col3 = st.columns(3)
                with col1:
                    if st.button("ğŸ’¾ ç¡®è®¤å¯¼å…¥å®ç‰©æ•°æ®", type="primary", use_container_width=True):
                        # æ•°æ®æ ‡å‡†åŒ–å¤„ç†
                        processed_data = []
                        for _, row in physical_df.iterrows():
                            record = {}
                            # ç¡®ä¿ä¸»é”®å­—æ®µæ­£ç¡®
                            record["å›ºå®šèµ„äº§ç¼–ç "] = str(row.get("å›ºå®šèµ„äº§ç¼–ç ", "")).strip()
                            record["å›ºå®šèµ„äº§åç§°"] = str(row.get("å›ºå®šèµ„äº§åç§°", "")).strip()

                            # âœ… ä¿®å¤ï¼šä¼˜å…ˆå¤„ç†å›ºå®šèµ„äº§åŸå€¼å­—æ®µ
                            record["å›ºå®šèµ„äº§åŸå€¼"] = safe_convert_to_float(row.get("å›ºå®šèµ„äº§åŸå€¼", 0))

                            # å¦‚æœæ²¡æœ‰å›ºå®šèµ„äº§åŸå€¼ï¼Œå°è¯•å…¶ä»–ä»·å€¼å­—æ®µ
                            if record["å›ºå®šèµ„äº§åŸå€¼"] == 0:
                                for alt_field in ["èµ„äº§ä»·å€¼", "åŸå€¼", "è´¦é¢ä»·å€¼"]:
                                    if alt_field in row and safe_convert_to_float(row.get(alt_field, 0)) > 0:
                                        record["å›ºå®šèµ„äº§åŸå€¼"] = safe_convert_to_float(row.get(alt_field, 0))
                                        break

                            # å…¶ä»–æ ‡å‡†å­—æ®µ
                            record["èµ„äº§ä»·å€¼"] = record["å›ºå®šèµ„äº§åŸå€¼"]  # ä¿æŒå…¼å®¹æ€§
                            record["å­˜æ”¾éƒ¨é—¨"] = str(row.get("å­˜æ”¾éƒ¨é—¨", "")).strip()
                            record["ä¿ç®¡äºº"] = str(row.get("ä¿ç®¡äºº", "")).strip()
                            record["èµ„äº§çŠ¶æ€"] = str(row.get("èµ„äº§çŠ¶æ€", "")).strip()
                            record["ä½¿ç”¨äºº"] = str(row.get("ä½¿ç”¨äºº", "")).strip()
                            record["å›ºå®šèµ„äº§ç±»å‹"] = str(row.get("å›ºå®šèµ„äº§ç±»å‹", "")).strip()

                            # ä¿ç•™æ‰€æœ‰å…¶ä»–å­—æ®µ
                            for col in physical_df.columns:
                                if col not in record:
                                    value = row.get(col)
                                    if pd.isna(value):
                                        record[col] = ""
                                    elif isinstance(value, (int, float)):
                                        record[col] = float(value) if not pd.isna(value) else 0
                                    else:
                                        record[col] = str(value).strip() if value is not None else ""

                            if record["å›ºå®šèµ„äº§ç¼–ç "]:
                                processed_data.append(record)

                        # æ ¹æ®å¯¼å…¥æ¨¡å¼å¤„ç†æ•°æ®
                        if import_mode == "è¦†ç›–å¯¼å…¥ï¼ˆæ¸…ç©ºåŸæ•°æ®ï¼‰":
                            save_data(processed_data, PHYSICAL_DATA_FILE)
                            st.success(f"âœ… è¦†ç›–å¯¼å…¥ {len(processed_data)} æ¡å®ç‰©èµ„äº§è®°å½•")

                        elif import_mode == "è¿½åŠ å¯¼å…¥ï¼ˆä¿ç•™åŸæ•°æ®ï¼‰":
                            existing_data = load_data(PHYSICAL_DATA_FILE)
                            combined_data = existing_data + processed_data
                            save_data(combined_data, PHYSICAL_DATA_FILE)
                            st.success(f"âœ… è¿½åŠ å¯¼å…¥ {len(processed_data)} æ¡è®°å½•ï¼Œæ€»è®¡ {len(combined_data)} æ¡")

                        elif import_mode == "æ›´æ–°å¯¼å…¥ï¼ˆæŒ‰ç¼–ç æ›´æ–°ï¼‰":
                            existing_data = load_data(PHYSICAL_DATA_FILE)
                            existing_dict = {record.get("å›ºå®šèµ„äº§ç¼–ç "): record for record in existing_data}

                            # æ›´æ–°æˆ–æ·»åŠ æ–°è®°å½•
                            for record in processed_data:
                                existing_dict[record["å›ºå®šèµ„äº§ç¼–ç "]] = record

                            updated_data = list(existing_dict.values())
                            save_data(updated_data, PHYSICAL_DATA_FILE)
                            st.success(f"âœ… æ›´æ–°å¯¼å…¥å®Œæˆï¼Œæ€»è®¡ {len(updated_data)} æ¡è®°å½•")

                        st.balloons()
                        time.sleep(2)
                        st.rerun()

                with col2:
                    if st.button("ğŸ“¥ å¯¼å‡ºå½“å‰æ•°æ®", use_container_width=True):
                        output = BytesIO()
                        with pd.ExcelWriter(output, engine='openpyxl') as writer:
                            physical_df.to_excel(writer, index=False, sheet_name='å®ç‰©æ•°æ®')

                        st.download_button(
                            label="â¬‡ï¸ ä¸‹è½½Excelæ–‡ä»¶",
                            data=output.getvalue(),
                            file_name=f"å®ç‰©æ•°æ®_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )

                with col3:
                    if st.button("ğŸ”„ é‡æ–°ä¸Šä¼ ", use_container_width=True):
                        st.rerun()

            except Exception as e:
                st.error(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥ï¼š{str(e)}")

    with tab3:
        st.subheader("ğŸ”— æ˜ å°„å…³ç³»æ•°æ®")
        st.markdown("**æ˜ å°„è§„åˆ™**ï¼šå»ºç«‹è´¢åŠ¡ç³»ç»Ÿ'èµ„äº§ç¼–å·+åºå·' â†” å®ç‰©å°è´¦'å›ºå®šèµ„äº§ç¼–ç 'çš„å¯¹åº”å…³ç³»")

        # æ˜¾ç¤ºå½“å‰æ˜ å°„æ•°æ®
        current_mapping = load_data(MAPPING_DATA_FILE)
        if current_mapping:
            st.success(f"âœ… å½“å‰å·²æœ‰ {len(current_mapping)} æ¡æ˜ å°„å…³ç³»")

            with st.expander("ğŸ“Š æŸ¥çœ‹å½“å‰æ‰€æœ‰æ˜ å°„å…³ç³»", expanded=False):
                df_mapping = pd.DataFrame(current_mapping)

                search_mapping = st.text_input("ğŸ” æœç´¢æ˜ å°„å…³ç³»", key="search_mapping_current")
                if search_mapping:
                    mask = df_mapping.astype(str).apply(
                        lambda x: x.str.contains(search_mapping, case=False, na=False)).any(axis=1)
                    df_filtered = df_mapping[mask]
                    st.write(f"æœç´¢ç»“æœï¼š{len(df_filtered)} æ¡è®°å½•")
                    st.dataframe(df_filtered, use_container_width=True, height=400)
                else:
                    st.dataframe(df_mapping, use_container_width=True, height=400)

            # ğŸ—‘ï¸ æ˜ å°„å…³ç³»åˆ é™¤åŠŸèƒ½
            st.markdown("---")
            with st.expander("ğŸ—‘ï¸ æ˜ å°„å…³ç³»å¿«é€Ÿåˆ é™¤", expanded=False):
                st.warning("âš ï¸ **æ³¨æ„**ï¼šåˆ é™¤æ“ä½œä¸å¯æ¢å¤ï¼Œè¯·è°¨æ…æ“ä½œï¼")

                col1, col2, col3 = st.columns(3)
                with col1:
                    st.markdown("**ğŸ¯ æ¡ä»¶åˆ é™¤**")
                    delete_condition = st.selectbox(
                        "é€‰æ‹©åˆ é™¤æ¡ä»¶",
                        ["é€‰æ‹©æ¡ä»¶...", "è´¢åŠ¡ç¼–å·ä¸ºç©º", "å®ç‰©ç¼–ç ä¸ºç©º", "è‡ªå®šä¹‰æ¡ä»¶"],
                        key="mapping_delete_condition"
                    )

                    if delete_condition == "è‡ªå®šä¹‰æ¡ä»¶":
                        custom_field = st.selectbox("é€‰æ‹©å­—æ®µ", df_mapping.columns.tolist(), key="mapping_custom_field")
                        custom_value = st.text_input("è¾“å…¥è¦åˆ é™¤çš„å€¼", key="mapping_custom_value")

                        if st.button("ğŸ—‘ï¸ æ‰§è¡Œæ¡ä»¶åˆ é™¤", key="mapping_condition_delete"):
                            if custom_value:
                                original_count = len(current_mapping)
                                filtered_data = [
                                    record for record in current_mapping
                                    if str(record.get(custom_field, "")) != custom_value
                                ]
                                save_data(filtered_data, MAPPING_DATA_FILE)
                                deleted_count = original_count - len(filtered_data)
                                st.success(f"âœ… å·²åˆ é™¤ {deleted_count} æ¡æ˜ å°„å…³ç³»")
                                st.rerun()

                    elif delete_condition != "é€‰æ‹©æ¡ä»¶..." and st.button("ğŸ—‘ï¸ æ‰§è¡Œæ¡ä»¶åˆ é™¤",
                                                                         key="mapping_preset_delete"):
                        original_count = len(current_mapping)
                        if delete_condition == "è´¢åŠ¡ç¼–å·ä¸ºç©º":
                            filtered_data = [
                                record for record in current_mapping
                                if str(record.get("èµ„äº§ç¼–å·+åºå·", "")).strip() != ""
                            ]
                        elif delete_condition == "å®ç‰©ç¼–ç ä¸ºç©º":
                            filtered_data = [
                                record for record in current_mapping
                                if str(record.get("å›ºå®šèµ„äº§ç¼–ç ", "")).strip() != ""
                            ]

                        save_data(filtered_data, MAPPING_DATA_FILE)
                        deleted_count = original_count - len(filtered_data)
                        st.success(f"âœ… å·²åˆ é™¤ {deleted_count} æ¡æ˜ å°„å…³ç³»")
                        st.rerun()

                with col2:
                    st.markdown("**ğŸ”¢ æŒ‰ç¼–å·åˆ é™¤**")
                    delete_type = st.radio(
                        "åˆ é™¤ç±»å‹",
                        ["æŒ‰è´¢åŠ¡ç¼–å·", "æŒ‰å®ç‰©ç¼–ç "],
                        key="mapping_delete_type"
                    )

                    delete_codes = st.text_area(
                        f"è¾“å…¥è¦åˆ é™¤çš„{'è´¢åŠ¡ç¼–å·' if delete_type == 'æŒ‰è´¢åŠ¡ç¼–å·' else 'å®ç‰©ç¼–ç '}ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰",
                        height=100,
                        key="mapping_delete_codes"
                    )

                    if st.button("ğŸ—‘ï¸ åˆ é™¤ç›¸å…³æ˜ å°„", key="mapping_code_delete"):
                        if delete_codes.strip():
                            codes_to_delete = [code.strip() for code in delete_codes.split('\n') if code.strip()]
                            original_count = len(current_mapping)

                            if delete_type == "æŒ‰è´¢åŠ¡ç¼–å·":
                                filtered_data = [
                                    record for record in current_mapping
                                    if record.get("èµ„äº§ç¼–å·+åºå·", "") not in codes_to_delete
                                ]
                            else:
                                filtered_data = [
                                    record for record in current_mapping
                                    if record.get("å›ºå®šèµ„äº§ç¼–ç ", "") not in codes_to_delete
                                ]

                            save_data(filtered_data, MAPPING_DATA_FILE)
                            deleted_count = original_count - len(filtered_data)
                            st.success(f"âœ… å·²åˆ é™¤ {deleted_count} æ¡æ˜ å°„å…³ç³»")
                            st.rerun()

                with col3:
                    st.markdown("**ğŸš¨ å±é™©æ“ä½œ**")
                    st.error("âš ï¸ ä»¥ä¸‹æ“ä½œå°†æ¸…ç©ºæ‰€æœ‰æ˜ å°„å…³ç³»")

                    confirm_clear = st.checkbox("æˆ‘ç¡®è®¤è¦æ¸…ç©ºæ‰€æœ‰æ˜ å°„å…³ç³»", key="mapping_confirm_clear")

                    if confirm_clear:
                        final_confirm = st.text_input(
                            "è¯·è¾“å…¥ 'DELETE ALL' ç¡®è®¤æ¸…ç©º",
                            key="mapping_final_confirm"
                        )

                        if final_confirm == "DELETE ALL" and st.button("ğŸš¨ æ¸…ç©ºæ‰€æœ‰æ˜ å°„", key="mapping_clear_all"):
                            save_data([], MAPPING_DATA_FILE)
                            st.success("âœ… å·²æ¸…ç©ºæ‰€æœ‰æ˜ å°„å…³ç³»")
                            st.rerun()

        else:
            st.warning("âš ï¸ æš‚æ— æ˜ å°„å…³ç³»æ•°æ®")

        # æ˜ å°„å…³ç³»ä¸Šä¼ éƒ¨åˆ†
        mapping_file = st.file_uploader(
            "ä¸Šä¼ æ˜ å°„å…³ç³»Excelæ–‡ä»¶",
            type=['xlsx', 'xls'],
            key="mapping_upload",
            help="Excelæ–‡ä»¶åº”åŒ…å«'èµ„äº§ç¼–å·+åºå·'å’Œ'å›ºå®šèµ„äº§ç¼–ç 'åˆ—"
        )

        if mapping_file is not None:
            try:
                mapping_df = pd.read_excel(mapping_file)
                st.success(f"âœ… æˆåŠŸè¯»å–æ˜ å°„æ•°æ®: {len(mapping_df)} è¡Œ x {len(mapping_df.columns)} åˆ—")

                required_columns = ["èµ„äº§ç¼–å·+åºå·", "å›ºå®šèµ„äº§ç¼–ç "]
                missing_columns = [col for col in required_columns if col not in mapping_df.columns]

                if missing_columns:
                    st.error(f"âŒ ç¼ºå°‘å¿…éœ€å­—æ®µï¼š{missing_columns}")
                    st.stop()

                st.subheader("ğŸ“Š æ˜ å°„æ•°æ®é¢„è§ˆ")
                st.dataframe(mapping_df, use_container_width=True, height=400)

                # å¯¼å…¥é€‰é¡¹
                st.markdown("---")
                st.subheader("ğŸ“¥ å¯¼å…¥é€‰é¡¹")

                import_mode = st.radio(
                    "é€‰æ‹©å¯¼å…¥æ¨¡å¼",
                    ["è¦†ç›–å¯¼å…¥ï¼ˆæ¸…ç©ºåŸæ•°æ®ï¼‰", "è¿½åŠ å¯¼å…¥ï¼ˆä¿ç•™åŸæ•°æ®ï¼‰"],
                    key="mapping_import_mode"
                )

                col1, col2, col3 = st.columns(3)
                with col1:
                    if st.button("ğŸ’¾ ç¡®è®¤å¯¼å…¥æ˜ å°„æ•°æ®", type="primary", use_container_width=True):
                        processed_data = []
                        for _, row in mapping_df.iterrows():
                            record = {
                                "èµ„äº§ç¼–å·+åºå·": str(row.get("èµ„äº§ç¼–å·+åºå·", "")).strip(),
                                "å›ºå®šèµ„äº§ç¼–ç ": str(row.get("å›ºå®šèµ„äº§ç¼–ç ", "")).strip()
                            }

                            # æ·»åŠ å…¶ä»–åˆ—
                            for col in mapping_df.columns:
                                if col not in ["èµ„äº§ç¼–å·+åºå·", "å›ºå®šèµ„äº§ç¼–ç "]:
                                    record[col] = str(row.get(col, "")).strip()

                            if record["èµ„äº§ç¼–å·+åºå·"] and record["å›ºå®šèµ„äº§ç¼–ç "]:
                                processed_data.append(record)

                        # æ ¹æ®å¯¼å…¥æ¨¡å¼å¤„ç†æ•°æ®
                        if import_mode == "è¦†ç›–å¯¼å…¥ï¼ˆæ¸…ç©ºåŸæ•°æ®ï¼‰":
                            save_data(processed_data, MAPPING_DATA_FILE)
                            st.success(f"âœ… è¦†ç›–å¯¼å…¥ {len(processed_data)} æ¡æ˜ å°„å…³ç³»")

                        elif import_mode == "è¿½åŠ å¯¼å…¥ï¼ˆä¿ç•™åŸæ•°æ®ï¼‰":
                            existing_data = load_data(MAPPING_DATA_FILE)
                            combined_data = existing_data + processed_data
                            save_data(combined_data, MAPPING_DATA_FILE)
                            st.success(f"âœ… è¿½åŠ å¯¼å…¥ {len(processed_data)} æ¡è®°å½•ï¼Œæ€»è®¡ {len(combined_data)} æ¡")

                        st.balloons()
                        time.sleep(2)
                        st.rerun()

                with col2:
                    if st.button("ğŸ“¥ å¯¼å‡ºå½“å‰æ•°æ®", use_container_width=True):
                        output = BytesIO()
                        with pd.ExcelWriter(output, engine='openpyxl') as writer:
                            mapping_df.to_excel(writer, index=False, sheet_name='æ˜ å°„æ•°æ®')

                        st.download_button(
                            label="â¬‡ï¸ ä¸‹è½½Excelæ–‡ä»¶",
                            data=output.getvalue(),
                            file_name=f"æ˜ å°„æ•°æ®_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )

                with col3:
                    if st.button("ğŸ”„ é‡æ–°ä¸Šä¼ ", use_container_width=True):
                        st.rerun()

            except Exception as e:
                st.error(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥ï¼š{str(e)}")

    with tab4:
        st.subheader("ğŸ—‘ï¸ æ•°æ®åˆ é™¤ç®¡ç†ä¸­å¿ƒ")
        st.markdown("**ç»Ÿä¸€ç®¡ç†æ‰€æœ‰æ•°æ®çš„åˆ é™¤æ“ä½œï¼Œæ”¯æŒæ‰¹é‡æ“ä½œå’Œæ•°æ®å¤‡ä»½**")

        # æ•°æ®æ¦‚è§ˆ
        st.markdown("---")
        st.subheader("ğŸ“Š å½“å‰æ•°æ®æ¦‚è§ˆ")

        col1, col2, col3 = st.columns(3)

        with col1:
            financial_data = load_data(FINANCIAL_DATA_FILE)
            st.metric(
                label="ğŸ’° è´¢åŠ¡ç³»ç»Ÿæ•°æ®",
                value=f"{len(financial_data)} æ¡",
                delta=f"æ€»ä»·å€¼: {sum(safe_convert_to_float(record.get('èµ„äº§ä»·å€¼', 0)) for record in financial_data):,.2f}" if financial_data else "æ— æ•°æ®"
            )

        with col2:
            physical_data = load_data(PHYSICAL_DATA_FILE)
            st.metric(
                label="ğŸ“¦ å®ç‰©å°è´¦æ•°æ®",
                value=f"{len(physical_data)} æ¡",
                delta=f"æ€»ä»·å€¼: {sum(safe_convert_to_float(record.get('èµ„äº§ä»·å€¼', 0)) for record in physical_data):,.2f}" if physical_data else "æ— æ•°æ®"
            )

        with col3:
            mapping_data = load_data(MAPPING_DATA_FILE)
            st.metric(
                label="ğŸ”— æ˜ å°„å…³ç³»æ•°æ®",
                value=f"{len(mapping_data)} æ¡",
                delta="æ˜ å°„å…³ç³»" if mapping_data else "æ— æ•°æ®"
            )

        # ğŸ”„ æ•°æ®å¤‡ä»½åŠŸèƒ½
        st.markdown("---")
        st.subheader("ğŸ’¾ æ•°æ®å¤‡ä»½")
        st.info("ğŸ’¡ **å»ºè®®**ï¼šåœ¨æ‰§è¡Œåˆ é™¤æ“ä½œå‰ï¼Œå…ˆå¤‡ä»½å½“å‰æ•°æ®ä»¥é˜²æ„å¤–")

        col1, col2 = st.columns(2)

        with col1:
            if st.button("ğŸ“¥ åˆ›å»ºå®Œæ•´æ•°æ®å¤‡ä»½", use_container_width=True):
                try:
                    backup_data = {
                        "financial_data": financial_data,
                        "physical_data": physical_data,
                        "mapping_data": mapping_data,
                        "backup_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    }

                    # åˆ›å»ºExcelå¤‡ä»½æ–‡ä»¶
                    output = BytesIO()
                    with pd.ExcelWriter(output, engine='openpyxl') as writer:
                        if financial_data:
                            pd.DataFrame(financial_data).to_excel(writer, index=False, sheet_name='è´¢åŠ¡æ•°æ®')
                        if physical_data:
                            pd.DataFrame(physical_data).to_excel(writer, index=False, sheet_name='å®ç‰©æ•°æ®')
                        if mapping_data:
                            pd.DataFrame(mapping_data).to_excel(writer, index=False, sheet_name='æ˜ å°„æ•°æ®')

                    st.download_button(
                        label="â¬‡ï¸ ä¸‹è½½å®Œæ•´å¤‡ä»½æ–‡ä»¶",
                        data=output.getvalue(),
                        file_name=f"å®Œæ•´æ•°æ®å¤‡ä»½_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                    st.success("âœ… å¤‡ä»½æ–‡ä»¶å·²ç”Ÿæˆï¼Œè¯·ç‚¹å‡»ä¸‹è½½")

                except Exception as e:
                    st.error(f"âŒ å¤‡ä»½å¤±è´¥ï¼š{str(e)}")

        with col2:
            st.markdown("**ğŸ“‹ å¤‡ä»½å†…å®¹åŒ…æ‹¬ï¼š**")
            st.markdown("- ğŸ’° æ‰€æœ‰è´¢åŠ¡ç³»ç»Ÿæ•°æ®")
            st.markdown("- ğŸ“¦ æ‰€æœ‰å®ç‰©å°è´¦æ•°æ®")
            st.markdown("- ğŸ”— æ‰€æœ‰æ˜ å°„å…³ç³»æ•°æ®")
            st.markdown("- ğŸ• å¤‡ä»½æ—¶é—´æˆ³")

        # ğŸ—‘ï¸ æ‰¹é‡åˆ é™¤åŠŸèƒ½
        st.markdown("---")
        st.subheader("ğŸ—‘ï¸ æ‰¹é‡åˆ é™¤æ“ä½œ")
        st.error("âš ï¸ **å±é™©åŒºåŸŸ**ï¼šä»¥ä¸‹æ“ä½œå°†æ°¸ä¹…åˆ é™¤æ•°æ®ï¼Œè¯·ç¡®ä¿å·²å¤‡ä»½é‡è¦æ•°æ®ï¼")

        # é€‰æ‹©æ€§åˆ é™¤
        st.markdown("**ğŸ¯ é€‰æ‹©æ€§åˆ é™¤**")
        delete_options = st.multiselect(
            "é€‰æ‹©è¦åˆ é™¤çš„æ•°æ®ç±»å‹",
            ["è´¢åŠ¡ç³»ç»Ÿæ•°æ®", "å®ç‰©å°è´¦æ•°æ®", "æ˜ å°„å…³ç³»æ•°æ®"],
            key="batch_delete_options"
        )

        if delete_options:
            st.warning(f"âš ï¸ å°†åˆ é™¤ï¼š{', '.join(delete_options)}")

            # åŒé‡ç¡®è®¤
            col1, col2 = st.columns(2)

            with col1:
                confirm_delete = st.checkbox(
                    f"æˆ‘ç¡®è®¤è¦åˆ é™¤é€‰ä¸­çš„ {len(delete_options)} ç±»æ•°æ®",
                    key="batch_confirm_delete"
                )

            with col2:
                if confirm_delete:
                    final_confirm = st.text_input(
                        "è¯·è¾“å…¥ 'DELETE SELECTED' æœ€ç»ˆç¡®è®¤",
                        key="batch_final_confirm"
                    )

                    if final_confirm == "DELETE SELECTED" and st.button("ğŸ—‘ï¸ æ‰§è¡Œæ‰¹é‡åˆ é™¤", key="batch_execute_delete"):
                        deleted_count = 0

                        if "è´¢åŠ¡ç³»ç»Ÿæ•°æ®" in delete_options:
                            save_data([], FINANCIAL_DATA_FILE)
                            deleted_count += len(financial_data)
                            st.success("âœ… å·²æ¸…ç©ºè´¢åŠ¡ç³»ç»Ÿæ•°æ®")

                        if "å®ç‰©å°è´¦æ•°æ®" in delete_options:
                            save_data([], PHYSICAL_DATA_FILE)
                            deleted_count += len(physical_data)
                            st.success("âœ… å·²æ¸…ç©ºå®ç‰©å°è´¦æ•°æ®")

                        if "æ˜ å°„å…³ç³»æ•°æ®" in delete_options:
                            save_data([], MAPPING_DATA_FILE)
                            deleted_count += len(mapping_data)
                            st.success("âœ… å·²æ¸…ç©ºæ˜ å°„å…³ç³»æ•°æ®")

                        st.success(f"ğŸ‰ æ‰¹é‡åˆ é™¤å®Œæˆï¼Œå…±åˆ é™¤ {deleted_count} æ¡è®°å½•")
                        st.balloons()
                        time.sleep(2)
                        st.rerun()

        # ğŸš¨ å®Œå…¨é‡ç½®
        st.markdown("---")
        st.markdown("**ğŸš¨ å®Œå…¨é‡ç½®ç³»ç»Ÿ**")
        st.error("ğŸ’€ **æåº¦å±é™©**ï¼šæ­¤æ“ä½œå°†æ¸…ç©ºæ‰€æœ‰æ•°æ®ï¼ŒåŒ…æ‹¬è´¢åŠ¡ã€å®ç‰©å’Œæ˜ å°„å…³ç³»ï¼")

        reset_confirm1 = st.checkbox("æˆ‘ç†è§£æ­¤æ“ä½œçš„åæœ", key="reset_confirm1")

        if reset_confirm1:
            reset_confirm2 = st.checkbox("æˆ‘å·²å¤‡ä»½æ‰€æœ‰é‡è¦æ•°æ®", key="reset_confirm2")

            if reset_confirm2:
                reset_confirm3 = st.text_input(
                    "è¯·è¾“å…¥ 'RESET ALL DATA' ç¡®è®¤å®Œå…¨é‡ç½®",
                    key="reset_final_confirm"
                )

                if reset_confirm3 == "RESET ALL DATA" and st.button("ğŸ’€ å®Œå…¨é‡ç½®ç³»ç»Ÿ", key="system_reset"):
                    # æ¸…ç©ºæ‰€æœ‰æ•°æ®æ–‡ä»¶
                    save_data([], FINANCIAL_DATA_FILE)
                    save_data([], PHYSICAL_DATA_FILE)
                    save_data([], MAPPING_DATA_FILE)

                    st.success("âœ… ç³»ç»Ÿå·²å®Œå…¨é‡ç½®")
                    st.info("ğŸ”„ é¡µé¢å°†åœ¨3ç§’ååˆ·æ–°...")
                    time.sleep(3)
                    st.rerun()

        # ğŸ“Š åˆ é™¤æ“ä½œç»Ÿè®¡
        st.markdown("---")
        st.subheader("ğŸ“Š åˆ é™¤æ“ä½œè®°å½•")
        st.info("ğŸ’¡ **æç¤º**ï¼šç³»ç»Ÿä¼šè®°å½•åˆ é™¤æ“ä½œçš„åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯")

        # è¿™é‡Œå¯ä»¥æ·»åŠ åˆ é™¤æ“ä½œçš„æ—¥å¿—è®°å½•åŠŸèƒ½
        if st.button("ğŸ” æŸ¥çœ‹æ“ä½œæ—¥å¿—", key="view_delete_log"):
            st.info("ğŸ“ æ“ä½œæ—¥å¿—åŠŸèƒ½å¼€å‘ä¸­...")
            # æœªæ¥å¯ä»¥æ·»åŠ æ“ä½œæ—¥å¿—çš„æ˜¾ç¤º

# éœ€è¦æ·»åŠ çš„è¾…åŠ©å‡½æ•°
import time
from datetime import datetime
from io import BytesIO


def safe_convert_to_float(value):
    """å®‰å…¨è½¬æ¢ä¸ºæµ®ç‚¹æ•° - å¢å¼ºç‰ˆ"""
    try:
        # å¤„ç†pandas NaN
        if pd.isna(value):
            return 0.0

        if value is None or value == "":
            return 0.0

        # å¤„ç†å­—ç¬¦ä¸²ç±»å‹çš„æ•°å€¼
        if isinstance(value, str):
            # ç§»é™¤è´§å¸ç¬¦å·å’Œé€—å·
            cleaned_value = value.replace("Â¥", "").replace("$", "").replace("â‚¬", "").replace(",", "").replace("ï¼Œ", "").strip()
            if cleaned_value == "" or cleaned_value == "-" or cleaned_value.lower() in ['nan', 'null', 'none']:
                return 0.0
            return float(cleaned_value)

        # å¤„ç†numpyç±»å‹
        if hasattr(value, 'dtype'):  # numpyç±»å‹
            if pd.isna(value):
                return 0.0
            return float(value)

        # å¤„ç†æ•°å­—ç±»å‹
        if isinstance(value, (int, float)):
            if pd.isna(value):
                return 0.0
            return float(value)

        return float(value)
    except (ValueError, TypeError, OverflowError):
        return 0.0


def mapping_query_page():
    """æ˜ å°„æŸ¥è¯¢é¡µé¢"""
    st.header("ğŸ” èµ„äº§æ˜ å°„å…³ç³»æŸ¥è¯¢")

    # åŠ è½½æ•°æ®
    with st.spinner("åŠ è½½æ•°æ®ä¸­..."):
        financial_data = load_data(FINANCIAL_DATA_FILE)
        physical_data = load_data(PHYSICAL_DATA_FILE)
        mapping_data = load_data(MAPPING_DATA_FILE)

    # ä¿®æ”¹ï¼šæ£€æŸ¥æ‰€æœ‰ä¸‰ä¸ªæ•°æ®æº
    if not all([financial_data, physical_data, mapping_data]):
        missing = []
        if not financial_data:
            missing.append("è´¢åŠ¡ç³»ç»Ÿæ•°æ®")
        if not physical_data:
            missing.append("å®ç‰©å°è´¦æ•°æ®")
        if not mapping_data:
            missing.append("æ˜ å°„å…³ç³»æ•°æ®")
        st.warning(f"âš ï¸ è¯·å…ˆå¯¼å…¥ï¼š{', '.join(missing)}")
        return
    # âš™ï¸ å­—æ®µæ˜ å°„é…ç½®
    st.markdown("### âš™ï¸ å­—æ®µæ˜ å°„é…ç½®")

    with st.expander("é…ç½®æ•°æ®å­—æ®µæ˜ å°„", expanded=False):
        col1, col2 = st.columns(2)

        with col1:
            st.markdown("**è´¢åŠ¡ç³»ç»Ÿå­—æ®µé…ç½®**")

            # è·å–è´¢åŠ¡æ•°æ®çš„æ‰€æœ‰å­—æ®µ
            financial_fields = list(financial_data[0].keys()) if financial_data else []

            financial_original_field = st.selectbox(
                "åŸå€¼å­—æ®µ",
                financial_fields,
                index=financial_fields.index("èµ„äº§ä»·å€¼") if "èµ„äº§ä»·å€¼" in financial_fields else 0,
                key="fin_original"
            )

            financial_depreciation_field = st.selectbox(
                "ç´¯è®¡æŠ˜æ—§å­—æ®µ",
                financial_fields,
                index=financial_fields.index("ç´¯è®¡æŠ˜æ—§") if "ç´¯è®¡æŠ˜æ—§" in financial_fields else 0,
                key="fin_depreciation"
            )

            financial_net_field = st.selectbox(
                "å‡€å€¼å­—æ®µ",
                financial_fields,
                index=financial_fields.index("å‡€é¢") if "å‡€é¢" in financial_fields else 0,
                key="fin_net"
            )

        with col2:
            st.markdown("**å®ç‰©ç³»ç»Ÿå­—æ®µé…ç½®**")

            # è·å–å®ç‰©æ•°æ®çš„æ‰€æœ‰å­—æ®µ
            physical_fields = list(physical_data[0].keys()) if physical_data else []

            physical_original_field = st.selectbox(
                "åŸå€¼å­—æ®µ",
                physical_fields,
                index=physical_fields.index("å›ºå®šèµ„äº§åŸå€¼") if "å›ºå®šèµ„äº§åŸå€¼" in physical_fields else 0,
                key="phy_original"
            )

            physical_depreciation_field = st.selectbox(
                "ç´¯è®¡æŠ˜æ—§å­—æ®µ",
                physical_fields,
                index=physical_fields.index("ç´¯è®¡æŠ˜æ—§") if "ç´¯è®¡æŠ˜æ—§" in physical_fields else 0,
                key="phy_depreciation"
            )

            # å®ç‰©ç³»ç»Ÿå‡€å€¼å­—æ®µï¼ˆå¯é€‰ï¼Œå¦‚æœæ²¡æœ‰åˆ™è®¡ç®—ï¼‰
            physical_net_field = st.selectbox(
                "å‡€å€¼å­—æ®µï¼ˆå¯é€‰ï¼‰",
                ["è®¡ç®—å¾—å‡º"] + physical_fields,
                key="phy_net"
            )

    # ğŸ” æ•°æ®è°ƒè¯•ä¿¡æ¯éƒ¨åˆ†
    st.markdown("### ğŸ” æ•°æ®å­—æ®µè°ƒè¯•ä¿¡æ¯")

    with st.expander("æŸ¥çœ‹æ•°æ®å­—æ®µè¯¦æƒ…", expanded=False):
        if financial_data:
            st.write("**è´¢åŠ¡ç³»ç»Ÿæ•°æ®ç¤ºä¾‹ï¼ˆå‰3æ¡ï¼‰ï¼š**")
            for i, record in enumerate(financial_data[:3]):
                st.write(f"è®°å½• {i + 1}:")
                st.json(record)

        if physical_data:
            st.write("**å®ç‰©ç³»ç»Ÿæ•°æ®ç¤ºä¾‹ï¼ˆå‰3æ¡ï¼‰ï¼š**")
            for i, record in enumerate(physical_data[:3]):
                st.write(f"è®°å½• {i + 1}:")
                st.json(record)
    # åˆ›å»ºç´¢å¼•ä»¥æé«˜æŸ¥è¯¢æ•ˆç‡
    financial_index = create_data_index(financial_data, "èµ„äº§ç¼–å·+åºå·")
    physical_index = create_data_index(physical_data, "å›ºå®šèµ„äº§ç¼–ç ")
    financial_to_physical_mapping, physical_to_financial_mapping = create_mapping_index(mapping_data)

    # æ˜¾ç¤ºæ˜ å°„ç»Ÿè®¡ä¿¡æ¯
    st.info(
        f"ğŸ“Š æ•°æ®æ¦‚å†µï¼šè´¢åŠ¡èµ„äº§ {len(financial_data)} æ¡ï¼Œå®ç‰©èµ„äº§ {len(physical_data)} æ¡ï¼Œæ˜ å°„å…³ç³» {len(mapping_data)} æ¡")

    # æŸ¥è¯¢é€‰é¡¹
    query_type = st.selectbox(
        "é€‰æ‹©æŸ¥è¯¢æ–¹å¼",
        ["æŒ‰èµ„äº§ç¼–å·é€‰æ‹©æŸ¥è¯¢", "æŒ‰èµ„äº§ç¼–å·+åºå·æŸ¥è¯¢", "æŒ‰å®ç‰©å°è´¦ç¼–å·æŸ¥è¯¢", "æŒ‰èµ„äº§åç§°æœç´¢", "æ‰¹é‡æŸ¥è¯¢"]
    )

    if query_type == "æŒ‰èµ„äº§ç¼–å·é€‰æ‹©æŸ¥è¯¢":
        st.subheader("ğŸ“‹ èµ„äº§ç¼–å·é€‰æ‹©æŸ¥è¯¢")

        # ğŸ” æå–æ‰€æœ‰è´¢åŠ¡èµ„äº§çš„èµ„äº§ç¼–å·ï¼ˆå»é™¤+åºå·éƒ¨åˆ†ï¼‰
        asset_numbers = set()
        asset_number_to_full_codes = {}  # èµ„äº§ç¼–å·åˆ°å®Œæ•´ç¼–å·+åºå·çš„æ˜ å°„

        for record in financial_data:
            full_code = str(record.get('èµ„äº§ç¼–å·+åºå·', '')).strip()
            if full_code:
                # å°è¯•æå–èµ„äº§ç¼–å·éƒ¨åˆ†ï¼ˆå»é™¤åºå·ï¼‰
                asset_number = full_code

                # ğŸ”§ æ™ºèƒ½æå–èµ„äº§ç¼–å·ï¼ˆå»é™¤åºå·éƒ¨åˆ†ï¼‰
                import re

                # æ–¹æ³•1ï¼šå¦‚æœåŒ…å«+å·ï¼Œå–+å·å‰çš„éƒ¨åˆ†
                if '+' in full_code:
                    asset_number = full_code.split('+')[0].strip()
                # æ–¹æ³•2ï¼šå¦‚æœåŒ…å«-å·ï¼Œå–-å·å‰çš„éƒ¨åˆ†
                elif '-' in full_code:
                    asset_number = full_code.split('-')[0].strip()
                # æ–¹æ³•3ï¼šå¦‚æœåŒ…å«_å·ï¼Œå–_å·å‰çš„éƒ¨åˆ†
                elif '_' in full_code:
                    asset_number = full_code.split('_')[0].strip()
                # æ–¹æ³•4ï¼šä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ï¼Œæå–å­—æ¯+æ•°å­—çš„ä¸»è¦éƒ¨åˆ†
                else:
                    # åŒ¹é…æ¨¡å¼ï¼šå­—æ¯å¼€å¤´ï¼Œåè·Ÿæ•°å­—ï¼Œå¯èƒ½æœ‰åºå·
                    match = re.match(r'^([A-Za-z]+\d+)', full_code)
                    if match:
                        asset_number = match.group(1)
                    else:
                        # å¦‚æœæ— æ³•æ™ºèƒ½æå–ï¼Œä½¿ç”¨åŸå§‹ç¼–å·
                        asset_number = full_code

                asset_numbers.add(asset_number)

                # å»ºç«‹èµ„äº§ç¼–å·åˆ°å®Œæ•´ç¼–å·çš„æ˜ å°„
                if asset_number not in asset_number_to_full_codes:
                    asset_number_to_full_codes[asset_number] = []
                asset_number_to_full_codes[asset_number].append(full_code)

        # æ’åºèµ„äº§ç¼–å·åˆ—è¡¨
        sorted_asset_numbers = sorted(list(asset_numbers))

        if not sorted_asset_numbers:
            st.warning("âš ï¸ æœªæ‰¾åˆ°å¯ç”¨çš„èµ„äº§ç¼–å·")
            return

        # ğŸ¯ èµ„äº§ç¼–å·é€‰æ‹©å™¨
        col1, col2 = st.columns([2, 1])

        with col1:
            selected_asset_number = st.selectbox(
                f"é€‰æ‹©èµ„äº§ç¼–å· (å…± {len(sorted_asset_numbers)} ä¸ª)",
                ["è¯·é€‰æ‹©èµ„äº§ç¼–å·..."] + sorted_asset_numbers,
                key="asset_number_selector"
            )

        with col2:
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            if selected_asset_number != "è¯·é€‰æ‹©èµ„äº§ç¼–å·...":
                related_count = len(asset_number_to_full_codes.get(selected_asset_number, []))
                st.metric("ç›¸å…³èµ„äº§æ•°é‡", f"{related_count} æ¡")

        # ğŸ” æœç´¢åŠŸèƒ½
        search_filter = st.text_input(
            "ğŸ” æœç´¢èµ„äº§ç¼–å· (å¯è¾“å…¥éƒ¨åˆ†ç¼–å·è¿›è¡Œç­›é€‰)",
            placeholder="è¾“å…¥ç¼–å·å…³é”®è¯è¿›è¡Œå¿«é€Ÿç­›é€‰...",
            key="asset_number_search"
        )

        # å¦‚æœæœ‰æœç´¢æ¡ä»¶ï¼Œè¿‡æ»¤èµ„äº§ç¼–å·åˆ—è¡¨
        if search_filter:
            filtered_asset_numbers = [num for num in sorted_asset_numbers
                                      if search_filter.lower() in num.lower()]

            if filtered_asset_numbers:
                st.info(f"ğŸ¯ æ‰¾åˆ° {len(filtered_asset_numbers)} ä¸ªåŒ¹é…çš„èµ„äº§ç¼–å·")

                # æ˜¾ç¤ºç­›é€‰åçš„é€‰æ‹©å™¨
                selected_asset_number_filtered = st.selectbox(
                    "ç­›é€‰ç»“æœä¸­é€‰æ‹©:",
                    ["è¯·é€‰æ‹©..."] + filtered_asset_numbers,
                    key="filtered_asset_selector"
                )

                if selected_asset_number_filtered != "è¯·é€‰æ‹©...":
                    selected_asset_number = selected_asset_number_filtered
            else:
                st.warning(f"âš ï¸ æ²¡æœ‰æ‰¾åˆ°åŒ…å« '{search_filter}' çš„èµ„äº§ç¼–å·")

        # ğŸ” æ‰§è¡ŒæŸ¥è¯¢
        if selected_asset_number != "è¯·é€‰æ‹©èµ„äº§ç¼–å·..." and st.button("ğŸ” æŸ¥è¯¢é€‰å®šèµ„äº§ç¼–å·", type="primary"):
            # è·å–è¯¥èµ„äº§ç¼–å·ä¸‹çš„æ‰€æœ‰å®Œæ•´ç¼–å·
            full_codes = asset_number_to_full_codes.get(selected_asset_number, [])

            if full_codes:
                st.success(f"âœ… èµ„äº§ç¼–å· '{selected_asset_number}' ä¸‹å…±æœ‰ {len(full_codes)} æ¡ç›¸å…³èµ„äº§")

                # ğŸ¯ æ˜¾ç¤ºè¯¥èµ„äº§ç¼–å·ä¸‹çš„æ‰€æœ‰èµ„äº§è¯¦æƒ…
                for i, full_code in enumerate(sorted(full_codes), 1):
                    financial_record = financial_index.get(full_code)

                    if financial_record:
                        # æ˜¾ç¤ºè´¢åŠ¡èµ„äº§ä¿¡æ¯
                        with st.expander(f"ğŸ“Š èµ„äº§ #{i}: {full_code} - {financial_record.get('èµ„äº§åç§°', '')}",
                                         expanded=True):
                            col1, col2 = st.columns(2)

                            with col1:
                                st.info(f"**å®Œæ•´ç¼–å·**: {financial_record.get('èµ„äº§ç¼–å·+åºå·', '')}")
                                st.info(f"**èµ„äº§åç§°**: {financial_record.get('èµ„äº§åç§°', '')}")
                                st.info(f"**èµ„äº§åˆ†ç±»**: {financial_record.get('èµ„äº§åˆ†ç±»', '')}")

                            with col2:
                                financial_value = safe_get_value(financial_record, "èµ„äº§ä»·å€¼")
                                st.info(f"**èµ„äº§ä»·å€¼**: Â¥{financial_value:,.2f}")
                                st.info(f"**æ‰€å±éƒ¨é—¨**: {financial_record.get('éƒ¨é—¨åç§°', '')}")
                                st.info(f"**ä¿ç®¡äºº**: {financial_record.get('ä¿ç®¡äºº', '')}")

                            # æŸ¥æ‰¾å¯¹åº”çš„å®ç‰©èµ„äº§
                            physical_codes = financial_to_physical_mapping.get(full_code, [])

                            if physical_codes:
                                st.success(f"âœ… å·²æ˜ å°„åˆ° {len(physical_codes)} ä¸ªå®ç‰©èµ„äº§")

                                total_physical_value = 0
                                valid_physical_count = 0

                                for j, physical_code in enumerate(physical_codes, 1):
                                    physical_record = physical_index.get(physical_code)

                                    if physical_record:
                                        # æ˜¾ç¤ºå®ç‰©èµ„äº§ä¿¡æ¯
                                        st.markdown(f"**ğŸ”— å¯¹åº”å®ç‰©èµ„äº§ #{j}: {physical_code}**")

                                        col_p1, col_p2 = st.columns(2)
                                        with col_p1:
                                            st.write(f"- **èµ„äº§ç¼–ç **: {physical_record.get('å›ºå®šèµ„äº§ç¼–ç ', '')}")
                                            st.write(f"- **èµ„äº§åç§°**: {physical_record.get('å›ºå®šèµ„äº§åç§°', '')}")
                                            st.write(f"- **èµ„äº§ç±»å‹**: {physical_record.get('å›ºå®šèµ„äº§ç±»å‹', '')}")

                                        with col_p2:
                                            physical_value = safe_get_value(physical_record, "èµ„äº§ä»·å€¼")
                                            st.write(f"- **èµ„äº§ä»·å€¼**: Â¥{physical_value:,.2f}")
                                            st.write(f"- **å­˜æ”¾éƒ¨é—¨**: {physical_record.get('å­˜æ”¾éƒ¨é—¨', '')}")
                                            st.write(f"- **ä½¿ç”¨çŠ¶æ€**: {physical_record.get('ä½¿ç”¨çŠ¶æ€', '')}")

                                        total_physical_value += physical_value
                                        valid_physical_count += 1
                                    else:
                                        st.error(f"âŒ å®ç‰©èµ„äº§è®°å½•ä¸å­˜åœ¨: {physical_code}")

                                # ä»·å€¼æ¯”è¾ƒ
                                if valid_physical_count > 0:
                                    value_diff = financial_value - total_physical_value

                                    col_v1, col_v2, col_v3 = st.columns(3)
                                    with col_v1:
                                        st.metric("è´¢åŠ¡ä»·å€¼", f"Â¥{financial_value:,.2f}")
                                    with col_v2:
                                        st.metric("å®ç‰©æ€»ä»·å€¼", f"Â¥{total_physical_value:,.2f}")
                                    with col_v3:
                                        st.metric("ä»·å€¼å·®å¼‚", f"Â¥{value_diff:,.2f}")

                                    if abs(value_diff) > 0.01:
                                        if value_diff > 0:
                                            st.warning(f"âš ï¸ è´¢åŠ¡ä»·å€¼é«˜äºå®ç‰©æ€»ä»·å€¼ Â¥{value_diff:,.2f}")
                                        else:
                                            st.warning(f"âš ï¸ å®ç‰©æ€»ä»·å€¼é«˜äºè´¢åŠ¡ä»·å€¼ Â¥{abs(value_diff):,.2f}")
                                    else:
                                        st.success("âœ… è´¢åŠ¡ä¸å®ç‰©ä»·å€¼ä¸€è‡´")
                            else:
                                st.warning("âš ï¸ è¯¥èµ„äº§æœªæ‰¾åˆ°å¯¹åº”çš„å®ç‰©èµ„äº§")
                    else:
                        st.error(f"âŒ è´¢åŠ¡èµ„äº§è®°å½•ä¸å­˜åœ¨: {full_code}")

                # ğŸ“Š æ±‡æ€»ç»Ÿè®¡
                st.markdown("---")
                st.subheader(f"ğŸ“Š èµ„äº§ç¼–å· '{selected_asset_number}' æ±‡æ€»ç»Ÿè®¡")

                # è®¡ç®—æ±‡æ€»æ•°æ®
                total_financial_value = 0
                total_physical_value = 0
                mapped_count = 0
                unmapped_count = 0

                for full_code in full_codes:
                    financial_record = financial_index.get(full_code)
                    if financial_record:
                        total_financial_value += safe_get_value(financial_record, "èµ„äº§ä»·å€¼")

                        physical_codes = financial_to_physical_mapping.get(full_code, [])
                        if physical_codes:
                            mapped_count += 1
                            for physical_code in physical_codes:
                                physical_record = physical_index.get(physical_code)
                                if physical_record:
                                    total_physical_value += safe_get_value(physical_record, "èµ„äº§ä»·å€¼")
                        else:
                            unmapped_count += 1

                # æ˜¾ç¤ºæ±‡æ€»ç»Ÿè®¡
                col1, col2, col3, col4 = st.columns(4)

                with col1:
                    st.metric("èµ„äº§æ€»æ•°", len(full_codes))

                with col2:
                    st.metric("å·²æ˜ å°„", mapped_count)

                with col3:
                    st.metric("æœªæ˜ å°„", unmapped_count)

                with col4:
                    mapping_rate = (mapped_count / len(full_codes) * 100) if full_codes else 0
                    st.metric("æ˜ å°„ç‡", f"{mapping_rate:.1f}%")

                # ä»·å€¼æ±‡æ€»
                col1, col2, col3 = st.columns(3)

                with col1:
                    st.metric("è´¢åŠ¡æ€»ä»·å€¼", f"Â¥{total_financial_value:,.2f}")

                with col2:
                    st.metric("å®ç‰©æ€»ä»·å€¼", f"Â¥{total_physical_value:,.2f}")

                with col3:
                    total_diff = total_financial_value - total_physical_value
                    st.metric("æ€»ä»·å€¼å·®å¼‚", f"Â¥{total_diff:,.2f}")
            else:
                st.error(f"âŒ èµ„äº§ç¼–å· '{selected_asset_number}' ä¸‹æ²¡æœ‰æ‰¾åˆ°ç›¸å…³èµ„äº§")

    if query_type == "æŒ‰èµ„äº§ç¼–å·+åºå·æŸ¥è¯¢":
        st.subheader("ğŸ” èµ„äº§ç¼–å·+åºå·æŸ¥è¯¢")

        financial_code = st.text_input("è¯·è¾“å…¥èµ„äº§ç¼–å·+åºå·", placeholder="ä¾‹å¦‚: FS001")

        if st.button("ğŸ” æŸ¥è¯¢è´¢åŠ¡èµ„äº§"):
            if financial_code:
                # æŸ¥æ‰¾è´¢åŠ¡èµ„äº§è®°å½•
                financial_record = financial_index.get(str(financial_code))

                if financial_record:
                    # æ˜¾ç¤ºè´¢åŠ¡èµ„äº§ä¿¡æ¯
                    with st.expander("ğŸ“Š è´¢åŠ¡èµ„äº§è¯¦æƒ…", expanded=True):
                        col1, col2 = st.columns(2)
                        with col1:
                            st.info(f"**èµ„äº§ç¼–å·**: {financial_record.get('èµ„äº§ç¼–å·+åºå·', '')}")
                            st.info(f"**èµ„äº§åç§°**: {financial_record.get('èµ„äº§åç§°', '')}")
                            st.info(f"**èµ„äº§åˆ†ç±»**: {financial_record.get('èµ„äº§åˆ†ç±»', '')}")
                        with col2:
                            financial_value = safe_get_value(financial_record, "èµ„äº§ä»·å€¼")
                            st.info(f"**èµ„äº§ä»·å€¼**: Â¥{financial_value:,.2f}")
                            st.info(f"**æ‰€å±éƒ¨é—¨**: {financial_record.get('éƒ¨é—¨åç§°', '')}")
                            st.info(f"**ä¿ç®¡äºº**: {financial_record.get('ä¿ç®¡äºº', '')}")

                    # æŸ¥æ‰¾å¯¹åº”çš„å®ç‰©èµ„äº§ï¼ˆæ”¯æŒå¤šå¯¹å¤šï¼‰
                    physical_codes = financial_to_physical_mapping.get(str(financial_code), [])

                    if physical_codes:
                        st.success(f"âœ… æ‰¾åˆ° {len(physical_codes)} ä¸ªå¯¹åº”çš„å®ç‰©èµ„äº§")

                        # ç”¨äºè®¡ç®—æ€»ä»·å€¼
                        total_physical_value = 0
                        valid_physical_count = 0

                        for i, physical_code in enumerate(physical_codes, 1):
                            physical_record = physical_index.get(physical_code)

                            if physical_record:
                                # æ˜¾ç¤ºå®ç‰©èµ„äº§ä¿¡æ¯
                                with st.expander(f"ğŸ“‹ å®ç‰©èµ„äº§è¯¦æƒ… #{i} - {physical_code}", expanded=True):
                                    col1, col2 = st.columns(2)
                                    with col1:
                                        st.info(f"**èµ„äº§ç¼–å·**: {physical_record.get('å›ºå®šèµ„äº§ç¼–ç ', '')}")
                                        st.info(f"**èµ„äº§åç§°**: {physical_record.get('å›ºå®šèµ„äº§åç§°', '')}")
                                        st.info(f"**èµ„äº§ç±»å‹**: {physical_record.get('å›ºå®šèµ„äº§ç±»å‹', '')}")
                                    with col2:
                                        physical_value = safe_get_value(physical_record, "èµ„äº§ä»·å€¼")
                                        st.info(f"**èµ„äº§ä»·å€¼**: Â¥{physical_value:,.2f}")
                                        st.info(f"**å­˜æ”¾éƒ¨é—¨**: {physical_record.get('å­˜æ”¾éƒ¨é—¨', '')}")
                                        st.info(f"**ä½¿ç”¨çŠ¶æ€**: {physical_record.get('ä½¿ç”¨çŠ¶æ€', '')}")

                                # ç´¯è®¡å®ç‰©èµ„äº§ä»·å€¼
                                physical_value = safe_get_value(physical_record, 'èµ„äº§ä»·å€¼')
                                total_physical_value += physical_value
                                valid_physical_count += 1

                            else:
                                st.error(f"âŒ æ˜ å°„çš„å®ç‰©èµ„äº§è®°å½•ä¸å­˜åœ¨: {physical_code}")

                        # å¤šå¯¹å¤šå…³ç³»çš„ä»·å€¼æ¯”è¾ƒ
                        if valid_physical_count > 0:
                            st.subheader("ğŸ’° ä»·å€¼æ¯”è¾ƒåˆ†æ")

                            financial_value = safe_get_value(financial_record, 'èµ„äº§ä»·å€¼')

                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric("è´¢åŠ¡ç³»ç»Ÿä»·å€¼", f"Â¥{financial_value:,.2f}")
                            with col2:
                                st.metric("å®ç‰©èµ„äº§æ€»ä»·å€¼", f"Â¥{total_physical_value:,.2f}")
                            with col3:
                                value_diff = financial_value - total_physical_value
                                st.metric("ä»·å€¼å·®å¼‚", f"Â¥{value_diff:,.2f}")

                            # ä»·å€¼å·®å¼‚åˆ†æ
                            if abs(value_diff) > 0.01:
                                if value_diff > 0:
                                    st.warning(f"âš ï¸ è´¢åŠ¡ç³»ç»Ÿä»·å€¼é«˜äºå®ç‰©æ€»ä»·å€¼ Â¥{value_diff:,.2f}")
                                else:
                                    st.warning(f"âš ï¸ å®ç‰©æ€»ä»·å€¼é«˜äºè´¢åŠ¡ç³»ç»Ÿä»·å€¼ Â¥{abs(value_diff):,.2f}")

                                # å·®å¼‚ç‡è®¡ç®—
                                if financial_value > 0:
                                    diff_rate = abs(value_diff) / financial_value * 100
                                    st.info(f"ğŸ“Š å·®å¼‚ç‡: {diff_rate:.2f}%")
                            else:
                                st.success("âœ… è´¢åŠ¡ä¸å®ç‰©èµ„äº§ä»·å€¼ä¸€è‡´")

                            # å¦‚æœæ˜¯å¤šä¸ªå®ç‰©èµ„äº§ï¼Œæ˜¾ç¤ºå¹³å‡ä»·å€¼
                            if valid_physical_count > 1:
                                avg_physical_value = total_physical_value / valid_physical_count
                                st.info(f"ğŸ“ˆ å®ç‰©èµ„äº§å¹³å‡ä»·å€¼: Â¥{avg_physical_value:,.2f}")

                        else:
                            st.error("âŒ æ‰€æœ‰æ˜ å°„çš„å®ç‰©èµ„äº§è®°å½•éƒ½ä¸å­˜åœ¨")

                    else:
                        st.warning("âš ï¸ è¯¥è´¢åŠ¡èµ„äº§æœªæ‰¾åˆ°å¯¹åº”çš„å®ç‰©èµ„äº§")
                else:
                    st.error("âŒ æœªæ‰¾åˆ°è¯¥èµ„äº§ç¼–å·+åºå·å¯¹åº”çš„èµ„äº§")
            else:
                st.warning("âš ï¸ è¯·è¾“å…¥èµ„äº§ç¼–å·+åºå·")

    elif query_type == "æŒ‰å®ç‰©å°è´¦ç¼–å·æŸ¥è¯¢":
        st.subheader("ğŸ” å®ç‰©å°è´¦ç¼–å·æŸ¥è¯¢")

        physical_code = st.text_input("è¯·è¾“å…¥å®ç‰©å°è´¦ç¼–å·", placeholder="ä¾‹å¦‚: PA001")

        if st.button("ğŸ” æŸ¥è¯¢å®ç‰©èµ„äº§"):
            if physical_code:
                # æŸ¥æ‰¾å®ç‰©èµ„äº§è®°å½•
                physical_record = physical_index.get(str(physical_code))

                if physical_record:
                    # æ˜¾ç¤ºå®ç‰©èµ„äº§ä¿¡æ¯
                    with st.expander("ğŸ“‹ å®ç‰©èµ„äº§è¯¦æƒ…", expanded=True):
                        col1, col2 = st.columns(2)
                        with col1:
                            st.info(f"**èµ„äº§ç¼–å·**: {physical_record.get('å›ºå®šèµ„äº§ç¼–ç ', '')}")
                            st.info(f"**èµ„äº§åç§°**: {physical_record.get('å›ºå®šèµ„äº§åç§°', '')}")
                            st.info(f"**èµ„äº§ç±»å‹**: {physical_record.get('å›ºå®šèµ„äº§ç±»å‹', '')}")
                        with col2:
                            physical_value = safe_get_value(physical_record, "èµ„äº§ä»·å€¼")
                            st.info(f"**èµ„äº§ä»·å€¼**: Â¥{physical_value:,.2f}")
                            st.info(f"**å­˜æ”¾éƒ¨é—¨**: {physical_record.get('å­˜æ”¾éƒ¨é—¨', '')}")
                            st.info(f"**ä½¿ç”¨çŠ¶æ€**: {physical_record.get('ä½¿ç”¨çŠ¶æ€', '')}")

                    # æŸ¥æ‰¾å¯¹åº”çš„è´¢åŠ¡èµ„äº§ï¼ˆæ”¯æŒå¤šå¯¹å¤šï¼‰
                    financial_codes = physical_to_financial_mapping.get(str(physical_code), [])

                    if financial_codes:
                        st.success(f"âœ… æ‰¾åˆ° {len(financial_codes)} ä¸ªå¯¹åº”çš„è´¢åŠ¡èµ„äº§")

                        # ç”¨äºè®¡ç®—æ€»ä»·å€¼
                        total_financial_value = 0
                        valid_financial_count = 0

                        for i, financial_code in enumerate(financial_codes, 1):
                            financial_record = financial_index.get(financial_code)

                            if financial_record:
                                # æ˜¾ç¤ºè´¢åŠ¡èµ„äº§ä¿¡æ¯
                                with st.expander(f"ğŸ“Š è´¢åŠ¡èµ„äº§è¯¦æƒ… #{i} - {financial_code}", expanded=True):
                                    col1, col2 = st.columns(2)
                                    with col1:
                                        st.info(f"**èµ„äº§ç¼–å·**: {financial_record.get('èµ„äº§ç¼–å·+åºå·', '')}")
                                        st.info(f"**èµ„äº§åç§°**: {financial_record.get('èµ„äº§åç§°', '')}")
                                        st.info(f"**èµ„äº§åˆ†ç±»**: {financial_record.get('èµ„äº§åˆ†ç±»', '')}")
                                    with col2:
                                        financial_value = safe_get_value(financial_record, "èµ„äº§ä»·å€¼")
                                        st.info(f"**èµ„äº§ä»·å€¼**: Â¥{financial_value:,.2f}")
                                        st.info(f"**æ‰€å±éƒ¨é—¨**: {financial_record.get('éƒ¨é—¨åç§°', '')}")
                                        st.info(f"**ä¿ç®¡äºº**: {financial_record.get('ä¿ç®¡äºº', '')}")

                                # ç´¯è®¡è´¢åŠ¡èµ„äº§ä»·å€¼
                                financial_value = safe_get_value(financial_record, 'èµ„äº§ä»·å€¼')
                                total_financial_value += financial_value
                                valid_financial_count += 1

                            else:
                                st.error(f"âŒ æ˜ å°„çš„è´¢åŠ¡èµ„äº§è®°å½•ä¸å­˜åœ¨: {financial_code}")

                        # å¤šå¯¹å¤šå…³ç³»çš„ä»·å€¼æ¯”è¾ƒ
                        if valid_financial_count > 0:
                            st.subheader("ğŸ’° ä»·å€¼æ¯”è¾ƒåˆ†æ")

                            physical_value = safe_get_value(physical_record, 'èµ„äº§ä»·å€¼')

                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric("å®ç‰©èµ„äº§ä»·å€¼", f"Â¥{physical_value:,.2f}")
                            with col2:
                                st.metric("è´¢åŠ¡ç³»ç»Ÿæ€»ä»·å€¼", f"Â¥{total_financial_value:,.2f}")
                            with col3:
                                value_diff = total_financial_value - physical_value
                                st.metric("ä»·å€¼å·®å¼‚", f"Â¥{value_diff:,.2f}")

                            # ä»·å€¼å·®å¼‚åˆ†æ
                            if abs(value_diff) > 0.01:
                                if value_diff > 0:
                                    st.warning(f"âš ï¸ è´¢åŠ¡ç³»ç»Ÿæ€»ä»·å€¼é«˜äºå®ç‰©ä»·å€¼ Â¥{value_diff:,.2f}")
                                else:
                                    st.warning(f"âš ï¸ å®ç‰©ä»·å€¼é«˜äºè´¢åŠ¡ç³»ç»Ÿæ€»ä»·å€¼ Â¥{abs(value_diff):,.2f}")

                                # å·®å¼‚ç‡è®¡ç®—
                                if physical_value > 0:
                                    diff_rate = abs(value_diff) / physical_value * 100
                                    st.info(f"ğŸ“Š å·®å¼‚ç‡: {diff_rate:.2f}%")
                            else:
                                st.success("âœ… å®ç‰©ä¸è´¢åŠ¡èµ„äº§ä»·å€¼ä¸€è‡´")

                            # å¦‚æœæ˜¯å¤šä¸ªè´¢åŠ¡èµ„äº§ï¼Œæ˜¾ç¤ºå¹³å‡ä»·å€¼
                            if valid_financial_count > 1:
                                avg_financial_value = total_financial_value / valid_financial_count
                                st.info(f"ğŸ“ˆ è´¢åŠ¡èµ„äº§å¹³å‡ä»·å€¼: Â¥{avg_financial_value:,.2f}")

                        else:
                            st.error("âŒ æ‰€æœ‰æ˜ å°„çš„è´¢åŠ¡èµ„äº§è®°å½•éƒ½ä¸å­˜åœ¨")

                    else:
                        st.warning("âš ï¸ è¯¥å®ç‰©èµ„äº§æœªæ‰¾åˆ°å¯¹åº”çš„è´¢åŠ¡èµ„äº§")
                else:
                    st.error("âŒ æœªæ‰¾åˆ°è¯¥å®ç‰©èµ„äº§ç¼–å·å¯¹åº”çš„èµ„äº§")
            else:
                st.warning("âš ï¸ è¯·è¾“å…¥å®ç‰©å°è´¦ç¼–å·")

    elif query_type == "æŒ‰èµ„äº§åç§°æœç´¢":
        st.subheader("ğŸ” èµ„äº§åç§°æœç´¢")

        search_term = st.text_input("è¯·è¾“å…¥èµ„äº§åç§°å…³é”®è¯", placeholder="ä¾‹å¦‚: ç”µè„‘ã€æ¡Œå­ã€ç©ºè°ƒ")

        if search_term:
            # åœ¨è´¢åŠ¡èµ„äº§ä¸­æœç´¢
            financial_results = [
                record for record in financial_data
                if search_term.lower() in str(record.get('èµ„äº§åç§°', '')).lower()
            ]

            # åœ¨å®ç‰©èµ„äº§ä¸­æœç´¢
            physical_results = [
                record for record in physical_data
                if search_term.lower() in str(record.get('å›ºå®šèµ„äº§åç§°', '')).lower()
            ]

            col1, col2 = st.columns(2)

            with col1:
                st.subheader(f"ğŸ“Š è´¢åŠ¡ç³»ç»Ÿæœç´¢ç»“æœ ({len(financial_results)}æ¡)")
                if financial_results:
                    for record in financial_results[:10]:  # é™åˆ¶æ˜¾ç¤ºå‰10æ¡
                        with st.expander(f"ğŸ’° {record.get('èµ„äº§åç§°', '')} - {record.get('èµ„äº§ç¼–å·+åºå·', '')}"):
                            st.write(f"**èµ„äº§åˆ†ç±»**: {record.get('èµ„äº§åˆ†ç±»', '')}")
                            asset_value = safe_get_value(record, "èµ„äº§ä»·å€¼")
                            st.write(f"**èµ„äº§ä»·å€¼**: Â¥{asset_value:,.2f}")
                            st.write(f"**æ‰€å±éƒ¨é—¨**: {record.get('éƒ¨é—¨åç§°', '')}")

                            # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„å®ç‰©èµ„äº§
                            physical_codes = financial_to_physical_mapping.get(str(record.get('èµ„äº§ç¼–å·+åºå·', '')), [])
                            if physical_codes:
                                st.success(f"âœ… å·²æ˜ å°„åˆ°å®ç‰©èµ„äº§: {', '.join(physical_codes)}")
                            else:
                                st.warning("âš ï¸ æœªæ‰¾åˆ°å¯¹åº”çš„å®ç‰©èµ„äº§")
                else:
                    st.info("æœªæ‰¾åˆ°åŒ¹é…çš„è´¢åŠ¡èµ„äº§")

            with col2:
                st.subheader(f"ğŸ“‹ å®ç‰©å°è´¦æœç´¢ç»“æœ ({len(physical_results)}æ¡)")
                if physical_results:
                    for record in physical_results[:10]:  # é™åˆ¶æ˜¾ç¤ºå‰10æ¡
                        with st.expander(f"ğŸ“¦ {record.get('å›ºå®šèµ„äº§åç§°', '')} - {record.get('å›ºå®šèµ„äº§ç¼–ç ', '')}"):
                            st.write(f"**èµ„äº§ç±»å‹**: {record.get('å›ºå®šèµ„äº§ç±»å‹', '')}")
                            asset_value = safe_get_value(record, "èµ„äº§ä»·å€¼")
                            st.write(f"**èµ„äº§ä»·å€¼**: Â¥{asset_value:,.2f}")
                            st.write(f"**å­˜æ”¾éƒ¨é—¨**: {record.get('å­˜æ”¾éƒ¨é—¨', '')}")
                            st.write(f"**ä½¿ç”¨çŠ¶æ€**: {record.get('ä½¿ç”¨çŠ¶æ€', '')}")

                            # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„è´¢åŠ¡èµ„äº§
                            financial_codes = physical_to_financial_mapping.get(str(record.get('å›ºå®šèµ„äº§ç¼–ç ', '')), [])
                            if financial_codes:
                                st.success(f"âœ… å·²æ˜ å°„åˆ°è´¢åŠ¡èµ„äº§: {', '.join(financial_codes)}")
                            else:
                                st.warning("âš ï¸ æœªæ‰¾åˆ°å¯¹åº”çš„è´¢åŠ¡èµ„äº§")
                else:
                    st.info("æœªæ‰¾åˆ°åŒ¹é…çš„å®ç‰©èµ„äº§")

    else:  # æ‰¹é‡æŸ¥è¯¢
        st.subheader("ğŸ“‹ æ‰¹é‡æŸ¥è¯¢")

        # è¾“å…¥å¤šä¸ªç¼–å·
        batch_input = st.text_area(
            "è¯·è¾“å…¥è¦æŸ¥è¯¢çš„ç¼–å·ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰",
            placeholder="FS001\nFS002\nPA001\nPA002",
            height=150
        )

        query_mode = st.radio("æŸ¥è¯¢æ¨¡å¼", ["èµ„äº§ç¼–å·+åºå·", "å®ç‰©å°è´¦ç¼–å·"])

        if batch_input and st.button("å¼€å§‹æ‰¹é‡æŸ¥è¯¢"):
            codes = [code.strip() for code in batch_input.split('\n') if code.strip()]

            if codes:
                results = []

                for code in codes:
                    if query_mode == "èµ„äº§ç¼–å·+åºå·":
                        financial_record = financial_index.get(str(code))
                        if financial_record:
                            physical_codes = financial_to_physical_mapping.get(str(code), [])
                            if physical_codes:
                                # å¤„ç†å¤šå¯¹å¤šå…³ç³»
                                physical_names = []
                                total_physical_value = 0
                                for pc in physical_codes:
                                    physical_record = physical_index.get(pc)
                                    if physical_record:
                                        physical_names.append(physical_record.get('å›ºå®šèµ„äº§åç§°', ''))
                                        total_physical_value += safe_get_value(physical_record, 'èµ„äº§ä»·å€¼')

                                results.append({
                                    "æŸ¥è¯¢ç¼–å·": code,
                                    "è´¢åŠ¡èµ„äº§åç§°": financial_record.get('èµ„äº§åç§°', ''),
                                    "è´¢åŠ¡èµ„äº§ä»·å€¼": safe_get_value(financial_record, 'èµ„äº§ä»·å€¼'),
                                    "å¯¹åº”å®ç‰©ç¼–å·": ', '.join(physical_codes),
                                    "å®ç‰©èµ„äº§åç§°": ', '.join(physical_names),
                                    "å®ç‰©èµ„äº§ä»·å€¼": total_physical_value,
                                    "çŠ¶æ€": "å·²æ˜ å°„"
                                })
                            else:
                                results.append({
                                    "æŸ¥è¯¢ç¼–å·": code,
                                    "è´¢åŠ¡èµ„äº§åç§°": financial_record.get('èµ„äº§åç§°', ''),
                                    "è´¢åŠ¡èµ„äº§ä»·å€¼": safe_get_value(financial_record, 'èµ„äº§ä»·å€¼'),
                                    "å¯¹åº”å®ç‰©ç¼–å·": "æœªæ˜ å°„",
                                    "å®ç‰©èµ„äº§åç§°": "æœªæ˜ å°„",
                                    "å®ç‰©èµ„äº§ä»·å€¼": 0,
                                    "çŠ¶æ€": "æœªæ˜ å°„"
                                })
                        else:
                            results.append({
                                "æŸ¥è¯¢ç¼–å·": code,
                                "è´¢åŠ¡èµ„äº§åç§°": "æœªæ‰¾åˆ°",
                                "è´¢åŠ¡èµ„äº§ä»·å€¼": 0,
                                "å¯¹åº”å®ç‰©ç¼–å·": "æœªæ‰¾åˆ°",
                                "å®ç‰©èµ„äº§åç§°": "æœªæ‰¾åˆ°",
                                "å®ç‰©èµ„äº§ä»·å€¼": 0,
                                "çŠ¶æ€": "ä¸å­˜åœ¨"
                            })

                    else:  # å®ç‰©å°è´¦ç¼–å·
                        physical_record = physical_index.get(str(code))
                        if physical_record:
                            financial_codes = physical_to_financial_mapping.get(str(code), [])
                            if financial_codes:
                                # å¤„ç†å¤šå¯¹å¤šå…³ç³»
                                financial_names = []
                                total_financial_value = 0
                                for fc in financial_codes:
                                    financial_record = financial_index.get(fc)
                                    if financial_record:
                                        financial_names.append(financial_record.get('èµ„äº§åç§°', ''))
                                        total_financial_value += safe_get_value(financial_record, 'èµ„äº§ä»·å€¼')

                                results.append({
                                    "æŸ¥è¯¢ç¼–å·": code,
                                    "å®ç‰©èµ„äº§åç§°": physical_record.get('å›ºå®šèµ„äº§åç§°', ''),
                                    "å®ç‰©èµ„äº§ä»·å€¼": safe_get_value(physical_record, 'èµ„äº§ä»·å€¼'),
                                    "å¯¹åº”è´¢åŠ¡ç¼–å·": ', '.join(financial_codes),
                                    "è´¢åŠ¡èµ„äº§åç§°": ', '.join(financial_names),
                                    "è´¢åŠ¡èµ„äº§ä»·å€¼": total_financial_value,
                                    "çŠ¶æ€": "å·²æ˜ å°„"
                                })
                            else:
                                results.append({
                                    "æŸ¥è¯¢ç¼–å·": code,
                                    "å®ç‰©èµ„äº§åç§°": physical_record.get('å›ºå®šèµ„äº§åç§°', ''),
                                    "å®ç‰©èµ„äº§ä»·å€¼": safe_get_value(physical_record, 'èµ„äº§ä»·å€¼'),
                                    "å¯¹åº”è´¢åŠ¡ç¼–å·": "æœªæ˜ å°„",
                                    "è´¢åŠ¡èµ„äº§åç§°": "æœªæ˜ å°„",
                                    "è´¢åŠ¡èµ„äº§ä»·å€¼": 0,
                                    "çŠ¶æ€": "æœªæ˜ å°„"
                                })
                        else:
                            results.append({
                                "æŸ¥è¯¢ç¼–å·": code,
                                "å®ç‰©èµ„äº§åç§°": "æœªæ‰¾åˆ°",
                                "å®ç‰©èµ„äº§ä»·å€¼": 0,
                                "å¯¹åº”è´¢åŠ¡ç¼–å·": "æœªæ‰¾åˆ°",
                                "è´¢åŠ¡èµ„äº§åç§°": "æœªæ‰¾åˆ°",
                                "è´¢åŠ¡èµ„äº§ä»·å€¼": 0,
                                "çŠ¶æ€": "ä¸å­˜åœ¨"
                            })

                # æ˜¾ç¤ºç»“æœ
                if results:
                    df = pd.DataFrame(results)
                    st.subheader(f"ğŸ“Š æ‰¹é‡æŸ¥è¯¢ç»“æœ (å…±{len(results)}æ¡)")
                    st.dataframe(df, use_container_width=True)

                    # ç»Ÿè®¡ä¿¡æ¯
                    mapped_count = len([r for r in results if r["çŠ¶æ€"] == "å·²æ˜ å°„"])
                    unmapped_count = len([r for r in results if r["çŠ¶æ€"] == "æœªæ˜ å°„"])
                    not_found_count = len([r for r in results if r["çŠ¶æ€"] == "ä¸å­˜åœ¨"])

                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("å·²æ˜ å°„", mapped_count)
                    with col2:
                        st.metric("æœªæ˜ å°„", unmapped_count)
                    with col3:
                        st.metric("ä¸å­˜åœ¨", not_found_count)

                    # å¯¼å‡ºåŠŸèƒ½
                    if st.button("ğŸ“¥ å¯¼å‡ºæŸ¥è¯¢ç»“æœ"):
                        try:
                            output = io.BytesIO()
                            df.to_excel(output, index=False, engine='openpyxl')
                            output.seek(0)
                            st.download_button(
                                label="ä¸‹è½½Excelæ–‡ä»¶",
                                data=output,
                                file_name=f"æ‰¹é‡æŸ¥è¯¢ç»“æœ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                            )
                        except Exception as e:
                            st.error(f"å¯¼å‡ºå¤±è´¥: {str(e)}")


def data_statistics_page():
    """æ•°æ®ç»Ÿè®¡é¡µé¢"""
    st.header("ğŸ“Š æ•°æ®ç»Ÿè®¡åˆ†æ")

    # ========== æ•°æ®åŠ è½½å’ŒéªŒè¯ ==========
    with st.spinner("åŠ è½½æ•°æ®ä¸­..."):
        financial_data = load_data(FINANCIAL_DATA_FILE)
        physical_data = load_data(PHYSICAL_DATA_FILE)
        mapping_data = load_data(MAPPING_DATA_FILE)

    if not all([financial_data, physical_data, mapping_data]):
        missing = []
        if not financial_data:
            missing.append("è´¢åŠ¡ç³»ç»Ÿæ•°æ®")
        if not physical_data:
            missing.append("å®ç‰©å°è´¦æ•°æ®")
        if not mapping_data:
            missing.append("æ˜ å°„å…³ç³»æ•°æ®")
        st.warning(f"âš ï¸ è¯·å…ˆå¯¼å…¥ï¼š{', '.join(missing)}")
        return

    # ========== åˆ›å»ºæ•°æ®ç´¢å¼• ==========
    financial_index = create_data_index(financial_data, "èµ„äº§ç¼–å·+åºå·")
    physical_index = create_data_index(physical_data, "å›ºå®šèµ„äº§ç¼–ç ")
    financial_to_physical_mapping, physical_to_financial_mapping = create_mapping_index(mapping_data)

    # ========== é¢„è®¡ç®—ç»Ÿè®¡æ•°æ® ==========
    # è®¡ç®—åŒ¹é…æ•°é‡
    matched_financial = len(
        [f for f in financial_data if str(f.get("èµ„äº§ç¼–å·+åºå·", "")).strip() in financial_to_physical_mapping])
    matched_physical = len(
        [p for p in physical_data if str(p.get("å›ºå®šèµ„äº§ç¼–ç ", "")).strip() in physical_to_financial_mapping])

    # è®¡ç®—ä»·å€¼
    financial_total_value = sum(safe_get_value(f, "èµ„äº§ä»·å€¼") for f in financial_data)

    # å¤„ç†å®ç‰©èµ„äº§ä»·å€¼è®¡ç®—ï¼ˆå»é‡å’Œæ ¸ç®—ç­›é€‰ï¼‰
    physical_df = pd.DataFrame(physical_data)
    if len(physical_df) > 0 and "å›ºå®šèµ„äº§ç¼–ç " in physical_df.columns:
        if "æ˜¯å¦æ ¸ç®—" in physical_df.columns:
            accounting_mask = physical_df["æ˜¯å¦æ ¸ç®—"].astype(str).str.strip().isin(
                ["æ˜¯", "Y", "y", "Yes", "YES", "1", "True", "true"])
            physical_df_accounting = physical_df[accounting_mask]
            non_accounting_count = len(physical_df) - len(physical_df_accounting)
            physical_df_deduped = physical_df_accounting.drop_duplicates(subset=['å›ºå®šèµ„äº§ç¼–ç '], keep='first')
            physical_duplicate_count = len(physical_df_accounting) - len(physical_df_deduped)
        else:
            physical_df_deduped = physical_df.drop_duplicates(subset=['å›ºå®šèµ„äº§ç¼–ç '], keep='first')
            physical_duplicate_count = len(physical_df) - len(physical_df_deduped)
            non_accounting_count = 0

        physical_total_value = sum(
            safe_get_value(row.to_dict(), "å›ºå®šèµ„äº§åŸå€¼") for _, row in physical_df_deduped.iterrows())

        # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
        st.session_state['physical_duplicate_count'] = physical_duplicate_count
        st.session_state['physical_deduped_count'] = len(physical_df_deduped)
        st.session_state['physical_original_count'] = len(physical_df)
    else:
        physical_total_value = sum(safe_get_value(p, "èµ„äº§ä»·å€¼") for p in physical_data)
        physical_duplicate_count = 0
        non_accounting_count = 0
        st.session_state['physical_duplicate_count'] = 0
        st.session_state['physical_deduped_count'] = len(physical_data)
        st.session_state['physical_original_count'] = len(physical_data)

    # ========== ä¸»è¦å†…å®¹åŒºåŸŸ ==========
    tab_summary, tab_analysis, tab_charts = st.tabs(["ğŸ“Š ç»Ÿè®¡æ¦‚è§ˆ", "ğŸ” å·®å¼‚åˆ†æ", "ğŸ“ˆ å¯è§†åŒ–åˆ†æ"])

    # ========== Tab 1: ç»Ÿè®¡æ¦‚è§ˆ ==========
    with tab_summary:
        # åŸºç¡€ç»Ÿè®¡
        st.subheader("ğŸ“‹ åŸºç¡€ç»Ÿè®¡ä¿¡æ¯")
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric("è´¢åŠ¡èµ„äº§æ€»æ•°", f"{len(financial_data):,}")
            st.caption(f"å·²åŒ¹é…: {matched_financial:,}")

        with col2:
            deduped_count = st.session_state.get('physical_deduped_count', len(physical_data))
            original_count = st.session_state.get('physical_original_count', len(physical_data))
            duplicate_count = st.session_state.get('physical_duplicate_count', 0)

            st.metric("å®ç‰©èµ„äº§æ€»æ•°", f"{deduped_count:,}")
            if duplicate_count > 0:
                st.caption(f"åŸå§‹: {original_count:,} | å»é‡: {duplicate_count}")
            else:
                st.caption(f"å·²åŒ¹é…: {matched_physical:,}")

        with col3:
            st.metric("æ˜ å°„å…³ç³»æ€»æ•°", f"{len(mapping_data):,}")

        with col4:
            overall_match_rate = (
                        (matched_financial + matched_physical) / (len(financial_data) + len(physical_data)) * 100) if (
                                                                                                                                  len(financial_data) + len(
                                                                                                                              physical_data)) > 0 else 0
            st.metric("æ•´ä½“åŒ¹é…ç‡", f"{overall_match_rate:.1f}%")

        st.divider()

        # åŒ¹é…ç‡ç»Ÿè®¡
        st.subheader("ğŸ¯ åŒ¹é…ç‡ç»Ÿè®¡")
        col1, col2 = st.columns(2)

        with col1:
            financial_match_rate = (matched_financial / len(financial_data) * 100) if financial_data else 0
            st.metric("è´¢åŠ¡èµ„äº§åŒ¹é…ç‡", f"{financial_match_rate:.1f}%")

            progress_val = financial_match_rate / 100
            st.progress(progress_val)

            unmatched_financial = len(financial_data) - matched_financial
            st.caption(f"æœªåŒ¹é…: {unmatched_financial:,} é¡¹")

        with col2:
            physical_match_rate = (matched_physical / len(physical_data) * 100) if physical_data else 0
            st.metric("å®ç‰©èµ„äº§åŒ¹é…ç‡", f"{physical_match_rate:.1f}%")

            progress_val = physical_match_rate / 100
            st.progress(progress_val)

            unmatched_physical = len(physical_data) - matched_physical
            st.caption(f"æœªåŒ¹é…: {unmatched_physical:,} é¡¹")

        st.divider()

        # ä»·å€¼ç»Ÿè®¡
        st.subheader("ğŸ’° ä»·å€¼ç»Ÿè®¡")

        # æ•°æ®å¤„ç†è¯´æ˜
        if non_accounting_count > 0 or physical_duplicate_count > 0:
            with st.expander("â„¹ï¸ æ•°æ®å¤„ç†è¯´æ˜", expanded=False):
                if non_accounting_count > 0:
                    st.info(f"ğŸ’¡ å·²æ’é™¤ {non_accounting_count:,} æ¡éæ ¸ç®—èµ„äº§")
                if physical_duplicate_count > 0:
                    st.info(f"ğŸ’¡ å·²å»é‡ {physical_duplicate_count:,} æ¡é‡å¤è®°å½•")

        col1, col2, col3 = st.columns(3)

        with col1:
            st.metric("è´¢åŠ¡èµ„äº§æ€»ä»·å€¼", f"Â¥{financial_total_value:,.2f}")

        with col2:
            st.metric("å®ç‰©èµ„äº§æ€»ä»·å€¼", f"Â¥{physical_total_value:,.2f}")

        with col3:
            total_diff = financial_total_value - physical_total_value
            diff_color = "normal"
            if abs(total_diff) > 100000:
                diff_color = "inverse"

            st.metric("æ€»ä»·å€¼å·®å¼‚", f"Â¥{total_diff:,.2f}", delta_color=diff_color)

            if abs(total_diff) > 100000:
                st.caption("ğŸ”´ å·®å¼‚è¾ƒå¤§ï¼Œéœ€è¦å…³æ³¨")
            elif abs(total_diff) > 10000:
                st.caption("ğŸŸ¡ å­˜åœ¨å·®å¼‚")
            else:
                st.caption("ğŸŸ¢ å·®å¼‚è¾ƒå°")

    # ========== Tab 2: å·®å¼‚åˆ†æ ==========
    with tab_analysis:
        st.subheader("ğŸ” ä»·å€¼å·®å¼‚è¯¦ç»†åˆ†æ")

        # æ•°æ®éªŒè¯
        if not all([financial_data, physical_data, mapping_data]):
            st.warning("âš ï¸ ç¼ºå°‘å¿…è¦æ•°æ®ï¼Œæ— æ³•è¿›è¡Œå·®å¼‚åˆ†æ")
            return

        # è®¡ç®—å·®å¼‚æ•°æ®
        with st.spinner("æ­£åœ¨è®¡ç®—å·®å¼‚æ•°æ®..."):
            # åˆ›å»ºåŒ¹é…é›†åˆ
            matched_financial_codes = set()
            matched_physical_codes = set()

            # éå†æ˜ å°„æ•°æ®è·å–åŒ¹é…çš„ç¼–ç 
            for mapping_record in mapping_data:
                financial_code = str(mapping_record.get("èµ„äº§ç¼–å·+åºå·", "")).strip()
                physical_code = str(mapping_record.get("å›ºå®šèµ„äº§ç¼–ç ", "")).strip()

                if financial_code and physical_code:
                    if financial_code in financial_index and physical_code in physical_index:
                        matched_financial_codes.add(financial_code)
                        matched_physical_codes.add(physical_code)

            # åˆ†ç±»èµ„äº§æ•°æ®
            matched_financial = [f for f in financial_data
                                 if str(f.get("èµ„äº§ç¼–å·+åºå·", "")).strip() in matched_financial_codes]
            matched_physical = [p for p in physical_data
                                if str(p.get("å›ºå®šèµ„äº§ç¼–ç ", "")).strip() in matched_physical_codes]

            unmatched_financial = [f for f in financial_data
                                   if str(f.get("èµ„äº§ç¼–å·+åºå·", "")).strip() not in matched_financial_codes]
            unmatched_physical = [p for p in physical_data
                                  if str(p.get("å›ºå®šèµ„äº§ç¼–ç ", "")).strip() not in matched_physical_codes]

            # è®¡ç®—æ±‡æ€»æ•°æ®
            def calculate_totals(data_list, is_financial=True):
                if is_financial:
                    original_key = "èµ„äº§ä»·å€¼"
                    depreciation_key = "ç´¯è®¡æŠ˜æ—§"
                    net_key = "å‡€é¢"
                else:
                    original_key = "å›ºå®šèµ„äº§åŸå€¼"
                    depreciation_key = "ç´¯è®¡æŠ˜æ—§"
                    net_key = None

                total_original = sum(safe_get_value(item, original_key, 0) for item in data_list)
                total_depreciation = sum(safe_get_value(item, depreciation_key, 0) for item in data_list)

                if is_financial:
                    total_net = sum(safe_get_value(item, net_key, 0) for item in data_list)
                    if total_net == 0:  # å¦‚æœå‡€é¢ä¸º0ï¼Œç”¨åŸå€¼-ç´¯è®¡æŠ˜æ—§è®¡ç®—
                        total_net = max(0, total_original - total_depreciation)
                else:
                    total_net = max(0, total_original - total_depreciation)

                return {
                    'original': total_original,
                    'depreciation': total_depreciation,
                    'net': total_net,
                    'count': len(data_list)
                }

            # è®¡ç®—å„ç±»æ±‡æ€»
            total_financial = calculate_totals(financial_data, True)
            total_physical = calculate_totals(physical_data, False)
            matched_financial_totals = calculate_totals(matched_financial, True)
            matched_physical_totals = calculate_totals(matched_physical, False)
            unmatched_financial_totals = calculate_totals(unmatched_financial, True)
            unmatched_physical_totals = calculate_totals(unmatched_physical, False)

        # ========== 1. æ€»ä½“å·®å¼‚å¯¹æ¯” ==========
        with tab_analysis:
            st.subheader("ğŸ” ä»·å€¼å·®å¼‚è¯¦ç»†åˆ†æ")

            # æ•°æ®éªŒè¯
            if not all([financial_data, physical_data, mapping_data]):
                st.warning("âš ï¸ ç¼ºå°‘å¿…è¦æ•°æ®ï¼Œæ— æ³•è¿›è¡Œå·®å¼‚åˆ†æ")
            else:
                # è®¡ç®—å·®å¼‚æ•°æ®
                with st.spinner("æ­£åœ¨è®¡ç®—å·®å¼‚æ•°æ®..."):
                    # åˆ›å»ºåŒ¹é…é›†åˆ
                    matched_financial_codes = set()
                    matched_physical_codes = set()

                    # éå†æ˜ å°„æ•°æ®è·å–åŒ¹é…çš„ç¼–ç 
                    for mapping_record in mapping_data:
                        financial_code = str(mapping_record.get("èµ„äº§ç¼–å·+åºå·", "")).strip()
                        physical_code = str(mapping_record.get("å›ºå®šèµ„äº§ç¼–ç ", "")).strip()

                        if financial_code and physical_code:
                            if financial_code in financial_index and physical_code in physical_index:
                                matched_financial_codes.add(financial_code)
                                matched_physical_codes.add(physical_code)

                    # åˆ†ç±»èµ„äº§æ•°æ®
                    matched_financial = [f for f in financial_data
                                         if str(f.get("èµ„äº§ç¼–å·+åºå·", "")).strip() in matched_financial_codes]
                    matched_physical = [p for p in physical_data
                                        if str(p.get("å›ºå®šèµ„äº§ç¼–ç ", "")).strip() in matched_physical_codes]

                    unmatched_financial = [f for f in financial_data
                                           if str(f.get("èµ„äº§ç¼–å·+åºå·", "")).strip() not in matched_financial_codes]
                    unmatched_physical = [p for p in physical_data
                                          if str(p.get("å›ºå®šèµ„äº§ç¼–ç ", "")).strip() not in matched_physical_codes]

                    # å®šä¹‰åŒ¹é…æ•°é‡å˜é‡
                    matched_count = len(matched_financial)

                    # è®¡ç®—æ±‡æ€»æ•°æ®
                    def calculate_totals(data_list, is_financial=True):
                        if is_financial:
                            original_key = "èµ„äº§ä»·å€¼"
                            depreciation_key = "ç´¯è®¡æŠ˜æ—§"
                            net_key = "å‡€é¢"
                        else:
                            original_key = "å›ºå®šèµ„äº§åŸå€¼"
                            depreciation_key = "ç´¯è®¡æŠ˜æ—§"
                            net_key = None

                        total_original = sum(safe_get_value(item, original_key, 0) for item in data_list)
                        total_depreciation = sum(safe_get_value(item, depreciation_key, 0) for item in data_list)

                        if is_financial:
                            total_net = sum(safe_get_value(item, net_key, 0) for item in data_list)
                            if total_net == 0:  # å¦‚æœå‡€é¢ä¸º0ï¼Œç”¨åŸå€¼-ç´¯è®¡æŠ˜æ—§è®¡ç®—
                                total_net = max(0, total_original - total_depreciation)
                        else:
                            total_net = max(0, total_original - total_depreciation)

                        return {
                            'original': total_original,
                            'depreciation': total_depreciation,
                            'net': total_net,
                            'count': len(data_list)
                        }

                    # è®¡ç®—å„ç±»æ±‡æ€»
                    total_financial = calculate_totals(financial_data, True)
                    total_physical = calculate_totals(physical_data, False)
                    matched_financial_totals = calculate_totals(matched_financial, True)
                    matched_physical_totals = calculate_totals(matched_physical, False)
                    unmatched_financial_totals = calculate_totals(unmatched_financial, True)
                    unmatched_physical_totals = calculate_totals(unmatched_physical, False)

                # ========== 1. æ€»ä½“å·®å¼‚å¯¹æ¯”ï¼ˆæ¨ªå‘å±•ç¤ºï¼‰ ==========
                st.markdown("### ğŸ’° æ€»ä½“å·®å¼‚å¯¹æ¯”")

                # åˆ›å»ºæ€»ä½“å¯¹æ¯”è¡¨æ ¼
                total_comparison_data = {
                    "é¡¹ç›®": ["èµ„äº§åŸå€¼", "ç´¯è®¡æŠ˜æ—§", "èµ„äº§å‡€é¢"],
                    "è´¢åŠ¡ç³»ç»Ÿ": [
                        f"Â¥{total_financial['original']:,.2f}",
                        f"Â¥{total_financial['depreciation']:,.2f}",
                        f"Â¥{total_financial['net']:,.2f}"
                    ],
                    "å®ç‰©ç³»ç»Ÿ": [
                        f"Â¥{total_physical['original']:,.2f}",
                        f"Â¥{total_physical['depreciation']:,.2f}",
                        f"Â¥{total_physical['net']:,.2f}"
                    ],
                    "å·®å¼‚é‡‘é¢": [
                        f"Â¥{total_financial['original'] - total_physical['original']:,.2f}",
                        f"Â¥{total_financial['depreciation'] - total_physical['depreciation']:,.2f}",
                        f"Â¥{total_financial['net'] - total_physical['net']:,.2f}"
                    ]
                }

                total_comparison_df = pd.DataFrame(total_comparison_data)
                st.dataframe(total_comparison_df, use_container_width=True, hide_index=True)

                # æ€»ä½“å·®å¼‚çŠ¶æ€
                total_original_diff = total_financial['original'] - total_physical['original']
                total_depreciation_diff = total_financial['depreciation'] - total_physical['depreciation']
                total_net_diff = total_financial['net'] - total_physical['net']

                def get_status_emoji(diff_value):
                    if abs(diff_value) > 1000000:
                        return "ğŸ”´ é‡å¤§å·®å¼‚"
                    elif abs(diff_value) > 100000:
                        return "ğŸŸ¡ ä¸­ç­‰å·®å¼‚"
                    elif abs(diff_value) > 1000:
                        return "ğŸŸ  è½»å¾®å·®å¼‚"
                    else:
                        return "ğŸŸ¢ åŸºæœ¬ä¸€è‡´"

                col_status1, col_status2, col_status3 = st.columns(3)
                with col_status1:
                    st.info(f"**åŸå€¼å·®å¼‚çŠ¶æ€**: {get_status_emoji(total_original_diff)}")
                with col_status2:
                    st.info(f"**æŠ˜æ—§å·®å¼‚çŠ¶æ€**: {get_status_emoji(total_depreciation_diff)}")
                with col_status3:
                    st.info(f"**å‡€é¢å·®å¼‚çŠ¶æ€**: {get_status_emoji(total_net_diff)}")

                st.divider()

                # ========== 2. å·²åŒ¹é…èµ„äº§åˆ†æï¼ˆæ¨ªå‘å±•ç¤ºï¼‰ ==========
                st.markdown("### ğŸ¯ å·²åŒ¹é…èµ„äº§åˆ†æ")

                # å·²åŒ¹é…å·®å¼‚è®¡ç®—
                matched_original_diff = matched_financial_totals['original'] - matched_physical_totals['original']
                matched_depreciation_diff = matched_financial_totals['depreciation'] - matched_physical_totals[
                    'depreciation']
                matched_net_diff = matched_financial_totals['net'] - matched_physical_totals['net']

                # å·²åŒ¹é…å¯¹æ¯”è¡¨æ ¼
                matched_comparison_data = {
                    "é¡¹ç›®": ["èµ„äº§åŸå€¼", "ç´¯è®¡æŠ˜æ—§", "èµ„äº§å‡€é¢"],
                    "è´¢åŠ¡ç³»ç»Ÿ": [
                        f"Â¥{matched_financial_totals['original']:,.2f}",
                        f"Â¥{matched_financial_totals['depreciation']:,.2f}",
                        f"Â¥{matched_financial_totals['net']:,.2f}"
                    ],
                    "å®ç‰©ç³»ç»Ÿ": [
                        f"Â¥{matched_physical_totals['original']:,.2f}",
                        f"Â¥{matched_physical_totals['depreciation']:,.2f}",
                        f"Â¥{matched_physical_totals['net']:,.2f}"
                    ],
                    "å·®å¼‚é‡‘é¢": [
                        f"Â¥{matched_original_diff:,.2f}",
                        f"Â¥{matched_depreciation_diff:,.2f}",
                        f"Â¥{matched_net_diff:,.2f}"
                    ],
                    "å æ€»èµ„äº§æ¯”ä¾‹": [
                        f"{(matched_financial_totals['original'] / total_financial['original'] * 100):.1f}%" if
                        total_financial['original'] > 0 else "0%",
                        f"{(matched_financial_totals['depreciation'] / total_financial['depreciation'] * 100):.1f}%" if
                        total_financial['depreciation'] > 0 else "0%",
                        f"{(matched_financial_totals['net'] / total_financial['net'] * 100):.1f}%" if total_financial[
                                                                                                          'net'] > 0 else "0%"
                    ]
                }

                matched_comparison_df = pd.DataFrame(matched_comparison_data)
                st.dataframe(matched_comparison_df, use_container_width=True, hide_index=True)

                # å·²åŒ¹é…èµ„äº§åŸºæœ¬ä¿¡æ¯
                col_matched1, col_matched2, col_matched3 = st.columns(3)
                with col_matched1:
                    st.metric("å·²åŒ¹é…èµ„äº§æ•°é‡", f"{matched_financial_totals['count']:,} é¡¹")
                with col_matched2:
                    overall_match_rate = (matched_count / len(financial_data) * 100) if financial_data else 0
                    st.metric("æ€»ä½“åŒ¹é…ç‡", f"{overall_match_rate:.1f}%")
                with col_matched3:
                    st.metric("å·²åŒ¹é…èµ„äº§å æ¯”",
                              f"{(matched_financial_totals['original'] / total_financial['original'] * 100):.1f}%" if
                              total_financial['original'] > 0 else "0%")

                st.divider()

                # ========== 3. æœªåŒ¹é…èµ„äº§åˆ†æï¼ˆæ¨ªå‘å±•ç¤ºï¼‰ ==========
                st.markdown("### âš ï¸ æœªåŒ¹é…èµ„äº§åˆ†æ")

                # æœªåŒ¹é…å¯¹æ¯”è¡¨æ ¼
                unmatched_comparison_data = {
                    "èµ„äº§ç±»å‹": ["æœªåŒ¹é…è´¢åŠ¡èµ„äº§", "æœªåŒ¹é…å®ç‰©èµ„äº§"],
                    "èµ„äº§åŸå€¼": [
                        f"Â¥{unmatched_financial_totals['original']:,.2f}",
                        f"Â¥{unmatched_physical_totals['original']:,.2f}"
                    ],
                    "ç´¯è®¡æŠ˜æ—§": [
                        f"Â¥{unmatched_financial_totals['depreciation']:,.2f}",
                        f"Â¥{unmatched_physical_totals['depreciation']:,.2f}"
                    ],
                    "èµ„äº§å‡€é¢": [
                        f"Â¥{unmatched_financial_totals['net']:,.2f}",
                        f"Â¥{unmatched_physical_totals['net']:,.2f}"
                    ],
                    "èµ„äº§æ•°é‡": [
                        f"{unmatched_financial_totals['count']:,} é¡¹",
                        f"{unmatched_physical_totals['count']:,} é¡¹"
                    ],
                    "å æ¯”": [
                        f"{(unmatched_financial_totals['original'] / total_financial['original'] * 100):.1f}%" if
                        total_financial['original'] > 0 else "0%",
                        f"{(unmatched_physical_totals['original'] / total_physical['original'] * 100):.1f}%" if
                        total_physical['original'] > 0 else "0%"
                    ]
                }

                unmatched_comparison_df = pd.DataFrame(unmatched_comparison_data)
                st.dataframe(unmatched_comparison_df, use_container_width=True, hide_index=True)

                # æœªåŒ¹é…èµ„äº§å·®å¼‚åˆ†æ
                unmatched_original_diff = unmatched_financial_totals['original'] - unmatched_physical_totals['original']
                unmatched_depreciation_diff = unmatched_financial_totals['depreciation'] - unmatched_physical_totals[
                    'depreciation']
                unmatched_net_diff = unmatched_financial_totals['net'] - unmatched_physical_totals['net']

                st.markdown("#### ğŸ“Š æœªåŒ¹é…èµ„äº§å·®å¼‚")
                col_unmatched1, col_unmatched2, col_unmatched3 = st.columns(3)

                with col_unmatched1:
                    st.metric("åŸå€¼å·®å¼‚", f"Â¥{unmatched_original_diff:,.2f}",
                              help="è´¢åŠ¡æœªåŒ¹é… - å®ç‰©æœªåŒ¹é…")
                with col_unmatched2:
                    st.metric("æŠ˜æ—§å·®å¼‚", f"Â¥{unmatched_depreciation_diff:,.2f}",
                              help="è´¢åŠ¡æœªåŒ¹é… - å®ç‰©æœªåŒ¹é…")
                with col_unmatched3:
                    st.metric("å‡€é¢å·®å¼‚", f"Â¥{unmatched_net_diff:,.2f}",
                              help="è´¢åŠ¡æœªåŒ¹é… - å®ç‰©æœªåŒ¹é…")

                st.divider()

                # ========== 4. å¯è§†åŒ–å›¾è¡¨ ==========
                st.markdown("### ğŸ“Š å·®å¼‚å¯è§†åŒ–åˆ†æ")

                # åˆ›å»ºå›¾è¡¨æ•°æ®
                chart_col1, chart_col2 = st.columns(2)

                with chart_col1:
                    st.markdown("#### ğŸ“ˆ åŒ¹é…çŠ¶æ€åˆ†å¸ƒ")

                    # å‡†å¤‡åŒ¹é…çŠ¶æ€æ•°æ®
                    financial_match_data = pd.DataFrame({
                        "çŠ¶æ€": ["å·²åŒ¹é…", "æœªåŒ¹é…"],
                        "æ•°é‡": [matched_count, len(unmatched_financial)],
                        "é‡‘é¢": [matched_financial_totals['original'], unmatched_financial_totals['original']]
                    })

                    physical_match_data = pd.DataFrame({
                        "çŠ¶æ€": ["å·²åŒ¹é…", "æœªåŒ¹é…"],
                        "æ•°é‡": [len(matched_physical), len(unmatched_physical)],
                        "é‡‘é¢": [matched_physical_totals['original'], unmatched_physical_totals['original']]
                    })

                    # å°è¯•ä½¿ç”¨plotlyç»˜å›¾
                    try:
                        import plotly.express as px
                        import plotly.graph_objects as go
                        from plotly.subplots import make_subplots

                        # åˆ›å»ºå­å›¾
                        fig = make_subplots(
                            rows=1, cols=2,
                            subplot_titles=('è´¢åŠ¡èµ„äº§åŒ¹é…çŠ¶æ€', 'å®ç‰©èµ„äº§åŒ¹é…çŠ¶æ€'),
                            specs=[[{"type": "pie"}, {"type": "pie"}]]
                        )

                        # è´¢åŠ¡èµ„äº§é¥¼å›¾
                        fig.add_trace(
                            go.Pie(
                                labels=financial_match_data["çŠ¶æ€"],
                                values=financial_match_data["é‡‘é¢"],
                                name="è´¢åŠ¡èµ„äº§",
                                marker_colors=['#2E8B57', '#DC143C']
                            ),
                            row=1, col=1
                        )

                        # å®ç‰©èµ„äº§é¥¼å›¾
                        fig.add_trace(
                            go.Pie(
                                labels=physical_match_data["çŠ¶æ€"],
                                values=physical_match_data["é‡‘é¢"],
                                name="å®ç‰©èµ„äº§",
                                marker_colors=['#4682B4', '#FF6347']
                            ),
                            row=1, col=2
                        )

                        fig.update_layout(height=400, showlegend=True)
                        st.plotly_chart(fig, use_container_width=True)

                    except ImportError:
                        # ä½¿ç”¨streamlitåŸç”Ÿå›¾è¡¨
                        st.write("**è´¢åŠ¡èµ„äº§åŒ¹é…çŠ¶æ€**")
                        fin_chart_data = pd.DataFrame({
                            'å·²åŒ¹é…': [matched_financial_totals['original']],
                            'æœªåŒ¹é…': [unmatched_financial_totals['original']]
                        })
                        st.bar_chart(fin_chart_data)

                        st.write("**å®ç‰©èµ„äº§åŒ¹é…çŠ¶æ€**")
                        phy_chart_data = pd.DataFrame({
                            'å·²åŒ¹é…': [matched_physical_totals['original']],
                            'æœªåŒ¹é…': [unmatched_physical_totals['original']]
                        })
                        st.bar_chart(phy_chart_data)

                with chart_col2:
                    st.markdown("#### ğŸ“Š å·®å¼‚å¯¹æ¯”åˆ†æ")

                    # å‡†å¤‡å·®å¼‚å¯¹æ¯”æ•°æ®
                    diff_comparison_data = pd.DataFrame({
                        "å·®å¼‚ç±»å‹": ["èµ„äº§åŸå€¼", "ç´¯è®¡æŠ˜æ—§", "èµ„äº§å‡€é¢"],
                        "æ€»ä½“å·®å¼‚": [total_original_diff, total_depreciation_diff, total_net_diff],
                        "å·²åŒ¹é…å·®å¼‚": [matched_original_diff, matched_depreciation_diff, matched_net_diff],
                        "æœªåŒ¹é…å·®å¼‚": [unmatched_original_diff, unmatched_depreciation_diff, unmatched_net_diff]
                    })

                    try:
                        # å·®å¼‚å¯¹æ¯”æŸ±çŠ¶å›¾
                        fig_diff = px.bar(
                            diff_comparison_data,
                            x="å·®å¼‚ç±»å‹",
                            y=["æ€»ä½“å·®å¼‚", "å·²åŒ¹é…å·®å¼‚", "æœªåŒ¹é…å·®å¼‚"],
                            title="å„ç±»å·®å¼‚å¯¹æ¯”åˆ†æ",
                            barmode="group",
                            color_discrete_map={
                                "æ€»ä½“å·®å¼‚": "#FF6B6B",
                                "å·²åŒ¹é…å·®å¼‚": "#4ECDC4",
                                "æœªåŒ¹é…å·®å¼‚": "#45B7D1"
                            }
                        )
                        fig_diff.update_layout(
                            xaxis_title="å·®å¼‚ç±»å‹",
                            yaxis_title="å·®å¼‚é‡‘é¢ï¼ˆå…ƒï¼‰",
                            height=400
                        )
                        st.plotly_chart(fig_diff, use_container_width=True)

                    except ImportError:
                        # ä½¿ç”¨streamlitåŸç”Ÿå›¾è¡¨
                        chart_data = diff_comparison_data.set_index("å·®å¼‚ç±»å‹")[
                            ["æ€»ä½“å·®å¼‚", "å·²åŒ¹é…å·®å¼‚", "æœªåŒ¹é…å·®å¼‚"]]
                        st.bar_chart(chart_data)

                # å…³é”®æŒ‡æ ‡æ±‡æ€»ï¼ˆæ¨ªå‘å±•ç¤ºï¼‰
                st.markdown("#### ğŸ“Š å…³é”®æŒ‡æ ‡æ±‡æ€»")

                key_metrics_data = {
                    "æŒ‡æ ‡": ["æ€»ä½“åŒ¹é…ç‡", "æ€»ä»·å€¼å·®å¼‚", "å·²åŒ¹é…é¡¹ç›®", "å¾…å¤„ç†é¡¹ç›®", "åŒ¹é…èµ„äº§å æ¯”"],
                    "æ•°å€¼": [
                        f"{overall_match_rate:.1f}%",
                        f"Â¥{abs(total_original_diff):,.0f}",
                        f"{matched_count:,} é¡¹",
                        f"{unmatched_financial_totals['count'] + unmatched_physical_totals['count']:,} é¡¹",
                        f"{(matched_financial_totals['original'] / total_financial['original'] * 100):.1f}%" if
                        total_financial['original'] > 0 else "0%"
                    ]
                }

                key_metrics_df = pd.DataFrame(key_metrics_data)
                st.dataframe(key_metrics_df, use_container_width=True, hide_index=True)

                # å¯¼å‡ºåŠŸèƒ½
                st.divider()
                if st.button("ğŸ“¥ å¯¼å‡ºå·®å¼‚åˆ†ææŠ¥å‘Š", key="export_analysis"):
                    # åˆ›å»ºå¯¼å‡ºæ•°æ®
                    export_data = []

                    # æ€»ä½“å¯¹æ¯”æ•°æ®
                    export_data.extend([
                        {"åˆ†ç±»": "æ€»ä½“å¯¹æ¯”", "é¡¹ç›®": "è´¢åŠ¡èµ„äº§åŸå€¼", "é‡‘é¢": total_financial['original']},
                        {"åˆ†ç±»": "æ€»ä½“å¯¹æ¯”", "é¡¹ç›®": "å®ç‰©èµ„äº§åŸå€¼", "é‡‘é¢": total_physical['original']},
                        {"åˆ†ç±»": "æ€»ä½“å¯¹æ¯”", "é¡¹ç›®": "åŸå€¼å·®å¼‚", "é‡‘é¢": total_original_diff},
                        {"åˆ†ç±»": "æ€»ä½“å¯¹æ¯”", "é¡¹ç›®": "è´¢åŠ¡ç´¯è®¡æŠ˜æ—§", "é‡‘é¢": total_financial['depreciation']},
                        {"åˆ†ç±»": "æ€»ä½“å¯¹æ¯”", "é¡¹ç›®": "å®ç‰©ç´¯è®¡æŠ˜æ—§", "é‡‘é¢": total_physical['depreciation']},
                        {"åˆ†ç±»": "æ€»ä½“å¯¹æ¯”", "é¡¹ç›®": "æŠ˜æ—§å·®å¼‚", "é‡‘é¢": total_depreciation_diff},
                        {"åˆ†ç±»": "æ€»ä½“å¯¹æ¯”", "é¡¹ç›®": "è´¢åŠ¡èµ„äº§å‡€é¢", "é‡‘é¢": total_financial['net']},
                        {"åˆ†ç±»": "æ€»ä½“å¯¹æ¯”", "é¡¹ç›®": "å®ç‰©èµ„äº§å‡€é¢", "é‡‘é¢": total_physical['net']},
                        {"åˆ†ç±»": "æ€»ä½“å¯¹æ¯”", "é¡¹ç›®": "å‡€é¢å·®å¼‚", "é‡‘é¢": total_net_diff}
                    ])

                    # å·²åŒ¹é…èµ„äº§æ•°æ®
                    export_data.extend([
                        {"åˆ†ç±»": "å·²åŒ¹é…èµ„äº§", "é¡¹ç›®": "è´¢åŠ¡èµ„äº§åŸå€¼", "é‡‘é¢": matched_financial_totals['original']},
                        {"åˆ†ç±»": "å·²åŒ¹é…èµ„äº§", "é¡¹ç›®": "å®ç‰©èµ„äº§åŸå€¼", "é‡‘é¢": matched_physical_totals['original']},
                        {"åˆ†ç±»": "å·²åŒ¹é…èµ„äº§", "é¡¹ç›®": "åŸå€¼å·®å¼‚", "é‡‘é¢": matched_original_diff},
                        {"åˆ†ç±»": "å·²åŒ¹é…èµ„äº§", "é¡¹ç›®": "è´¢åŠ¡ç´¯è®¡æŠ˜æ—§",
                         "é‡‘é¢": matched_financial_totals['depreciation']},
                        {"åˆ†ç±»": "å·²åŒ¹é…èµ„äº§", "é¡¹ç›®": "å®ç‰©ç´¯è®¡æŠ˜æ—§", "é‡‘é¢": matched_physical_totals['depreciation']},
                        {"åˆ†ç±»": "å·²åŒ¹é…èµ„äº§", "é¡¹ç›®": "æŠ˜æ—§å·®å¼‚", "é‡‘é¢": matched_depreciation_diff},
                        {"åˆ†ç±»": "å·²åŒ¹é…èµ„äº§", "é¡¹ç›®": "è´¢åŠ¡èµ„äº§å‡€é¢", "é‡‘é¢": matched_financial_totals['net']},
                        {"åˆ†ç±»": "å·²åŒ¹é…èµ„äº§", "é¡¹ç›®": "å®ç‰©èµ„äº§å‡€é¢", "é‡‘é¢": matched_physical_totals['net']},
                        {"åˆ†ç±»": "å·²åŒ¹é…èµ„äº§", "é¡¹ç›®": "å‡€é¢å·®å¼‚", "é‡‘é¢": matched_net_diff},
                        {"åˆ†ç±»": "å·²åŒ¹é…èµ„äº§", "é¡¹ç›®": "åŒ¹é…æ•°é‡", "é‡‘é¢": matched_financial_totals['count']}
                    ])

                    # æœªåŒ¹é…èµ„äº§æ•°æ®
                    export_data.extend([
                        {"åˆ†ç±»": "æœªåŒ¹é…è´¢åŠ¡èµ„äº§", "é¡¹ç›®": "èµ„äº§åŸå€¼", "é‡‘é¢": unmatched_financial_totals['original']},
                        {"åˆ†ç±»": "æœªåŒ¹é…è´¢åŠ¡èµ„äº§", "é¡¹ç›®": "ç´¯è®¡æŠ˜æ—§",
                         "é‡‘é¢": unmatched_financial_totals['depreciation']},
                        {"åˆ†ç±»": "æœªåŒ¹é…è´¢åŠ¡èµ„äº§", "é¡¹ç›®": "èµ„äº§å‡€é¢", "é‡‘é¢": unmatched_financial_totals['net']},
                        {"åˆ†ç±»": "æœªåŒ¹é…è´¢åŠ¡èµ„äº§", "é¡¹ç›®": "æ•°é‡", "é‡‘é¢": unmatched_financial_totals['count']},
                        {"åˆ†ç±»": "æœªåŒ¹é…å®ç‰©èµ„äº§", "é¡¹ç›®": "èµ„äº§åŸå€¼", "é‡‘é¢": unmatched_physical_totals['original']},
                        {"åˆ†ç±»": "æœªåŒ¹é…å®ç‰©èµ„äº§", "é¡¹ç›®": "ç´¯è®¡æŠ˜æ—§",
                         "é‡‘é¢": unmatched_physical_totals['depreciation']},
                        {"åˆ†ç±»": "æœªåŒ¹é…å®ç‰©èµ„äº§", "é¡¹ç›®": "èµ„äº§å‡€é¢", "é‡‘é¢": unmatched_physical_totals['net']},
                        {"åˆ†ç±»": "æœªåŒ¹é…å®ç‰©èµ„äº§", "é¡¹ç›®": "æ•°é‡", "é‡‘é¢": unmatched_physical_totals['count']}
                    ])

                    export_df = pd.DataFrame(export_data)
                    csv = export_df.to_csv(index=False, encoding='utf-8-sig')

                    st.download_button(
                        label="ğŸ’¾ ä¸‹è½½å·®å¼‚åˆ†ææŠ¥å‘Š CSV",
                        data=csv,
                        file_name=f"èµ„äº§å·®å¼‚åˆ†ææŠ¥å‘Š_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv"
                    )

                    st.success("âœ… æŠ¥å‘Šå·²å‡†å¤‡å°±ç»ªï¼Œç‚¹å‡»ä¸Šæ–¹æŒ‰é’®ä¸‹è½½")

    # ========== Tab 3: å¯è§†åŒ–åˆ†æ ==========
    with tab_charts:
        st.subheader("ğŸ“ˆ å¯è§†åŒ–åˆ†æ")

        chart_tab1, chart_tab2, chart_tab3 = st.tabs(["ğŸ’° ä»·å€¼åˆ†å¸ƒ", "ğŸ¯ åŒ¹é…çŠ¶æ€", "ğŸ¢ éƒ¨é—¨åˆ†æ"])

        with chart_tab1:
            # ä»·å€¼å¯¹æ¯”å›¾
            col_chart1, col_chart2 = st.columns(2)

            with col_chart1:
                # æ€»ä»·å€¼å¯¹æ¯”
                try:
                    import plotly.express as px
                    fig_pie = px.pie(
                        values=[financial_total_value, physical_total_value],
                        names=["è´¢åŠ¡ç³»ç»Ÿ", "å®ç‰©ç³»ç»Ÿ"],
                        title="æ€»ä»·å€¼åˆ†å¸ƒå¯¹æ¯”",
                        color_discrete_sequence=['#FF6B6B', '#4ECDC4']
                    )
                    fig_pie.update_traces(textposition='inside', textinfo='percent+label')
                    st.plotly_chart(fig_pie, use_container_width=True)
                except:
                    # ä½¿ç”¨streamlitåŸç”Ÿå›¾è¡¨
                    chart_data = pd.DataFrame({
                        "è´¢åŠ¡ç³»ç»Ÿ": [financial_total_value],
                        "å®ç‰©ç³»ç»Ÿ": [physical_total_value]
                    })
                    st.bar_chart(chart_data)

            with col_chart2:
                # åŒ¹é…vsæœªåŒ¹é…ä»·å€¼å¯¹æ¯”
                unmatched_financial = [f for f in financial_data if
                                       str(f.get("èµ„äº§ç¼–å·+åºå·", "")).strip() not in financial_to_physical_mapping]
                unmatched_physical = [p for p in physical_data if
                                      str(p.get("å›ºå®šèµ„äº§ç¼–ç ", "")).strip() not in physical_to_financial_mapping]

                unmatched_financial_value = sum(safe_get_value(f, "èµ„äº§ä»·å€¼") for f in unmatched_financial)
                matched_financial_value = financial_total_value - unmatched_financial_value

                # å®ç‰©èµ„äº§å»é‡è®¡ç®—
                if unmatched_physical:
                    unmatched_physical_df = pd.DataFrame(unmatched_physical)
                    if "å›ºå®šèµ„äº§ç¼–ç " in unmatched_physical_df.columns:
                        unmatched_physical_df_deduped = unmatched_physical_df.drop_duplicates(
                            subset=['å›ºå®šèµ„äº§ç¼–ç '], keep='first')
                        unmatched_physical_value = sum(
                            safe_get_value(row.to_dict(), "å›ºå®šèµ„äº§åŸå€¼")
                            for _, row in unmatched_physical_df_deduped.iterrows())
                    else:
                        unmatched_physical_value = sum(safe_get_value(p, "å›ºå®šèµ„äº§åŸå€¼") for p in unmatched_physical)
                else:
                    unmatched_physical_value = 0

                matched_physical_value = physical_total_value - unmatched_physical_value

                try:
                    match_status_data = pd.DataFrame({
                        "çŠ¶æ€": ["å·²åŒ¹é…è´¢åŠ¡", "æœªåŒ¹é…è´¢åŠ¡", "å·²åŒ¹é…å®ç‰©", "æœªåŒ¹é…å®ç‰©"],
                        "ä»·å€¼": [matched_financial_value, unmatched_financial_value,
                                 matched_physical_value, unmatched_physical_value]
                    })

                    fig_bar = px.bar(
                        match_status_data,
                        x="çŠ¶æ€",
                        y="ä»·å€¼",
                        title="åŒ¹é…çŠ¶æ€ä»·å€¼åˆ†å¸ƒ",
                        color="çŠ¶æ€",
                        color_discrete_sequence=['#95E1D3', '#F38BA8', '#A8E6CF', '#FFB3BA']
                    )
                    fig_bar.update_layout(xaxis_tickangle=-45)
                    st.plotly_chart(fig_bar, use_container_width=True)
                except:
                    st.bar_chart(match_status_data.set_index("çŠ¶æ€"))

        with chart_tab2:
            # åŒ¹é…çŠ¶æ€åˆ†å¸ƒ
            col_dist1, col_dist2 = st.columns(2)

            with col_dist1:
                # è´¢åŠ¡èµ„äº§åŒ¹é…çŠ¶æ€
                try:
                    financial_match_data = pd.DataFrame({
                        "çŠ¶æ€": ["å·²åŒ¹é…", "æœªåŒ¹é…"],
                        "æ•°é‡": [matched_financial, len(financial_data) - matched_financial]
                    })

                    fig_financial = px.pie(
                        financial_match_data,
                        values="æ•°é‡",
                        names="çŠ¶æ€",
                        title="è´¢åŠ¡èµ„äº§åŒ¹é…çŠ¶æ€",
                        color_discrete_sequence=['#A8E6CF', '#FFB3BA']
                    )
                    fig_financial.update_traces(textposition='inside', textinfo='percent+label')
                    st.plotly_chart(fig_financial, use_container_width=True)
                except:
                    st.write("**è´¢åŠ¡èµ„äº§åŒ¹é…çŠ¶æ€**")
                    st.dataframe(financial_match_data)

            with col_dist2:
                # å®ç‰©èµ„äº§åŒ¹é…çŠ¶æ€
                try:
                    physical_match_data = pd.DataFrame({
                        "çŠ¶æ€": ["å·²åŒ¹é…", "æœªåŒ¹é…"],
                        "æ•°é‡": [matched_physical, len(physical_data) - matched_physical]
                    })

                    fig_physical = px.pie(
                        physical_match_data,
                        values="æ•°é‡",
                        names="çŠ¶æ€",
                        title="å®ç‰©èµ„äº§åŒ¹é…çŠ¶æ€",
                        color_discrete_sequence=['#95E1D3', '#F38BA8']
                    )
                    fig_physical.update_traces(textposition='inside', textinfo='percent+label')
                    st.plotly_chart(fig_physical, use_container_width=True)
                except:
                    st.write("**å®ç‰©èµ„äº§åŒ¹é…çŠ¶æ€**")
                    st.dataframe(physical_match_data)

        with chart_tab3:
            # éƒ¨é—¨åˆ†æå›¾è¡¨
            # è®¡ç®—éƒ¨é—¨ç»Ÿè®¡
            financial_dept_stats = {}
            for f in financial_data:
                dept = f.get("éƒ¨é—¨åç§°", "æœªçŸ¥éƒ¨é—¨")
                if dept not in financial_dept_stats:
                    financial_dept_stats[dept] = {"count": 0, "value": 0, "matched": 0}
                financial_dept_stats[dept]["count"] += 1
                financial_dept_stats[dept]["value"] += safe_get_value(f, "èµ„äº§ä»·å€¼")

                financial_code = str(f.get("èµ„äº§ç¼–å·+åºå·", "")).strip()
                if financial_code in financial_to_physical_mapping:
                    financial_dept_stats[dept]["matched"] += 1

            # éƒ¨é—¨ä»·å€¼å¯¹æ¯”
            dept_chart_data = []
            for dept, stats in financial_dept_stats.items():
                dept_chart_data.append({
                    "éƒ¨é—¨": dept,
                    "æ€»ä»·å€¼": stats["value"],
                    "èµ„äº§æ•°é‡": stats["count"],
                    "åŒ¹é…ç‡": (stats["matched"] / stats["count"] * 100) if stats["count"] > 0 else 0
                })

            if dept_chart_data:
                dept_df = pd.DataFrame(dept_chart_data)
                dept_df = dept_df.sort_values("æ€»ä»·å€¼", ascending=False).head(10)  # æ˜¾ç¤ºå‰10ä¸ªéƒ¨é—¨

                col_dept1, col_dept2 = st.columns(2)

                with col_dept1:
                    try:
                        fig_dept_value = px.bar(
                            dept_df,
                            x="éƒ¨é—¨",
                            y="æ€»ä»·å€¼",
                            title="å„éƒ¨é—¨èµ„äº§ä»·å€¼åˆ†å¸ƒï¼ˆå‰10ï¼‰",
                            color="æ€»ä»·å€¼",
                            color_continuous_scale="Viridis"
                        )
                        fig_dept_value.update_xaxes(tickangle=45)
                        st.plotly_chart(fig_dept_value, use_container_width=True)
                    except:
                        st.write("**å„éƒ¨é—¨èµ„äº§ä»·å€¼åˆ†å¸ƒ**")
                        st.bar_chart(dept_df.set_index("éƒ¨é—¨")["æ€»ä»·å€¼"])

                with col_dept2:
                    try:
                        fig_dept_match = px.scatter(
                            dept_df,
                            x="èµ„äº§æ•°é‡",
                            y="åŒ¹é…ç‡",
                            size="æ€»ä»·å€¼",
                            hover_data=["éƒ¨é—¨"],
                            title="éƒ¨é—¨åŒ¹é…ç‡ vs èµ„äº§æ•°é‡",
                            color="åŒ¹é…ç‡",
                            color_continuous_scale="RdYlGn"
                        )
                        st.plotly_chart(fig_dept_match, use_container_width=True)
                    except:
                        st.write("**éƒ¨é—¨åŒ¹é…ç‡åˆ†æ**")
                        st.dataframe(dept_df[["éƒ¨é—¨", "èµ„äº§æ•°é‡", "åŒ¹é…ç‡"]])

                # éƒ¨é—¨è¯¦ç»†ç»Ÿè®¡è¡¨
                st.markdown("#### ğŸ“Š éƒ¨é—¨ç»Ÿè®¡è¯¦æƒ…")
                dept_detail_df = dept_df.copy()
                dept_detail_df["æ€»ä»·å€¼"] = dept_detail_df["æ€»ä»·å€¼"].apply(lambda x: f"Â¥{x:,.2f}")
                dept_detail_df["åŒ¹é…ç‡"] = dept_detail_df["åŒ¹é…ç‡"].apply(lambda x: f"{x:.1f}%")

                st.dataframe(
                    dept_detail_df[["éƒ¨é—¨", "èµ„äº§æ•°é‡", "æ€»ä»·å€¼", "åŒ¹é…ç‡"]],
                    use_container_width=True
                )

                # éƒ¨é—¨åŒ¹é…ç‡åˆ†æ
                st.markdown("#### ğŸ¯ éƒ¨é—¨åŒ¹é…ç‡åˆ†æ")

                high_match_depts = dept_df[dept_df["åŒ¹é…ç‡"] >= 80]
                medium_match_depts = dept_df[(dept_df["åŒ¹é…ç‡"] >= 50) & (dept_df["åŒ¹é…ç‡"] < 80)]
                low_match_depts = dept_df[dept_df["åŒ¹é…ç‡"] < 50]

                match_analysis_col1, match_analysis_col2, match_analysis_col3 = st.columns(3)

                with match_analysis_col1:
                    st.metric("é«˜åŒ¹é…ç‡éƒ¨é—¨ (â‰¥80%)", f"{len(high_match_depts)} ä¸ª")
                    if len(high_match_depts) > 0:
                        st.caption("âœ… åŒ¹é…è‰¯å¥½")

                with match_analysis_col2:
                    st.metric("ä¸­ç­‰åŒ¹é…ç‡éƒ¨é—¨ (50-80%)", f"{len(medium_match_depts)} ä¸ª")
                    if len(medium_match_depts) > 0:
                        st.caption("âš ï¸ éœ€è¦æ”¹è¿›")

                with match_analysis_col3:
                    st.metric("ä½åŒ¹é…ç‡éƒ¨é—¨ (<50%)", f"{len(low_match_depts)} ä¸ª")
                    if len(low_match_depts) > 0:
                        st.caption("ğŸ”´ æ€¥éœ€å…³æ³¨")

                # æ˜¾ç¤ºéœ€è¦å…³æ³¨çš„éƒ¨é—¨
                if len(low_match_depts) > 0:
                    with st.expander("ğŸ” ä½åŒ¹é…ç‡éƒ¨é—¨è¯¦æƒ…", expanded=False):
                        low_match_display = low_match_depts[["éƒ¨é—¨", "èµ„äº§æ•°é‡", "åŒ¹é…ç‡"]].copy()
                        low_match_display["åŒ¹é…ç‡"] = low_match_display["åŒ¹é…ç‡"].apply(lambda x: f"{x:.1f}%")
                        st.dataframe(low_match_display, use_container_width=True)
                        st.warning("ğŸ’¡ å»ºè®®ä¼˜å…ˆå¤„ç†è¿™äº›éƒ¨é—¨çš„èµ„äº§åŒ¹é…å·¥ä½œ")

            else:
                st.info("æš‚æ— éƒ¨é—¨æ•°æ®å¯ä¾›åˆ†æ")
        # ========== é¡µé¢åº•éƒ¨æ±‡æ€»ä¿¡æ¯ ==========
    st.divider()
    st.markdown("### ğŸ“‹ æ•°æ®ç»Ÿè®¡æ±‡æ€»")

    # åˆ›å»ºæ±‡æ€»ä¿¡æ¯
    summary_col1, summary_col2 = st.columns(2)

    with summary_col1:
        st.markdown("#### ğŸ“Š æ•°æ®æ¦‚å†µ")
        st.write(f"â€¢ è´¢åŠ¡èµ„äº§æ€»æ•°ï¼š**{len(financial_data):,}** é¡¹")
        st.write(
            f"â€¢ å®ç‰©èµ„äº§æ€»æ•°ï¼š**{st.session_state.get('physical_deduped_count', len(physical_data)):,}** é¡¹ï¼ˆå»é‡åï¼‰")
        st.write(f"â€¢ æ˜ å°„å…³ç³»æ€»æ•°ï¼š**{len(mapping_data):,}** æ¡")
        st.write(f"â€¢ æ•´ä½“åŒ¹é…ç‡ï¼š**{overall_match_rate:.1f}%**")

    with summary_col2:
        st.markdown("#### ğŸ’° ä»·å€¼æ¦‚å†µ")
        st.write(f"â€¢ è´¢åŠ¡èµ„äº§æ€»ä»·å€¼ï¼š**Â¥{financial_total_value:,.2f}**")
        st.write(f"â€¢ å®ç‰©èµ„äº§æ€»ä»·å€¼ï¼š**Â¥{physical_total_value:,.2f}**")
        st.write(f"â€¢ æ€»ä»·å€¼å·®å¼‚ï¼š**Â¥{total_diff:,.2f}**")

        if matched_count > 0:
            st.write(f"â€¢ å·²åŒ¹é…é¡¹ç›®ï¼š**{matched_count:,}** é¡¹")

    # æ•°æ®å¤„ç†è¯´æ˜
    if non_accounting_count > 0 or physical_duplicate_count > 0:
        st.markdown("#### â„¹ï¸ æ•°æ®å¤„ç†è¯´æ˜")
        if non_accounting_count > 0:
            st.info(f"ğŸ“Œ å·²æ’é™¤ **{non_accounting_count:,}** æ¡éæ ¸ç®—èµ„äº§")
        if physical_duplicate_count > 0:
            st.info(f"ğŸ“Œ å·²å»é‡ **{physical_duplicate_count:,}** æ¡é‡å¤è®°å½•")
    # æœ€åæ›´æ–°æ—¶é—´
    st.caption(f"ğŸ“… ç»Ÿè®¡ç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


def all_data_view_page():
    """æŸ¥çœ‹å…¨éƒ¨å¯¹åº”å…³ç³»é¡µé¢"""
    st.header("ğŸ“‹ å…¨éƒ¨èµ„äº§å¯¹åº”å…³ç³»")

    # åŠ è½½æ•°æ®
    with st.spinner("åŠ è½½æ•°æ®ä¸­..."):
        financial_data = load_data(FINANCIAL_DATA_FILE)
        physical_data = load_data(PHYSICAL_DATA_FILE)
        mapping_data = load_data(MAPPING_DATA_FILE)

    # ä¿®æ”¹ï¼šæ£€æŸ¥æ‰€æœ‰ä¸‰ä¸ªæ•°æ®æº
    if not all([financial_data, physical_data, mapping_data]):
        missing = []
        if not financial_data:
            missing.append("è´¢åŠ¡ç³»ç»Ÿæ•°æ®")
        if not physical_data:
            missing.append("å®ç‰©å°è´¦æ•°æ®")
        if not mapping_data:
            missing.append("æ˜ å°„å…³ç³»æ•°æ®")
        st.warning(f"âš ï¸ è¯·å…ˆå¯¼å…¥ï¼š{', '.join(missing)}")
        return
        # ğŸ†• æ·»åŠ æ•°æ®æ ¼å¼æ£€æŸ¥
        if financial_data:
            financial_df_check = pd.DataFrame(financial_data)
            if "èµ„äº§ç¼–å·+åºå·" not in financial_df_check.columns:
                st.error("âŒ è´¢åŠ¡æ•°æ®æ ¼å¼é”™è¯¯ï¼šç¼ºå°‘'èµ„äº§ç¼–å·+åºå·'åˆ—")
                st.write("è´¢åŠ¡æ•°æ®å½“å‰åˆ—åï¼š", list(financial_df_check.columns))
                return

        if physical_data:
            physical_df_check = pd.DataFrame(physical_data)
            if "å›ºå®šèµ„äº§ç¼–ç " not in physical_df_check.columns:
                st.error("âŒ å®ç‰©æ•°æ®æ ¼å¼é”™è¯¯ï¼šç¼ºå°‘'å›ºå®šèµ„äº§ç¼–ç 'åˆ—")
                st.write("å®ç‰©æ•°æ®å½“å‰åˆ—åï¼š", list(physical_df_check.columns))
                return
    # åˆ›å»ºç´¢å¼•
    financial_index = create_data_index(financial_data, "èµ„äº§ç¼–å·+åºå·")
    physical_index = create_data_index(physical_data, "å›ºå®šèµ„äº§ç¼–ç ")
    financial_to_physical_mapping, physical_to_financial_mapping = create_mapping_index(mapping_data)

    # é€‰æ‹©æŸ¥çœ‹æ¨¡å¼
    view_mode = st.selectbox("é€‰æ‹©æŸ¥çœ‹æ¨¡å¼",
                             ["å¯¹åº”å…³ç³»æ±‡æ€»", "è´¢åŠ¡ç³»ç»Ÿæ˜ç»†", "å®ç‰©å°è´¦æ˜ç»†", "æœªåŒ¹é…èµ„äº§"])

    if view_mode == "å¯¹åº”å…³ç³»æ±‡æ€»":
        st.subheader("ğŸ”— å®Œæ•´å¯¹åº”å…³ç³»æ±‡æ€»")

        # æ„å»ºæ±‡æ€»æ•°æ® - ä¿®å¤ï¼šå¤„ç†å¤šå¯¹å¤šå…³ç³»
        mapping_summary = []

        # ç”¨é›†åˆè®°å½•å·²å¤„ç†çš„æ˜ å°„å…³ç³»ï¼Œé¿å…é‡å¤
        processed_pairs = set()

        for mapping_record in mapping_data:
            financial_code = str(mapping_record.get("èµ„äº§ç¼–å·+åºå·", "")).strip()
            physical_code = str(mapping_record.get("å›ºå®šèµ„äº§ç¼–ç ", "")).strip()

            # åˆ›å»ºå”¯ä¸€æ ‡è¯†ç¬¦é¿å…é‡å¤å¤„ç†
            pair_key = f"{financial_code}|{physical_code}"
            if pair_key in processed_pairs:
                continue
            processed_pairs.add(pair_key)

            if financial_code and physical_code:
                financial_record = financial_index.get(financial_code)
                physical_record = physical_index.get(physical_code)

                if financial_record and physical_record:
                    financial_value = safe_get_value(financial_record, "èµ„äº§ä»·å€¼")
                    physical_value = safe_get_value(physical_record, "èµ„äº§ä»·å€¼")

                    mapping_summary.append({
                        "èµ„äº§ç¼–å·+åºå·": financial_code,
                        "è´¢åŠ¡èµ„äº§åç§°": financial_record.get("èµ„äº§åç§°", ""),
                        "è´¢åŠ¡èµ„äº§ä»·å€¼": financial_value,
                        "è´¢åŠ¡éƒ¨é—¨": financial_record.get("éƒ¨é—¨åç§°", ""),
                        "è´¢åŠ¡ä¿ç®¡äºº": financial_record.get("ä¿ç®¡äºº", ""),
                        "å®ç‰©å°è´¦ç¼–å·": physical_code,
                        "å®ç‰©èµ„äº§åç§°": physical_record.get("å›ºå®šèµ„äº§åç§°", ""),
                        "å®ç‰©èµ„äº§ä»·å€¼": physical_value,
                        "å®ç‰©éƒ¨é—¨": physical_record.get("å­˜æ”¾éƒ¨é—¨", ""),
                        "å®ç‰©ä¿ç®¡äºº": physical_record.get("ä¿ç®¡äºº", ""),
                        "ä»·å€¼å·®å¼‚": financial_value - physical_value,
                        "çŠ¶æ€": "æ­£å¸¸åŒ¹é…"
                    })
                else:
                    # è®°å½•æ˜ å°„å­˜åœ¨ä½†æ•°æ®ç¼ºå¤±çš„æƒ…å†µ
                    mapping_summary.append({
                        "èµ„äº§ç¼–å·+åºå·": financial_code,
                        "è´¢åŠ¡èµ„äº§åç§°": "æ•°æ®ç¼ºå¤±" if not financial_record else financial_record.get("èµ„äº§åç§°", ""),
                        "è´¢åŠ¡èµ„äº§ä»·å€¼": 0 if not financial_record else safe_get_value(financial_record, "èµ„äº§ä»·å€¼"),
                        "è´¢åŠ¡éƒ¨é—¨": "æ•°æ®ç¼ºå¤±" if not financial_record else financial_record.get("éƒ¨é—¨åç§°", ""),
                        "è´¢åŠ¡ä¿ç®¡äºº": "æ•°æ®ç¼ºå¤±" if not financial_record else financial_record.get("ä¿ç®¡äºº", ""),
                        "å®ç‰©å°è´¦ç¼–å·": physical_code,
                        "å®ç‰©èµ„äº§åç§°": "æ•°æ®ç¼ºå¤±" if not physical_record else physical_record.get("å›ºå®šèµ„äº§åç§°", ""),
                        "å®ç‰©èµ„äº§ä»·å€¼": 0 if not physical_record else safe_get_value(physical_record, "èµ„äº§ä»·å€¼"),
                        "å®ç‰©éƒ¨é—¨": "æ•°æ®ç¼ºå¤±" if not physical_record else physical_record.get("å­˜æ”¾éƒ¨é—¨", ""),
                        "å®ç‰©ä¿ç®¡äºº": "æ•°æ®ç¼ºå¤±" if not physical_record else physical_record.get("ä¿ç®¡äºº", ""),
                        "ä»·å€¼å·®å¼‚": 0,
                        "çŠ¶æ€": "æ•°æ®å¼‚å¸¸"
                    })

        if mapping_summary:
            df = pd.DataFrame(mapping_summary)

            # æ·»åŠ ç­›é€‰åŠŸèƒ½
            col1, col2, col3 = st.columns(3)
            with col1:
                # è·å–æ‰€æœ‰éƒ¨é—¨ï¼ˆè´¢åŠ¡å’Œå®ç‰©ï¼‰
                all_financial_depts = [dept for dept in df["è´¢åŠ¡éƒ¨é—¨"].unique() if dept and dept != "æ•°æ®ç¼ºå¤±"]
                all_physical_depts = [dept for dept in df["å®ç‰©éƒ¨é—¨"].unique() if dept and dept != "æ•°æ®ç¼ºå¤±"]
                all_depts = sorted(list(set(all_financial_depts + all_physical_depts)))
                dept_filter = st.selectbox("æŒ‰éƒ¨é—¨ç­›é€‰", ["å…¨éƒ¨"] + all_depts)

            with col2:
                diff_filter = st.selectbox("æŒ‰å·®å¼‚ç­›é€‰", ["å…¨éƒ¨", "æœ‰å·®å¼‚", "æ— å·®å¼‚", "æ•°æ®å¼‚å¸¸"])

            with col3:
                search_term = st.text_input("æœç´¢èµ„äº§åç§°")

            # åº”ç”¨ç­›é€‰
            filtered_df = df.copy()

            if dept_filter != "å…¨éƒ¨":
                filtered_df = filtered_df[
                    (filtered_df["è´¢åŠ¡éƒ¨é—¨"] == dept_filter) | (filtered_df["å®ç‰©éƒ¨é—¨"] == dept_filter)]

            if diff_filter == "æœ‰å·®å¼‚":
                filtered_df = filtered_df[(filtered_df["ä»·å€¼å·®å¼‚"].abs() > 0.01) & (filtered_df["çŠ¶æ€"] == "æ­£å¸¸åŒ¹é…")]
            elif diff_filter == "æ— å·®å¼‚":
                filtered_df = filtered_df[(filtered_df["ä»·å€¼å·®å¼‚"].abs() <= 0.01) & (filtered_df["çŠ¶æ€"] == "æ­£å¸¸åŒ¹é…")]
            elif diff_filter == "æ•°æ®å¼‚å¸¸":
                filtered_df = filtered_df[filtered_df["çŠ¶æ€"] == "æ•°æ®å¼‚å¸¸"]

            if search_term:
                filtered_df = filtered_df[
                    filtered_df["è´¢åŠ¡èµ„äº§åç§°"].astype(str).str.contains(search_term, case=False, na=False) |
                    filtered_df["å®ç‰©èµ„äº§åç§°"].astype(str).str.contains(search_term, case=False, na=False)
                    ]

            st.info(f"å…± {len(filtered_df)} æ¡è®°å½•ï¼ˆæ€»æ˜ å°„å…³ç³» {len(df)} æ¡ï¼‰")

            # æ ¼å¼åŒ–æ˜¾ç¤ºæ•°å€¼
            display_df = filtered_df.copy()
            display_df["è´¢åŠ¡èµ„äº§ä»·å€¼"] = display_df["è´¢åŠ¡èµ„äº§ä»·å€¼"].apply(
                lambda x: f"Â¥{x:,.2f}" if isinstance(x, (int, float)) else x)
            display_df["å®ç‰©èµ„äº§ä»·å€¼"] = display_df["å®ç‰©èµ„äº§ä»·å€¼"].apply(
                lambda x: f"Â¥{x:,.2f}" if isinstance(x, (int, float)) else x)
            display_df["ä»·å€¼å·®å¼‚"] = display_df["ä»·å€¼å·®å¼‚"].apply(
                lambda x: f"Â¥{x:,.2f}" if isinstance(x, (int, float)) else x)

            st.dataframe(display_df, use_container_width=True)

            # å¯¼å‡ºåŠŸèƒ½
            if st.button("ğŸ“¥ å¯¼å‡ºä¸ºExcel"):
                try:
                    output = io.BytesIO()
                    filtered_df.to_excel(output, index=False, engine='openpyxl')
                    output.seek(0)
                    st.download_button(
                        label="ä¸‹è½½Excelæ–‡ä»¶",
                        data=output,
                        file_name=f"èµ„äº§å¯¹åº”å…³ç³»æ±‡æ€»_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                except Exception as e:
                    st.error(f"å¯¼å‡ºå¤±è´¥: {str(e)}")
        else:
            st.warning("âš ï¸ æš‚æ— æ˜ å°„å…³ç³»æ•°æ®")

    elif view_mode == "è´¢åŠ¡ç³»ç»Ÿæ˜ç»†":
        st.subheader("ğŸ“Š è´¢åŠ¡ç³»ç»Ÿèµ„äº§æ˜ç»†")

        if not financial_data:
            st.warning("âš ï¸ æš‚æ— è´¢åŠ¡ç³»ç»Ÿæ•°æ®")
            return

        df = pd.DataFrame(financial_data)

        # æ£€æŸ¥å¿…éœ€åˆ—æ˜¯å¦å­˜åœ¨
        if "èµ„äº§ç¼–å·+åºå·" not in df.columns:
            st.error("âŒ è´¢åŠ¡æ•°æ®ä¸­ç¼ºå°‘'èµ„äº§ç¼–å·+åºå·'åˆ—ï¼Œè¯·æ£€æŸ¥æ•°æ®æ ¼å¼")
            st.write("å½“å‰åˆ—åï¼š", list(df.columns))
            return

        # ä¿®å¤ï¼šæ­£ç¡®æ·»åŠ åŒ¹é…çŠ¶æ€åˆ—
        df["åŒ¹é…çŠ¶æ€"] = df["èµ„äº§ç¼–å·+åºå·"].astype(str).apply(
            lambda x: "å·²åŒ¹é…" if str(x).strip() in financial_to_physical_mapping else "æœªåŒ¹é…")

        # æ·»åŠ å¯¹åº”å®ç‰©ç¼–å·åˆ—
        df["å¯¹åº”å®ç‰©ç¼–å·"] = df["èµ„äº§ç¼–å·+åºå·"].astype(str).apply(
            lambda x: ", ".join(financial_to_physical_mapping.get(str(x).strip(), [])) if str(
                x).strip() in financial_to_physical_mapping else "æ— ")

        # ç­›é€‰åŠŸèƒ½
        col1, col2, col3 = st.columns(3)
        with col1:
            match_filter = st.selectbox("åŒ¹é…çŠ¶æ€", ["å…¨éƒ¨", "å·²åŒ¹é…", "æœªåŒ¹é…"])
        with col2:
            # éƒ¨é—¨ç­›é€‰
            all_depts = sorted([dept for dept in df["éƒ¨é—¨åç§°"].unique() if dept and str(dept).strip()])
            dept_filter = st.selectbox("æŒ‰éƒ¨é—¨ç­›é€‰", ["å…¨éƒ¨"] + all_depts, key="financial_dept_filter")
        with col3:
            search_term = st.text_input("æœç´¢èµ„äº§", key="financial_search")

        filtered_df = df.copy()

        if match_filter != "å…¨éƒ¨":
            filtered_df = filtered_df[filtered_df["åŒ¹é…çŠ¶æ€"] == match_filter]

        if dept_filter != "å…¨éƒ¨":
            filtered_df = filtered_df[filtered_df["éƒ¨é—¨åç§°"] == dept_filter]

        if search_term:
            filtered_df = filtered_df[
                filtered_df["èµ„äº§åç§°"].astype(str).str.contains(search_term, case=False, na=False) |
                filtered_df["èµ„äº§ç¼–å·+åºå·"].astype(str).str.contains(search_term, case=False, na=False)
                ]

        st.info(f"å…± {len(filtered_df)} æ¡è®°å½•ï¼ˆæ€»è´¢åŠ¡èµ„äº§ {len(df)} æ¡ï¼‰")

        # é€‰æ‹©è¦æ˜¾ç¤ºçš„åˆ—
        available_columns = list(filtered_df.columns)
        default_columns = ["èµ„äº§ç¼–å·+åºå·", "èµ„äº§åç§°", "èµ„äº§åˆ†ç±»", "èµ„äº§ä»·å€¼", "ç´¯è®¡æŠ˜æ—§", "èµ„äº§å‡€é¢", "éƒ¨é—¨åç§°", "ä¿ç®¡äºº", "åŒ¹é…çŠ¶æ€", "å¯¹åº”å®ç‰©ç¼–å·"]
        display_columns = [col for col in default_columns if col in available_columns]

        # æ ¼å¼åŒ–æ˜¾ç¤º
        display_df = filtered_df[display_columns].copy()
        # æ ¼å¼åŒ–æ‰€æœ‰é‡‘é¢å­—æ®µ
        for amount_col in ["èµ„äº§ä»·å€¼", "ç´¯è®¡æŠ˜æ—§", "èµ„äº§å‡€é¢"]:
            if amount_col in display_df.columns:
                display_df[amount_col] = display_df[amount_col].apply(
                    lambda x: f"Â¥{x:,.2f}" if isinstance(x, (int, float)) else x)

        st.dataframe(display_df, use_container_width=True)

        # ç»Ÿè®¡ä¿¡æ¯
        col1, col2, col3 = st.columns(3)
        with col1:
            matched_count = len(filtered_df[filtered_df["åŒ¹é…çŠ¶æ€"] == "å·²åŒ¹é…"])
            st.metric("å·²åŒ¹é…", matched_count)
        with col2:
            unmatched_count = len(filtered_df[filtered_df["åŒ¹é…çŠ¶æ€"] == "æœªåŒ¹é…"])
            st.metric("æœªåŒ¹é…", unmatched_count)
        with col3:
            total_value = filtered_df["èµ„äº§ä»·å€¼"].sum() if "èµ„äº§ä»·å€¼" in filtered_df.columns else 0
            try:
                total_value = 0.0
                valid_count = 0
                error_count = 0

                for _, row in filtered_df.iterrows():
                    try:
                        value = safe_convert_to_float(row.get("èµ„äº§ä»·å€¼", 0))
                        if value > 0:
                            total_value += value
                            valid_count += 1
                        elif value == 0:
                            pass  # ä»·å€¼ä¸º0çš„è®°å½•
                        else:
                            error_count += 1
                    except:
                        error_count += 1

                st.metric("æ€»ä»·å€¼", f"Â¥{total_value:,.2f}")

                if valid_count > 0:
                    success_rate = (valid_count / len(filtered_df)) * 100
                    st.caption(f"æœ‰æ•ˆè®°å½•: {valid_count}/{len(filtered_df)} ({success_rate:.1f}%)")

                if error_count > 0:
                    st.caption(f"âš ï¸ {error_count}æ¡è®°å½•æ•°å€¼å¼‚å¸¸")

            except Exception as e:
                st.metric("æ€»ä»·å€¼", "è®¡ç®—é”™è¯¯")
                st.error(f"âŒ è®¡ç®—é”™è¯¯: {str(e)}")


    elif view_mode == "å®ç‰©å°è´¦æ˜ç»†":

        st.subheader("ğŸ“‹ å®ç‰©å°è´¦èµ„äº§æ˜ç»†")

        if not physical_data:
            st.warning("âš ï¸ æš‚æ— å®ç‰©å°è´¦æ•°æ®")

            return

        df = pd.DataFrame(physical_data)

        # æ£€æŸ¥å¿…éœ€åˆ—æ˜¯å¦å­˜åœ¨

        if "å›ºå®šèµ„äº§ç¼–ç " not in df.columns:
            st.error("âŒ å®ç‰©æ•°æ®ä¸­ç¼ºå°‘'å›ºå®šèµ„äº§ç¼–ç 'åˆ—ï¼Œè¯·æ£€æŸ¥æ•°æ®æ ¼å¼")

            st.write("å½“å‰åˆ—åï¼š", list(df.columns))

            return

        # âœ… æ£€æŸ¥å›ºå®šèµ„äº§åŸå€¼å­—æ®µæ˜¯å¦å­˜åœ¨

        if "å›ºå®šèµ„äº§åŸå€¼" not in df.columns:
            st.error("âŒ å®ç‰©æ•°æ®ä¸­ç¼ºå°‘'å›ºå®šèµ„äº§åŸå€¼'åˆ—ï¼Œè¯·æ£€æŸ¥æ•°æ®æ ¼å¼")

            st.write("å½“å‰åˆ—åï¼š", list(df.columns))

            st.info("ğŸ’¡ è¯·ç¡®ä¿Excelæ–‡ä»¶ä¸­åŒ…å«åä¸º'å›ºå®šèµ„äº§åŸå€¼'çš„åˆ—")

            return

        # ä¿®å¤ï¼šæ­£ç¡®æ·»åŠ åŒ¹é…çŠ¶æ€åˆ—

        df["åŒ¹é…çŠ¶æ€"] = df["å›ºå®šèµ„äº§ç¼–ç "].astype(str).apply(

            lambda x: "å·²åŒ¹é…" if str(x).strip() in physical_to_financial_mapping else "æœªåŒ¹é…")

        # æ·»åŠ å¯¹åº”è´¢åŠ¡ç¼–å·åˆ—

        df["å¯¹åº”è´¢åŠ¡ç¼–å·"] = df["å›ºå®šèµ„äº§ç¼–ç "].astype(str).apply(

            lambda x: ", ".join(physical_to_financial_mapping.get(str(x).strip(), [])) if str(

                x).strip() in physical_to_financial_mapping else "æ— ")

        # ç­›é€‰åŠŸèƒ½

        col1, col2, col3 = st.columns(3)

        with col1:

            match_filter = st.selectbox("åŒ¹é…çŠ¶æ€", ["å…¨éƒ¨", "å·²åŒ¹é…", "æœªåŒ¹é…"], key="physical_match")

        with col2:

            # éƒ¨é—¨ç­›é€‰

            all_depts = sorted([dept for dept in df["å­˜æ”¾éƒ¨é—¨"].unique() if dept and str(dept).strip()])

            dept_filter = st.selectbox("æŒ‰éƒ¨é—¨ç­›é€‰", ["å…¨éƒ¨"] + all_depts, key="physical_dept_filter")

        with col3:

            search_term = st.text_input("æœç´¢èµ„äº§", key="physical_search")

        filtered_df = df.copy()

        if match_filter != "å…¨éƒ¨":
            filtered_df = filtered_df[filtered_df["åŒ¹é…çŠ¶æ€"] == match_filter]

        if dept_filter != "å…¨éƒ¨":
            filtered_df = filtered_df[filtered_df["å­˜æ”¾éƒ¨é—¨"] == dept_filter]

        if search_term:
            filtered_df = filtered_df[

                filtered_df["å›ºå®šèµ„äº§åç§°"].astype(str).str.contains(search_term, case=False, na=False) |

                filtered_df["å›ºå®šèµ„äº§ç¼–ç "].astype(str).str.contains(search_term, case=False, na=False)

                ]

        st.info(f"å…± {len(filtered_df)} æ¡è®°å½•ï¼ˆæ€»å®ç‰©èµ„äº§ {len(df)} æ¡ï¼‰")

        # âœ… å›ºå®šä½¿ç”¨"å›ºå®šèµ„äº§åŸå€¼"å­—æ®µ

        value_field = "å›ºå®šèµ„äº§åŸå€¼"

        default_columns = ["å›ºå®šèµ„äº§ç¼–ç ", "å›ºå®šèµ„äº§åç§°", "å›ºå®šèµ„äº§ç±»å‹", "å›ºå®šèµ„äº§åŸå€¼", "ç´¯è®¡æŠ˜æ—§", "èµ„äº§å‡€å€¼", "å­˜æ”¾éƒ¨é—¨", "ä¿ç®¡äºº", "ä½¿ç”¨çŠ¶æ€", "åŒ¹é…çŠ¶æ€", "å¯¹åº”è´¢åŠ¡ç¼–å·"]

        # åªæ˜¾ç¤ºå­˜åœ¨çš„åˆ—

        available_columns = list(filtered_df.columns)

        display_columns = [col for col in default_columns if col in available_columns]

        # âœ… æ ¼å¼åŒ–æ˜¾ç¤ºå›ºå®šèµ„äº§åŸå€¼

        display_df = filtered_df[display_columns].copy()

        for amount_col in ["å›ºå®šèµ„äº§åŸå€¼", "ç´¯è®¡æŠ˜æ—§", "èµ„äº§å‡€å€¼"]:
            if amount_col in display_df.columns:
                display_df[amount_col] = display_df[amount_col].apply(
                    lambda x: f"Â¥{x:,.2f}" if isinstance(x, (int, float)) else (
                        f"Â¥0.00" if pd.isna(x) or x == "" else str(x)))

        st.dataframe(display_df, use_container_width=True)

        # âœ… ç»Ÿè®¡ä¿¡æ¯ - ä»…ä½¿ç”¨å›ºå®šèµ„äº§åŸå€¼å­—æ®µ

        col1, col2, col3 = st.columns(3)

        with col1:

            matched_count = len(filtered_df[filtered_df["åŒ¹é…çŠ¶æ€"] == "å·²åŒ¹é…"])

            st.metric("å·²åŒ¹é…", matched_count)

        with col2:

            unmatched_count = len(filtered_df[filtered_df["åŒ¹é…çŠ¶æ€"] == "æœªåŒ¹é…"])

            st.metric("æœªåŒ¹é…", unmatched_count)

        # âœ… å…³é”®ä¿®å¤ï¼šä»…ä½¿ç”¨å›ºå®šèµ„äº§åŸå€¼å­—æ®µè®¡ç®—æ€»ä»·å€¼ï¼Œæ”¯æŒæ ¸ç®—ç­›é€‰
        try:
            # ğŸ†• æ–°å¢ï¼šæ£€æŸ¥æ˜¯å¦æœ‰æ ¸ç®—å­—æ®µ
            has_accounting_field = "æ˜¯å¦æ ¸ç®—" in filtered_df.columns

            # åŸå§‹è®¡ç®—ï¼ˆåŒ…å«é‡å¤è®°å½•ï¼Œæ”¯æŒæ ¸ç®—ç­›é€‰ï¼‰
            total_value_raw = 0.0
            valid_count = 0
            error_count = 0
            non_accounting_count = 0  # éæ ¸ç®—èµ„äº§æ•°é‡

            for _, row in filtered_df.iterrows():
                try:
                    # ğŸ†• æ£€æŸ¥æ˜¯å¦æ ¸ç®—
                    if has_accounting_field:
                        accounting_status = str(row.get("æ˜¯å¦æ ¸ç®—", "")).strip()
                        if accounting_status not in ["æ˜¯", "Y", "y", "Yes", "YES", "1", "True", "true"]:
                            non_accounting_count += 1
                            continue  # è·³è¿‡éæ ¸ç®—èµ„äº§

                    value = safe_convert_to_float(row.get("å›ºå®šèµ„äº§åŸå€¼", 0))
                    if value > 0:
                        total_value_raw += value
                        valid_count += 1
                    elif value == 0:
                        pass  # ä»·å€¼ä¸º0çš„è®°å½•
                    else:
                        error_count += 1
                except:
                    error_count += 1

            # å»é‡è®¡ç®—ï¼ˆæŒ‰å›ºå®šèµ„äº§ç¼–ç å»é‡ï¼‰
            df_deduped = filtered_df.drop_duplicates(subset=['å›ºå®šèµ„äº§ç¼–ç '], keep='first')

            # ğŸ†• æ–°å¢ï¼šå¯¹å»é‡åçš„æ•°æ®ä¹Ÿåº”ç”¨æ ¸ç®—ç­›é€‰
            total_value_dedup = 0.0
            valid_count_dedup = 0
            non_accounting_dedup_count = 0

            for _, row in df_deduped.iterrows():
                try:
                    # ğŸ†• æ£€æŸ¥æ˜¯å¦æ ¸ç®—
                    if has_accounting_field:
                        accounting_status = str(row.get("æ˜¯å¦æ ¸ç®—", "")).strip()
                        if accounting_status not in ["æ˜¯", "Y", "y", "Yes", "YES", "1", "True", "true"]:
                            non_accounting_dedup_count += 1
                            continue  # è·³è¿‡éæ ¸ç®—èµ„äº§

                    value = safe_convert_to_float(row.get("å›ºå®šèµ„äº§åŸå€¼", 0))
                    if value > 0:
                        total_value_dedup += value
                        valid_count_dedup += 1
                except:
                    pass

            # æ˜¾ç¤ºç»“æœ
            duplicate_count = len(filtered_df) - len(df_deduped)

            if duplicate_count > 0:
                st.metric("å›ºå®šèµ„äº§åŸå€¼æ€»è®¡", f"Â¥{total_value_dedup:,.2f}")
                # âœ… ä¿®å¤ï¼šä½¿ç”¨æ›´ç®€æ´çš„è¯´æ˜æ–‡å­—ï¼Œé¿å…æ–‡å­—è¿‡é•¿
                caption_text = f"å·²å»é‡ ({duplicate_count}æ¡)"
                if has_accounting_field and non_accounting_dedup_count > 0:
                    caption_text += f" | å·²æ’é™¤{non_accounting_dedup_count}æ¡éæ ¸ç®—"
                st.caption(caption_text)
            else:
                st.metric("å›ºå®šèµ„äº§åŸå€¼æ€»è®¡", f"Â¥{total_value_raw:,.2f}")
                caption_text = "æ— é‡å¤è®°å½•"
                if has_accounting_field and non_accounting_count > 0:
                    caption_text += f" | å·²æ’é™¤{non_accounting_count}æ¡éæ ¸ç®—"
                st.caption(caption_text)

            # âœ… æ–°å¢ï¼šæ˜¾ç¤ºæ ¸ç®—ç­›é€‰ç»Ÿè®¡
            if has_accounting_field:
                total_accounting = valid_count if duplicate_count == 0 else valid_count_dedup
                total_non_accounting = non_accounting_count if duplicate_count == 0 else non_accounting_dedup_count
                total_records = total_accounting + total_non_accounting

                if total_non_accounting > 0:
                    st.info(
                        f"ğŸ“Š æ ¸ç®—ç­›é€‰ç»Ÿè®¡: æ ¸ç®—èµ„äº§{total_accounting}æ¡ | éæ ¸ç®—èµ„äº§{total_non_accounting}æ¡ | æ€»è®¡{total_records}æ¡")

            # æ˜¾ç¤ºå¤„ç†ç»Ÿè®¡
            if valid_count > 0:
                success_rate = (valid_count / len(filtered_df)) * 100
                if success_rate < 100:
                    st.warning(f"âš ï¸ {error_count}æ¡è®°å½•æ•°å€¼å¼‚å¸¸")
            else:
                st.error("âŒ æ‰€æœ‰è®°å½•æ•°å€¼å¼‚å¸¸")

        except Exception as e:
            st.metric("å›ºå®šèµ„äº§åŸå€¼æ€»è®¡", "è®¡ç®—é”™è¯¯")
            st.error(f"âŒ è®¡ç®—é”™è¯¯: {str(e)}")

            with st.expander("ğŸš¨ é”™è¯¯è¯¦æƒ…"):
                st.code(f"é”™è¯¯ç±»å‹: {type(e).__name__}\né”™è¯¯ä¿¡æ¯: {str(e)}")
                if len(filtered_df) > 0:
                    st.write("æ•°æ®æ ·æœ¬ï¼š", filtered_df["å›ºå®šèµ„äº§åŸå€¼"].head(3).tolist())

                # âœ… ä¿®å¤ï¼šå°†è¯¦ç»†ä¿¡æ¯ç§»åˆ°ä¸‹æ–¹å•ç‹¬æ˜¾ç¤ºï¼Œé¿å…æŒ¤å‹
                if duplicate_count > 0:
                    st.info(f"ğŸ“Š åŸå§‹è®°å½•: {len(filtered_df)}æ¡ â†’ å»é‡å: {len(df_deduped)}æ¡")

                # æ˜¾ç¤ºå¤„ç†ç»Ÿè®¡
                if valid_count > 0:
                    success_rate = (valid_count / len(filtered_df)) * 100
                    if success_rate < 100:
                        st.warning(f"âš ï¸ {error_count}æ¡è®°å½•æ•°å€¼å¼‚å¸¸")
                else:
                    st.error("âŒ æ‰€æœ‰è®°å½•æ•°å€¼å¼‚å¸¸")

        # âœ… æ–°å¢ï¼šå°†è¯¦ç»†ç»Ÿè®¡æŒ‰é’®ç§»åˆ°åˆ—å¤–ï¼Œå•ç‹¬æ˜¾ç¤º
        if valid_count > 0:
            st.markdown("---")

            # åˆ›å»ºå±•å¼€çš„ç»Ÿè®¡ä¿¡æ¯åŒºåŸŸ
            with st.expander("ğŸ“Š è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯", expanded=False):
                # ä½¿ç”¨4åˆ—å¸ƒå±€æ˜¾ç¤ºæ›´å¤šç»Ÿè®¡ä¿¡æ¯
                stat_col1, stat_col2, stat_col3, stat_col4 = st.columns(4)

                with stat_col1:
                    st.metric("åŸå§‹æ€»ä»·å€¼", f"Â¥{total_value_raw:,.2f}")
                    st.caption(f"åŒ…å« {len(filtered_df)} æ¡è®°å½•")

                with stat_col2:
                    st.metric("å»é‡æ€»ä»·å€¼", f"Â¥{total_value_dedup:,.2f}")
                    st.caption(f"å»é‡å {len(df_deduped)} æ¡è®°å½•")

                with stat_col3:
                    if duplicate_count > 0:
                        reduction = total_value_raw - total_value_dedup
                        st.metric("é‡å¤é‡‘é¢", f"Â¥{reduction:,.2f}")
                        st.caption(f"åˆ é™¤ {duplicate_count} æ¡é‡å¤")
                    else:
                        st.metric("é‡å¤è®°å½•", "0æ¡")
                        st.caption("æ— é‡å¤æ•°æ®")

                with stat_col4:
                    if valid_count > 0:
                        success_rate = (valid_count / len(filtered_df)) * 100
                        st.metric("æ•°æ®æœ‰æ•ˆç‡", f"{success_rate:.1f}%")
                        st.caption(f"{valid_count}/{len(filtered_df)} æ¡æœ‰æ•ˆ")
                    else:
                        st.metric("æ•°æ®æœ‰æ•ˆç‡", "0%")
                        st.caption("æ— æœ‰æ•ˆæ•°æ®")

                # æ˜¾ç¤ºå­—æ®µä½¿ç”¨æƒ…å†µ
                st.info("ğŸ’¡ ç»Ÿè®¡åŸºäº `å›ºå®šèµ„äº§åŸå€¼` å­—æ®µ")

                # æ˜¾ç¤ºé‡å¤è®°å½•è¯¦æƒ…
                if duplicate_count > 0:
                    st.markdown("### ğŸ“‹ é‡å¤è®°å½•åˆ†æ")

                    # é‡å¤è®°å½•ç»Ÿè®¡
                    duplicate_analysis = filtered_df[
                        filtered_df.duplicated(subset=['å›ºå®šèµ„äº§ç¼–ç '], keep=False)].groupby('å›ºå®šèµ„äº§ç¼–ç ').agg({
                        'å›ºå®šèµ„äº§åç§°': 'first',
                        'å›ºå®šèµ„äº§åŸå€¼': ['first', 'count'],
                        'å­˜æ”¾éƒ¨é—¨': lambda x: ', '.join(x.unique()) if len(x.unique()) > 1 else x.iloc[0]
                    }).reset_index()

                    # æ‰å¹³åŒ–åˆ—å
                    duplicate_analysis.columns = ['å›ºå®šèµ„äº§ç¼–ç ', 'å›ºå®šèµ„äº§åç§°', 'å›ºå®šèµ„äº§åŸå€¼', 'é‡å¤æ¬¡æ•°',
                                                  'å­˜æ”¾éƒ¨é—¨']

                    # æ ¼å¼åŒ–æ˜¾ç¤º
                    duplicate_analysis['å›ºå®šèµ„äº§åŸå€¼'] = duplicate_analysis['å›ºå®šèµ„äº§åŸå€¼'].apply(
                        lambda x: f"Â¥{x:,.2f}" if isinstance(x, (int, float)) else x)

                    st.dataframe(duplicate_analysis, use_container_width=True)

                    if st.button("ğŸ“¥ å¯¼å‡ºé‡å¤è®°å½•", key="export_duplicates"):
                        try:
                            output = io.BytesIO()
                            duplicate_analysis.to_excel(output, index=False, engine='openpyxl')
                            output.seek(0)
                            st.download_button(
                                label="ä¸‹è½½é‡å¤è®°å½•Excel",
                                data=output,
                                file_name=f"é‡å¤è®°å½•åˆ†æ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                key="download_duplicates"
                            )
                        except Exception as e:
                            st.error(f"å¯¼å‡ºå¤±è´¥: {str(e)}")

                # æ¨èä½¿ç”¨çš„æ€»ä»·å€¼
                if duplicate_count > 0:
                    st.success(f"âœ… **æ¨èä½¿ç”¨å»é‡åæ€»ä»·å€¼ï¼šÂ¥{total_value_dedup:,.2f}**")
                    st.info(f"ğŸ’¡ å»é‡å¯é¿å…é‡å¤è®¡ç®—ï¼ŒèŠ‚çœ Â¥{total_value_raw - total_value_dedup:,.2f}")
                else:
                    st.success(f"âœ… **å›ºå®šèµ„äº§åŸå€¼æ€»è®¡ï¼šÂ¥{total_value_raw:,.2f}**")
                    st.info("ğŸ’¡ æ•°æ®æ— é‡å¤ï¼Œå¯ç›´æ¥ä½¿ç”¨æ­¤æ€»ä»·å€¼")

        # âœ… å¦‚æœæœ‰æ•°æ®å¼‚å¸¸ï¼Œæ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
        if error_count > 0:
            with st.expander("ğŸ”§ æ•°æ®å¼‚å¸¸åˆ†æ", expanded=False):
                st.write("**å¼‚å¸¸è®°å½•çš„å›ºå®šèµ„äº§åŸå€¼å­—æ®µå†…å®¹ï¼š**")

                # æ‰¾å‡ºå¼‚å¸¸è®°å½•
                error_records = []
                for _, row in filtered_df.iterrows():
                    try:
                        value = safe_convert_to_float(row.get("å›ºå®šèµ„äº§åŸå€¼", 0))
                        if value <= 0 and value != 0:  # æ’é™¤æ­£å¸¸çš„0å€¼
                            error_records.append({
                                'å›ºå®šèµ„äº§ç¼–ç ': row.get('å›ºå®šèµ„äº§ç¼–ç ', ''),
                                'å›ºå®šèµ„äº§åç§°': row.get('å›ºå®šèµ„äº§åç§°', ''),
                                'å›ºå®šèµ„äº§åŸå€¼': row.get('å›ºå®šèµ„äº§åŸå€¼', ''),
                                'åŸå€¼ç±»å‹': type(row.get('å›ºå®šèµ„äº§åŸå€¼', '')).__name__,
                                'è½¬æ¢ç»“æœ': value
                            })
                    except:
                        error_records.append({
                            'å›ºå®šèµ„äº§ç¼–ç ': row.get('å›ºå®šèµ„äº§ç¼–ç ', ''),
                            'å›ºå®šèµ„äº§åç§°': row.get('å›ºå®šèµ„äº§åç§°', ''),
                            'å›ºå®šèµ„äº§åŸå€¼': row.get('å›ºå®šèµ„äº§åŸå€¼', ''),
                            'åŸå€¼ç±»å‹': type(row.get('å›ºå®šèµ„äº§åŸå€¼', '')).__name__,
                            'è½¬æ¢ç»“æœ': 'è½¬æ¢å¤±è´¥'
                        })

                if error_records:
                    error_df = pd.DataFrame(error_records[:10])  # åªæ˜¾ç¤ºå‰10æ¡
                    st.dataframe(error_df, use_container_width=True)

                    if len(error_records) > 10:
                        st.info(f"æ˜¾ç¤ºå‰10æ¡ï¼Œå…±{len(error_records)}æ¡å¼‚å¸¸è®°å½•")

                st.markdown("**å¯èƒ½çš„é—®é¢˜åŠè§£å†³æ–¹æ¡ˆï¼š**")
                st.markdown("- ğŸ”§ **æ–‡æœ¬æ ¼å¼**: åŸå€¼å­—æ®µåŒ…å«æ–‡å­—ï¼Œéœ€è¦æ¸…ç†æ•°æ®")
                st.markdown("- ğŸ”§ **ç‰¹æ®Šå­—ç¬¦**: åŒ…å«è´§å¸ç¬¦å·æˆ–åƒä½åˆ†éš”ç¬¦ï¼Œéœ€è¦æ ¼å¼åŒ–")
                st.markdown("- ğŸ”§ **ç©ºå€¼**: å­—æ®µä¸ºç©ºæˆ–NaNï¼Œå»ºè®®å¡«å…¥0æˆ–åˆ é™¤è®°å½•")
                st.markdown("- ğŸ”§ **è´Ÿæ•°**: åŸå€¼ä¸ºè´Ÿæ•°ï¼Œéœ€è¦æ£€æŸ¥æ•°æ®åˆç†æ€§")

    else:  # æœªåŒ¹é…èµ„äº§
        st.subheader("âš ï¸ æœªåŒ¹é…èµ„äº§åˆ—è¡¨")

        tab1, tab2 = st.tabs(["æœªåŒ¹é…è´¢åŠ¡èµ„äº§", "æœªåŒ¹é…å®ç‰©èµ„äº§"])

        with tab1:
            if not financial_data:
                st.warning("âš ï¸ æš‚æ— è´¢åŠ¡ç³»ç»Ÿæ•°æ®")
            else:
                # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
                if financial_data and "èµ„äº§ç¼–å·+åºå·" not in pd.DataFrame(financial_data).columns:
                    st.error("âŒ è´¢åŠ¡æ•°æ®ä¸­ç¼ºå°‘'èµ„äº§ç¼–å·+åºå·'åˆ—")
                    return

                # ä¿®å¤ï¼šæ­£ç¡®ç­›é€‰æœªåŒ¹é…çš„è´¢åŠ¡èµ„äº§
                unmatched_financial = [f for f in financial_data if
                                       str(f.get("èµ„äº§ç¼–å·+åºå·", "")).strip() not in financial_to_physical_mapping]

                if unmatched_financial:  # âœ… æ·»åŠ ï¼šåˆ¤æ–­æ˜¯å¦æœ‰æœªåŒ¹é…æ•°æ®
                    df = pd.DataFrame(unmatched_financial)  # âœ… æ·»åŠ ï¼šåˆ›å»ºDataFrame
                    st.info(f"å…± {len(df)} æ¡æœªåŒ¹é…è´¢åŠ¡èµ„äº§ï¼ˆæ€»è®¡ {len(financial_data)} æ¡ï¼‰")

                    # æ·»åŠ æœç´¢åŠŸèƒ½
                    search_term = st.text_input("æœç´¢æœªåŒ¹é…è´¢åŠ¡èµ„äº§", key="search_unmatched_financial")
                    if search_term:  # âœ… ä¿®å¤ï¼šæ­£ç¡®çš„ç¼©è¿›
                        df = df[  # âœ… ä¿®å¤ï¼šæ­£ç¡®çš„ç¼©è¿›
                            df["èµ„äº§åç§°"].astype(str).str.contains(search_term, case=False, na=False) |
                            df["èµ„äº§ç¼–å·+åºå·"].astype(str).str.contains(search_term, case=False, na=False)
                            ]
                        st.info(f"æœç´¢ç»“æœï¼š{len(df)} æ¡è®°å½•")

                    # é€‰æ‹©è¦æ˜¾ç¤ºçš„åˆ—
                    available_columns = list(df.columns)
                    default_columns = ["èµ„äº§ç¼–å·+åºå·", "èµ„äº§åç§°", "èµ„äº§åˆ†ç±»", "èµ„äº§ä»·å€¼", "ç´¯è®¡æŠ˜æ—§", "èµ„äº§å‡€é¢", "éƒ¨é—¨åç§°", "ä¿ç®¡äºº"]
                    display_columns = [col for col in default_columns if col in available_columns]

                    # æ ¼å¼åŒ–æ˜¾ç¤º
                    display_df = df[display_columns].copy()
                    # æ ¼å¼åŒ–æ‰€æœ‰é‡‘é¢å­—æ®µ
                    for amount_col in ["èµ„äº§ä»·å€¼", "ç´¯è®¡æŠ˜æ—§", "èµ„äº§å‡€é¢"]:
                        if amount_col in display_df.columns:
                            display_df[amount_col] = display_df[amount_col].apply(
                                lambda x: f"Â¥{x:,.2f}" if isinstance(x, (int, float)) else x)

                    st.dataframe(display_df, use_container_width=True)

                    # ç»Ÿè®¡ä¿¡æ¯
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        # å®‰å…¨è®¡ç®—æœªåŒ¹é…è´¢åŠ¡èµ„äº§æ€»ä»·å€¼
                        try:
                            total_value = 0.0
                            for record in unmatched_financial:  # âœ… ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„å˜é‡
                                if isinstance(record, dict):
                                    # ä½¿ç”¨è´¢åŠ¡ç³»ç»Ÿçš„ä»·å€¼å­—æ®µ
                                    value = safe_get_value(record, "èµ„äº§ä»·å€¼", 0)
                                    total_value += value
                            st.metric("æœªåŒ¹é…èµ„äº§æ€»ä»·å€¼", f"Â¥{total_value:,.2f}")
                        except Exception as e:
                            st.metric("æœªåŒ¹é…èµ„äº§æ€»ä»·å€¼", "è®¡ç®—é”™è¯¯")

                    with col2:
                        match_rate = ((len(financial_data) - len(unmatched_financial)) / len(
                            financial_data) * 100) if financial_data else 0
                        st.metric("è´¢åŠ¡èµ„äº§åŒ¹é…ç‡", f"{match_rate:.1f}%")

                        with col3:
                            # è®¡ç®—ç´¯è®¡æŠ˜æ—§æ€»é¢ - è´¢åŠ¡ç³»ç»Ÿï¼Œä½¿ç”¨"ç´¯è®¡æŠ˜æ—§"å­—æ®µ
                            try:
                                total_depreciation = 0.0
                                valid_depreciation_count = 0
                                zero_depreciation_count = 0

                                for record in unmatched_financial:
                                    if isinstance(record, dict):
                                        # ç›´æ¥ä½¿ç”¨"ç´¯è®¡æŠ˜æ—§"å­—æ®µ
                                        depreciation_value = safe_get_value(record, "ç´¯è®¡æŠ˜æ—§", 0)

                                        if depreciation_value > 0:
                                            total_depreciation += depreciation_value
                                            valid_depreciation_count += 1
                                        elif depreciation_value == 0:
                                            zero_depreciation_count += 1

                                st.metric("æœªåŒ¹é…ç´¯è®¡æŠ˜æ—§æ€»é¢", f"Â¥{total_depreciation:,.2f}")

                                # æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡
                                if valid_depreciation_count > 0:
                                    st.caption(f"âœ… æœ‰æŠ˜æ—§: {valid_depreciation_count}æ¡")
                                if zero_depreciation_count > 0:
                                    st.caption(f"âšª é›¶æŠ˜æ—§: {zero_depreciation_count}æ¡")

                            except Exception as e:
                                st.metric("æœªåŒ¹é…ç´¯è®¡æŠ˜æ—§æ€»é¢", "è®¡ç®—é”™è¯¯")
                                st.error(f"è®¡ç®—é”™è¯¯: {str(e)}")

                        with col4:
                            # è®¡ç®—èµ„äº§å‡€å€¼æ€»è®¡ - è´¢åŠ¡ç³»ç»Ÿï¼Œä½¿ç”¨"èµ„äº§å‡€é¢"å­—æ®µ
                            try:
                                total_net_value = 0.0
                                valid_net_count = 0
                                zero_net_count = 0

                                for record in unmatched_financial:
                                    if isinstance(record, dict):
                                        # ç›´æ¥ä½¿ç”¨"èµ„äº§å‡€é¢"å­—æ®µ
                                        net_value = safe_get_value(record, "èµ„äº§å‡€é¢", 0)

                                        if net_value > 0:
                                            total_net_value += net_value
                                            valid_net_count += 1
                                        elif net_value == 0:
                                            zero_net_count += 1

                                st.metric("æœªåŒ¹é…èµ„äº§å‡€å€¼æ€»è®¡", f"Â¥{total_net_value:,.2f}")

                                # æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡
                                if valid_net_count > 0:
                                    st.caption(f"âœ… æœ‰å‡€å€¼: {valid_net_count}æ¡")
                                if zero_net_count > 0:
                                    st.caption(f"âšª é›¶å‡€å€¼: {zero_net_count}æ¡")

                                st.info("ğŸ’¡ ä½¿ç”¨è´¢åŠ¡ç³»ç»Ÿ `èµ„äº§å‡€é¢` å­—æ®µ")

                            except Exception as e:
                                st.metric("æœªåŒ¹é…èµ„äº§å‡€å€¼æ€»è®¡", "è®¡ç®—é”™è¯¯")
                                st.caption(f"é”™è¯¯: {str(e)}")

        with tab2:
            if not physical_data:
                st.warning("âš ï¸ æš‚æ— å®ç‰©å°è´¦æ•°æ®")
            else:
                # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
                if physical_data and "å›ºå®šèµ„äº§ç¼–ç " not in pd.DataFrame(physical_data).columns:
                    st.error("âŒ å®ç‰©æ•°æ®ä¸­ç¼ºå°‘'å›ºå®šèµ„äº§ç¼–ç 'åˆ—")
                    return

                # ä¿®å¤ï¼šæ­£ç¡®ç­›é€‰æœªåŒ¹é…çš„å®ç‰©èµ„äº§
                unmatched_physical = [p for p in physical_data if
                                      str(p.get("å›ºå®šèµ„äº§ç¼–ç ", "")).strip() not in physical_to_financial_mapping]

                if unmatched_physical:  # âœ… æ·»åŠ ï¼šåˆ¤æ–­æ˜¯å¦æœ‰æœªåŒ¹é…æ•°æ®
                    df = pd.DataFrame(unmatched_physical)  # âœ… æ·»åŠ ï¼šåˆ›å»ºDataFrame
                    st.info(f"å…± {len(df)} æ¡æœªåŒ¹é…å®ç‰©èµ„äº§ï¼ˆæ€»è®¡ {len(physical_data)} æ¡ï¼‰")

                    # æ·»åŠ æœç´¢åŠŸèƒ½
                    search_term = st.text_input("æœç´¢æœªåŒ¹é…å®ç‰©èµ„äº§", key="search_unmatched_physical")
                    if search_term:
                        df = df[
                            df["å›ºå®šèµ„äº§åç§°"].astype(str).str.contains(search_term, case=False, na=False) |
                            df["å›ºå®šèµ„äº§ç¼–ç "].astype(str).str.contains(search_term, case=False, na=False)
                            ]
                        st.info(f"æœç´¢ç»“æœï¼š{len(df)} æ¡è®°å½•")

                    # é€‰æ‹©è¦æ˜¾ç¤ºçš„åˆ—
                    available_columns = list(df.columns)
                    default_columns = ["å›ºå®šèµ„äº§ç¼–ç ", "å›ºå®šèµ„äº§åç§°", "å›ºå®šèµ„äº§ç±»å‹", "å›ºå®šèµ„äº§åŸå€¼", "ç´¯è®¡æŠ˜æ—§", "èµ„äº§å‡€å€¼", "å­˜æ”¾éƒ¨é—¨", "ä¿ç®¡äºº", "ä½¿ç”¨çŠ¶æ€"]
                    display_columns = [col for col in default_columns if col in available_columns]

                    # æ ¼å¼åŒ–æ˜¾ç¤º
                    display_df = df[display_columns].copy()
                    # æ ¼å¼åŒ–æ‰€æœ‰é‡‘é¢å­—æ®µ
                    for amount_col in ["å›ºå®šèµ„äº§åŸå€¼", "èµ„äº§ä»·å€¼", "ç´¯è®¡æŠ˜æ—§", "èµ„äº§å‡€å€¼"]:
                        if amount_col in display_df.columns:
                            display_df[amount_col] = display_df[amount_col].apply(
                                lambda x: f"Â¥{x:,.2f}" if isinstance(x, (int, float)) else (
                                    f"Â¥0.00" if pd.isna(x) or x == "" else str(x)))

                    st.dataframe(display_df, use_container_width=True)

                    # ç»Ÿè®¡ä¿¡æ¯
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        # æ™ºèƒ½è¯†åˆ«å®ç‰©èµ„äº§ä»·å€¼å­—æ®µå¹¶è®¡ç®—æ€»ä»·å€¼
                        try:
                            total_value = 0.0
                            processed_count = 0
                            field_usage_stats = {}  # ç»Ÿè®¡å„å­—æ®µçš„ä½¿ç”¨æƒ…å†µ

                            # ğŸ” æ‰©å±•çš„å®ç‰©èµ„äº§ä»·å€¼å­—æ®µåˆ—è¡¨ï¼ˆè´¢åŠ¡äººå‘˜å¸¸ç”¨å­—æ®µï¼‰
                            possible_value_fields = [
                                # æ ‡å‡†è´¢åŠ¡å­—æ®µ
                                "èµ„äº§ä»·å€¼", "å›ºå®šèµ„äº§åŸå€¼", "åŸå€¼", "è´¦é¢ä»·å€¼", "å‡€å€¼", "è´¦é¢å‡€å€¼",
                                "èµ„äº§åŸå€¼", "è´­ç½®ä»·å€¼", "è¯„ä¼°ä»·å€¼", "å¸‚å€¼", "ä»·å€¼", "å…¥è´¦ä»·å€¼",

                                # å¸¸è§å˜ä½“å­—æ®µ
                                "é‡‘é¢", "æ€»ä»·", "å•ä»·", "æˆæœ¬", "è´­ä¹°ä»·æ ¼", "é‡‡è´­ä»·æ ¼", "å†å²æˆæœ¬",
                                "èµ„äº§æ€»é¢", "å›ºå®šèµ„äº§å‡€å€¼", "èµ„äº§å‡€é¢", "æŠ•èµ„æˆæœ¬", "å»ºé€ æˆæœ¬",

                                # å¯èƒ½çš„è‹±æ–‡å­—æ®µ
                                "Value", "Amount", "Cost", "Price", "Total", "Net_Value",

                                # å¯èƒ½åŒ…å«æ•°å­—çš„å…¶ä»–å­—æ®µ
                                "ä»·æ ¼", "è´¹ç”¨", "æ”¯å‡º", "æŠ•å…¥", "é€ ä»·"
                            ]

                            # ğŸ”§ ç¬¬ä¸€æ­¥ï¼šå°è¯•æ ‡å‡†å­—æ®µè¯†åˆ«
                            for record in unmatched_physical:
                                if isinstance(record, dict):
                                    asset_value = 0.0
                                    used_field = None

                                    # æŒ‰ä¼˜å…ˆçº§å°è¯•å„ä¸ªå¯èƒ½çš„ä»·å€¼å­—æ®µ
                                    for field in possible_value_fields:
                                        if field in record and record[field] is not None:
                                            try:
                                                converted_value = safe_convert_to_float(record[field])
                                                if converted_value > 0:  # åªæ¥å—å¤§äº0çš„å€¼
                                                    asset_value = converted_value
                                                    used_field = field
                                                    break
                                            except:
                                                continue

                                    # å¦‚æœæ‰¾åˆ°æœ‰æ•ˆä»·å€¼ï¼Œç´¯åŠ å¹¶è®°å½•
                                    if asset_value > 0 and used_field:
                                        total_value += asset_value
                                        processed_count += 1

                                        # ç»Ÿè®¡å­—æ®µä½¿ç”¨æƒ…å†µ
                                        if used_field not in field_usage_stats:
                                            field_usage_stats[used_field] = 0
                                        field_usage_stats[used_field] += 1

                            # ğŸ“Š æ˜¾ç¤ºè®¡ç®—ç»“æœ
                            st.metric("æœªåŒ¹é…èµ„äº§æ€»ä»·å€¼", f"Â¥{total_value:,.2f}")

                            # âœ… æˆåŠŸå¤„ç†çš„æƒ…å†µ
                            if processed_count > 0:
                                success_rate = (processed_count / len(unmatched_physical)) * 100
                                st.success(
                                    f"âœ… æˆåŠŸå¤„ç† {processed_count}/{len(unmatched_physical)} æ¡è®°å½• ({success_rate:.1f}%)")

                                # æ˜¾ç¤ºå­—æ®µä½¿ç”¨ç»Ÿè®¡
                                with st.expander("ğŸ“Š ä»·å€¼å­—æ®µä½¿ç”¨ç»Ÿè®¡", expanded=True):
                                    st.write("**æˆåŠŸè¯†åˆ«çš„ä»·å€¼å­—æ®µï¼š**")
                                    for field, count in sorted(field_usage_stats.items(), key=lambda x: x[1],
                                                               reverse=True):
                                        percentage = (count / processed_count) * 100
                                        st.write(f"- **{field}**: {count} æ¡è®°å½• ({percentage:.1f}%)")

                                    st.info(
                                        f"ğŸ’¡ å»ºè®®ï¼šä¸»è¦ä½¿ç”¨ `{max(field_usage_stats.items(), key=lambda x: x[1])[0]}` å­—æ®µä½œä¸ºä»·å€¼å­—æ®µ")

                            # âŒ å¤„ç†å¤±è´¥çš„æƒ…å†µ
                            else:
                                st.error(f"âŒ æ— æ³•ä» {len(unmatched_physical)} æ¡è®°å½•ä¸­æå–æœ‰æ•ˆä»·å€¼")

                                # ğŸ” æ˜¾ç¤ºè¯¦ç»†è°ƒè¯•ä¿¡æ¯
                                with st.expander("ğŸ”§ è¯¦ç»†å­—æ®µåˆ†æ", expanded=True):
                                    if unmatched_physical:
                                        sample_record = unmatched_physical[0]

                                        st.markdown("### ğŸ“‹ ç¬¬ä¸€æ¡è®°å½•çš„å®Œæ•´å­—æ®µåˆ†æ")

                                        # æ˜¾ç¤ºæ‰€æœ‰å­—æ®µ
                                        col_left, col_right = st.columns(2)

                                        with col_left:
                                            st.write("**æ‰€æœ‰å­—æ®µåŠå…¶å€¼ï¼š**")
                                            for key, value in sample_record.items():
                                                # å°è¯•è½¬æ¢ä¸ºæ•°å­—çœ‹æ˜¯å¦å¯èƒ½æ˜¯ä»·å€¼å­—æ®µ
                                                converted = safe_convert_to_float(value)
                                                if converted > 0:
                                                    st.write(f"ğŸŸ¢ `{key}`: {value} â†’ **{converted:,.2f}** â­")
                                                else:
                                                    st.write(f"ğŸ”˜ `{key}`: {value}")

                                        with col_right:
                                            st.write("**å¯èƒ½çš„ä»·å€¼å­—æ®µï¼ˆæ•°å€¼>0ï¼‰ï¼š**")
                                            potential_fields = {}
                                            for key, value in sample_record.items():
                                                converted = safe_convert_to_float(value)
                                                if converted > 0:
                                                    potential_fields[key] = converted

                                            if potential_fields:
                                                for key, value in sorted(potential_fields.items(), key=lambda x: x[1],
                                                                         reverse=True):
                                                    st.write(f"ğŸ’° **{key}**: Â¥{value:,.2f}")
                                            else:
                                                st.warning("âš ï¸ æœªå‘ç°åŒ…å«æœ‰æ•ˆæ•°å€¼çš„å­—æ®µ")

                                        # ğŸ”§ æ‰‹åŠ¨å­—æ®µé€‰æ‹©åŠŸèƒ½
                                        st.markdown("---")
                                        st.markdown("### ğŸ› ï¸ æ‰‹åŠ¨æŒ‡å®šä»·å€¼å­—æ®µ")
                                        st.info("å¦‚æœè‡ªåŠ¨è¯†åˆ«å¤±è´¥ï¼Œæ‚¨å¯ä»¥æ‰‹åŠ¨é€‰æ‹©æ­£ç¡®çš„ä»·å€¼å­—æ®µï¼š")

                                        available_fields = [k for k in sample_record.keys() if
                                                            sample_record[k] is not None]
                                        selected_field = st.selectbox(
                                            "é€‰æ‹©åŒ…å«èµ„äº§ä»·å€¼çš„å­—æ®µï¼š",
                                            ["è¯·é€‰æ‹©å­—æ®µ..."] + available_fields,
                                            key="manual_value_field_physical_enhanced"
                                        )

                                        if selected_field != "è¯·é€‰æ‹©å­—æ®µ..." and st.button("ğŸ”„ ä½¿ç”¨é€‰å®šå­—æ®µé‡æ–°è®¡ç®—",
                                                                                           key="recalc_physical_enhanced"):
                                            # ä½¿ç”¨æ‰‹åŠ¨é€‰æ‹©çš„å­—æ®µé‡æ–°è®¡ç®—
                                            manual_total = 0.0
                                            manual_count = 0
                                            manual_errors = 0

                                            for record in unmatched_physical:
                                                if isinstance(record, dict) and selected_field in record:
                                                    try:
                                                        value = safe_convert_to_float(record[selected_field])
                                                        if value > 0:
                                                            manual_total += value
                                                            manual_count += 1
                                                        elif value == 0:
                                                            pass  # ä»·å€¼ä¸º0çš„è®°å½•
                                                        else:
                                                            manual_errors += 1
                                                    except:
                                                        manual_errors += 1

                                            # æ˜¾ç¤ºé‡æ–°è®¡ç®—ç»“æœ
                                            st.success(f"âœ… ä½¿ç”¨å­—æ®µ `{selected_field}` é‡æ–°è®¡ç®—å®Œæˆï¼")

                                            col1, col2, col3 = st.columns(3)
                                            with col1:
                                                st.metric("é‡æ–°è®¡ç®—æ€»ä»·å€¼", f"Â¥{manual_total:,.2f}")
                                            with col2:
                                                st.metric("æœ‰æ•ˆè®°å½•æ•°", f"{manual_count}/{len(unmatched_physical)}")
                                            with col3:
                                                success_rate = (manual_count / len(unmatched_physical)) * 100
                                                st.metric("æˆåŠŸç‡", f"{success_rate:.1f}%")

                                            if manual_errors > 0:
                                                st.warning(f"âš ï¸ {manual_errors} æ¡è®°å½•æ— æ³•è½¬æ¢ä¸ºæœ‰æ•ˆæ•°å€¼")

                                            # æä¾›åº”ç”¨ä¿®å¤çš„é€‰é¡¹
                                            if manual_total > 0:
                                                st.info("ğŸ’¡ å¦‚æœè¿™ä¸ªç»“æœæ­£ç¡®ï¼Œå»ºè®®è”ç³»æŠ€æœ¯äººå‘˜å°†æ­¤å­—æ®µè®¾ç½®ä¸ºé»˜è®¤ä»·å€¼å­—æ®µ")

                        except Exception as e:
                            st.metric("æœªåŒ¹é…èµ„äº§æ€»ä»·å€¼", "è®¡ç®—é”™è¯¯")
                            st.error(f"âŒ è®¡ç®—é”™è¯¯è¯¦æƒ…: {str(e)}")

                            # æ˜¾ç¤ºå¼‚å¸¸è°ƒè¯•ä¿¡æ¯
                            with st.expander("ğŸš¨ å¼‚å¸¸è¯¦æƒ…"):
                                st.code(f"é”™è¯¯ç±»å‹: {type(e).__name__}\né”™è¯¯ä¿¡æ¯: {str(e)}")
                                if unmatched_physical:
                                    st.write("æ•°æ®æ ·æœ¬ï¼š", unmatched_physical[0])

                            st.metric("æœªåŒ¹é…èµ„äº§æ€»ä»·å€¼", f"Â¥{total_value:,.2f}")

                            # è°ƒè¯•ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
                            if total_value == 0 and len(unmatched_physical) > 0:
                                st.warning(
                                    f"âš ï¸ æ£€æµ‹åˆ°{len(unmatched_physical)}æ¡æœªåŒ¹é…èµ„äº§ä½†æ€»ä»·å€¼ä¸º0ï¼Œå¯èƒ½æ˜¯æ•°æ®å­—æ®µé—®é¢˜")
                                with st.expander("ğŸ”§ è°ƒè¯•ä¿¡æ¯"):
                                    sample_record = unmatched_physical[0]
                                    st.write("ç¬¬ä¸€æ¡è®°å½•çš„å­—æ®µï¼š", list(sample_record.keys()))
                                    st.write("ä»·å€¼ç›¸å…³å­—æ®µï¼š", {k: v for k, v in sample_record.items() if
                                                               "ä»·å€¼" in k or "é‡‘é¢" in k or "å€¼" in k or "åŸå€¼" in k})

                        except Exception as e:
                            st.metric("æœªåŒ¹é…èµ„äº§æ€»ä»·å€¼", "è®¡ç®—é”™è¯¯")
                            st.error(f"è®¡ç®—é”™è¯¯è¯¦æƒ…: {str(e)}")
                    with col2:
                        match_rate = ((len(physical_data) - len(unmatched_physical)) / len(
                            physical_data) * 100) if physical_data else 0
                        st.metric("å®ç‰©èµ„äº§åŒ¹é…ç‡", f"{match_rate:.1f}%")

                    # å¯¼å‡ºæœªåŒ¹é…å®ç‰©èµ„äº§
                    if st.button("ğŸ“¥ å¯¼å‡ºæœªåŒ¹é…å®ç‰©èµ„äº§", key="export_unmatched_physical"):
                        try:
                            output = io.BytesIO()
                            df[display_columns].to_excel(output, index=False, engine='openpyxl')
                            output.seek(0)
                            st.download_button(
                                label="ä¸‹è½½Excelæ–‡ä»¶",
                                data=output,
                                file_name=f"æœªåŒ¹é…å®ç‰©èµ„äº§_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                key="download_unmatched_physical"
                            )
                        except Exception as e:
                            st.error(f"å¯¼å‡ºå¤±è´¥: {str(e)}")
                else:  # âœ… ä¿®å¤ï¼šæ­£ç¡®çš„ç¼©è¿›ï¼Œä¸if unmatched_physicalå¯¹é½
                    st.success("âœ… æ‰€æœ‰å®ç‰©èµ„äº§éƒ½å·²åŒ¹é…")

                with col3:
                    # è®¡ç®—ç´¯è®¡æŠ˜æ—§æ€»é¢ - å®ç‰©ç³»ç»Ÿï¼Œä½¿ç”¨"ç´¯è®¡æŠ˜æ—§"å­—æ®µ
                    try:
                        total_depreciation = 0.0
                        valid_depreciation_count = 0
                        zero_depreciation_count = 0

                        for record in unmatched_physical:
                            if isinstance(record, dict):
                                # ç›´æ¥ä½¿ç”¨"ç´¯è®¡æŠ˜æ—§"å­—æ®µ
                                depreciation_value = safe_get_value(record, "ç´¯è®¡æŠ˜æ—§", 0)

                                if depreciation_value > 0:
                                    total_depreciation += depreciation_value
                                    valid_depreciation_count += 1
                                elif depreciation_value == 0:
                                    zero_depreciation_count += 1

                        st.metric("æœªåŒ¹é…ç´¯è®¡æŠ˜æ—§æ€»é¢", f"Â¥{total_depreciation:,.2f}")

                        # æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡
                        if valid_depreciation_count > 0:
                            st.caption(f"âœ… æœ‰æŠ˜æ—§: {valid_depreciation_count}æ¡")
                        if zero_depreciation_count > 0:
                            st.caption(f"âšª é›¶æŠ˜æ—§: {zero_depreciation_count}æ¡")

                        st.info("ğŸ’¡ ä½¿ç”¨å®ç‰©ç³»ç»Ÿ `ç´¯è®¡æŠ˜æ—§` å­—æ®µ")

                    except Exception as e:
                        st.metric("æœªåŒ¹é…ç´¯è®¡æŠ˜æ—§æ€»é¢", "è®¡ç®—é”™è¯¯")
                        st.caption(f"é”™è¯¯: {str(e)}")

                with col4:
                    # è®¡ç®—èµ„äº§å‡€å€¼æ€»è®¡ - å®ç‰©ç³»ç»Ÿï¼Œé€šè¿‡"å›ºå®šèµ„äº§åŸå€¼-ç´¯è®¡æŠ˜æ—§"è®¡ç®—
                    try:
                        total_net_value = 0.0
                        calculated_count = 0
                        no_original_count = 0
                        negative_net_count = 0

                        for record in unmatched_physical:
                            if isinstance(record, dict):
                                # è·å–å›ºå®šèµ„äº§åŸå€¼
                                original_value = safe_get_value(record, "å›ºå®šèµ„äº§åŸå€¼", 0)

                                if original_value > 0:
                                    # è·å–ç´¯è®¡æŠ˜æ—§
                                    depreciation_value = safe_get_value(record, "ç´¯è®¡æŠ˜æ—§", 0)

                                    # è®¡ç®—å‡€å€¼ = å›ºå®šèµ„äº§åŸå€¼ - ç´¯è®¡æŠ˜æ—§
                                    calculated_net = original_value - depreciation_value

                                    if calculated_net >= 0:
                                        total_net_value += calculated_net
                                        calculated_count += 1
                                    else:
                                        negative_net_count += 1
                                else:
                                    no_original_count += 1

                        st.metric("æœªåŒ¹é…èµ„äº§å‡€å€¼æ€»è®¡", f"Â¥{total_net_value:,.2f}")

                        # æ˜¾ç¤ºè®¡ç®—ç»Ÿè®¡
                        if calculated_count > 0:
                            st.caption(f"ğŸ§® æˆåŠŸè®¡ç®—: {calculated_count}æ¡")
                        if no_original_count > 0:
                            st.caption(f"âšª æ— åŸå€¼: {no_original_count}æ¡")
                        if negative_net_count > 0:
                            st.caption(f"âš ï¸ è´Ÿå‡€å€¼: {negative_net_count}æ¡")

                        st.info("ğŸ’¡ å‡€å€¼ = å›ºå®šèµ„äº§åŸå€¼ - ç´¯è®¡æŠ˜æ—§")

                    except Exception as e:
                        st.metric("æœªåŒ¹é…èµ„äº§å‡€å€¼æ€»è®¡", "è®¡ç®—é”™è¯¯")
                        st.caption(f"é”™è¯¯: {str(e)}")


def main():
    """ä¸»å‡½æ•°"""
    st.title("ğŸ”— èµ„äº§æ˜ å°„å…³ç³»æŸ¥è¯¢")

    # ä¾§è¾¹æ å¯¼èˆª
    with st.sidebar:
        st.header("ğŸ“‹ ç³»ç»Ÿå¯¼èˆª")

        # åˆå§‹åŒ– session state
        if 'current_page' not in st.session_state:
            st.session_state.current_page = "ğŸ“¥ æ•°æ®å¯¼å…¥"

        # åˆ›å»ºå‚ç›´å¯¼èˆªæŒ‰é’®
        st.markdown("### ğŸ”§ åŠŸèƒ½æ¨¡å—")

        if st.button("ğŸ“¥ æ•°æ®å¯¼å…¥",
                     type="primary" if st.session_state.current_page == "ğŸ“¥ æ•°æ®å¯¼å…¥" else "secondary",
                     use_container_width=True, key="nav_import"):
            st.session_state.current_page = "ğŸ“¥ æ•°æ®å¯¼å…¥"
            st.rerun()

        if st.button("ğŸ” æ˜ å°„æŸ¥è¯¢",
                     type="primary" if st.session_state.current_page == "ğŸ” æ˜ å°„æŸ¥è¯¢" else "secondary",
                     use_container_width=True, key="nav_query"):
            st.session_state.current_page = "ğŸ” æ˜ å°„æŸ¥è¯¢"
            st.rerun()

        if st.button("ğŸ“Š æ•°æ®ç»Ÿè®¡",
                     type="primary" if st.session_state.current_page == "ğŸ“Š æ•°æ®ç»Ÿè®¡" else "secondary",
                     use_container_width=True, key="nav_stats"):
            st.session_state.current_page = "ğŸ“Š æ•°æ®ç»Ÿè®¡"
            st.rerun()

        if st.button("ğŸ“‹ å…¨éƒ¨æ•°æ®",
                     type="primary" if st.session_state.current_page == "ğŸ“‹ å…¨éƒ¨æ•°æ®" else "secondary",
                     use_container_width=True, key="nav_all"):
            st.session_state.current_page = "ğŸ“‹ å…¨éƒ¨æ•°æ®"
            st.rerun()

        # è·å–å½“å‰é¡µé¢
        page = st.session_state.current_page

        st.markdown("---")
        st.markdown("### ğŸ“ ä½¿ç”¨è¯´æ˜")
        st.markdown("""
        1. **æ•°æ®å¯¼å…¥**ï¼šä¸Šä¼ Excelæ–‡ä»¶å¯¼å…¥æ•°æ®
        2. **æ˜ å°„æŸ¥è¯¢**ï¼šæŸ¥è¯¢èµ„äº§å¯¹åº”å…³ç³»
        3. **æ•°æ®ç»Ÿè®¡**ï¼šæŸ¥çœ‹ç»Ÿè®¡åˆ†æç»“æœ
        4. **å…¨éƒ¨æ•°æ®**ï¼šæµè§ˆæ‰€æœ‰æ•°æ®è®°å½•
        """)

        # âœ… ä¿®å¤ï¼šåªæ˜¾ç¤ºä¸€æ¬¡æ•°æ®çŠ¶æ€ï¼Œå¹¶ä¸”é™é»˜åŠ è½½
        st.markdown("---")
    st.markdown("### ğŸ”§ GitHubé…ç½®æ£€æŸ¥")
    
    if st.button("ğŸ” æ£€æŸ¥GitHubé…ç½®", key="check_github"):
        config = get_github_config()
        if config:
            st.success("âœ… GitHubé…ç½®å·²æ‰¾åˆ°")
            st.write(f"ä»“åº“: {config['repo']}")
            st.write(f"Token: {'*' * (len(config['token']) - 4) + config['token'][-4:]}")
            
            # æµ‹è¯•GitHubè¿æ¥
            try:
                g = Github(config["token"])
                repo = g.get_repo(config["repo"])
                st.success(f"âœ… ä»“åº“è¿æ¥æˆåŠŸ: {repo.full_name}")
                
                # æ£€æŸ¥dataæ–‡ä»¶å¤¹
                try:
                    contents = repo.get_contents("data")
                    files = [item.name for item in contents if item.type == "file"]
                    st.write(f"ğŸ“ dataæ–‡ä»¶å¤¹æ–‡ä»¶: {files}")
                except Exception as e:
                    st.error(f"âŒ dataæ–‡ä»¶å¤¹è®¿é—®å¤±è´¥: {str(e)}")
                    
            except Exception as e:
                st.error(f"âŒ GitHubè¿æ¥å¤±è´¥: {str(e)}")
        else:
            st.error("âŒ GitHubé…ç½®æœªæ‰¾åˆ°")
 if GITHUB_AVAILABLE and get_github_config():
    st.sidebar.markdown("---")
    
    # æ·»åŠ æ–‡ä»¶ä¿®å¤åŠŸèƒ½
    create_sample_data_files()
    
    # æ·»åŠ ä¿®å¤æŒ‡å—
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ğŸš¨ æ–‡ä»¶ä¿®å¤æŒ‡å—")
    st.sidebar.info("""
    **å½“å‰é—®é¢˜**: JSONæ–‡ä»¶ä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯

    **è§£å†³æ­¥éª¤**:
    1. ç‚¹å‡»"æ£€æŸ¥æ–‡ä»¶å†…å®¹"æŸ¥çœ‹è¯¦æƒ…
    2. ç‚¹å‡»"åˆ›å»ºç¤ºä¾‹æ•°æ®"ç”Ÿæˆæ¨¡æ¿
    3. ä¸‹è½½æ¨¡æ¿æ–‡ä»¶
    4. ä¸Šä¼ åˆ°GitHubçš„dataæ–‡ä»¶å¤¹
    5. ç¡®ä¿æ–‡ä»¶ç¼–ç ä¸ºUTF-8
    """)
    
    # æ·»åŠ éªŒè¯æŒ‰é’®
    if st.sidebar.button("ğŸ”§ éªŒè¯ä¿®å¤", key="verify_fix"):
        st.sidebar.write("**éªŒè¯ç»“æœ:**")
        
        # æµ‹è¯•è´¢åŠ¡æ•°æ®
        financial_data = load_data_from_github("financial_data.json")
        if financial_data:
            st.sidebar.success(f"âœ… è´¢åŠ¡æ•°æ®: {len(financial_data)} æ¡")
        else:
            st.sidebar.error("âŒ è´¢åŠ¡æ•°æ®ä»æœ‰é—®é¢˜")
        
        # æµ‹è¯•å®ç‰©æ•°æ®  
        physical_data = load_data_from_github("physical_data.json")
        if physical_data:
            st.sidebar.success(f"âœ… å®ç‰©æ•°æ®: {len(physical_data)} æ¡")
        else:
            st.sidebar.error("âŒ å®ç‰©æ•°æ®ä»æœ‰é—®é¢˜")
   
    # æ ¹æ®é€‰æ‹©æ˜¾ç¤ºå¯¹åº”é¡µé¢
    if page == "ğŸ“¥ æ•°æ®å¯¼å…¥":
        data_import_page()
    elif page == "ğŸ” æ˜ å°„æŸ¥è¯¢":
        mapping_query_page()
    elif page == "ğŸ“Š æ•°æ®ç»Ÿè®¡":
        data_statistics_page()
    elif page == "ğŸ“‹ å…¨éƒ¨æ•°æ®":
        all_data_view_page()

# ========== ç¨‹åºå…¥å£ ==========
if __name__ == "__main__":
  main()
